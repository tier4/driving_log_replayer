{"config":{"lang":["en","ja"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Driving Log Replayer Documentation","text":"<p>Language selection is available by pressing the \"\u6587 A\" icon at the top of the page.</p> <p>This repository is currently in maintenance mode. Bug fixes only, no new features will be added. Please use v2 below.</p> <p>https://github.com/tier4/driving_log_replayer_v2</p>"},{"location":"#about-driving-log-replayer","title":"About Driving Log Replayer","text":"<p>Driving Log Replayer is a ROS 2 package that evaluates the performance of Autoware.Universe based on previously recorded input data. It allows for defining and checking whether the assumptions of the system operation have been met.</p>"},{"location":"analyzer/","title":"Driving Log Replayer Analyzer","text":"<p>Package to analyze the result files of tests performed by Driving Log Replayer.</p>"},{"location":"analyzer/#directory-structure","title":"Directory Structure","text":"<p>The directory structure is as follows.</p> <pre><code>driving_log_replayer_analyzer\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 __main__.py    # Entry point for CLI\n\u251c\u2500\u2500 analysis       # CLI analysis command\n\u251c\u2500\u2500 config         # Configuration file and module to read configuration\n\u251c\u2500\u2500 data           # Module to read data from jsonl\n\u2514\u2500\u2500 plot           # Module to plot data\n</code></pre> <p>Although this package is ROS-independent, it is also imported into ROS nodes as a library, so it is also installed as a ROS package.</p> <p>The roles of the modules are shown in Fig.</p> <p>architecture</p>"},{"location":"analyzer/#caution","title":"Caution","text":"<p>Currently only analysis of result.jsonl of obstacle_segmentation is possible. If necessary, add analysis modules for each use case. Add use_case_name.py files to analysis, config, and data.</p>"},{"location":"analyzer/#how-to-install","title":"How to install","text":"<ul> <li>Installed with driving_log_replayer_cli</li> <li>Installed with driving_log_replayer as a ros package</li> </ul>"},{"location":"analyzer/#usage","title":"Usage","text":"<pre><code>dlr-analyzer analysis ${use-case-name} ${result.jsonl_path} [-c ${config_path}]\n</code></pre>"},{"location":"overview/command/","title":"Command","text":"<p>After installing <code>driving_log_replayer_cli</code>, the <code>dlr</code> command can be executed in the terminal. The <code>dlr</code> command has subcommands. The arguments required for each command can be displayed by specifying the <code>--help</code> option.</p> <pre><code># driving_log_replayer top level help\ndlr --help\n\n# show version\ndlr --version\n\n# show subcommand help\ndlr subcommand --help\n\n# show subsubcommand help\ndlr subcommand subsubcommand --help\n</code></pre>"},{"location":"overview/command/#cli-subcommands","title":"CLI subcommands","text":"<p>The list of supported subcommands can be found below:</p> <ul> <li>configure</li> <li>simulation</li> </ul>"},{"location":"overview/command/#dlr-configure","title":"dlr configure","text":"<p>Command to manipulate the configuration file <code>.driving_log_replayer.config.toml</code>.</p> <pre><code># Set data_directory, output_directory, and autoware_path to the profile name specified by -p.\n# If -p is omitted, default is specified for the profile name.\ndlr configure register -d ${data_directory} -o ${output_directory} -a ${autoware_path} [-p ${profile}]\n</code></pre>"},{"location":"overview/command/#dlr-simulation","title":"dlr simulation","text":"<p>Available commands to run the Autoware evaluation:</p> <pre><code># simulation run\ndlr simulation run -p ${profile}\n\n# Check results and display summary of result files under output_directory\ndlr simulation show-result ${output_directory}\n</code></pre>"},{"location":"overview/command/#dlr-simulation-run-launch-argument-option","title":"dlr simulation run launch argument option","text":"<p>The driving_log_replayer cli reads the necessary launch arguments such as sensor_model from the scenario file and generates the launch command. On the other hand, launch arguments that you want to change at runtime, such as bag playback speed, can be specified by passing them as options. Multiple arguments can be specified by arranging them in a comma-separated list.</p> <p>An example is shown below.</p> <pre><code># The playback speed of bag, i.e., simulation time, is set to 0.5x speed.\ndlr simulation run -p default -l play_rate:=0.5\n\n# Set bag playback speed to 0.5x and input_pointcloud to /sensing/lidar/concatenated/pointcloud\ndlr simulation run -p default -l play_rate:=0.5 -l input_pointcloud:=/sensing/lidar/concatenated/pointcloud\n\n# Set perception_mode to camera_lidar_fusion\ndlr simulation run -p default -l perception_mode:=camera_lidar_fusion\n\n# Dry-run mode to obtain metrics without creating a scenario file\n# set bag, map, sensor_model, vehicle_model, [and vehicle_id] from arguments\ndlr simulation dry-run -p ${profile} -u ${use_case} -l sensor_model:=${sensor_model} -l vehicle_model:=${vehicle_model} -l map_path:=${map_path} -l input_bag:=${bag_path} [-l vehicle_id:=${vehicle_id}]\n\n# Command example\n# The -p option is used to determine the output destination for bag and result.jsonl. If omitted, the output is sent to the output_directory of the default profile.\n# Currently, use_case is only annotationless_perception, so if -u is omitted, it automatically becomes annotationless_perception.\ndlr simulation dry-run -l input_bag:=$HOME/dlr_data/auto/annotationless/sample/input_bag -l sensor_model:=sample_sensor_kit -l vehicle_model:=sample_vehicle -l map_path:=$HOME/map/sample_map\n</code></pre> <p>The arguments that can be specified can be displayed by using the -s option of ros2 launch.</p> <pre><code># \u276f ros2 launch driving_log_replayer ${use_case}.launch.py -s\n\u276f ros2 launch driving_log_replayer localization.launch.py -s\nArguments (pass arguments as '&lt;name&gt;:=&lt;value&gt;'):\n\n    'with_autoware':\n        Whether to launch autoware or not\n        (default: 'true')\n\n    'scenario_path':\n        scenario path\n...\n</code></pre> <p>However, some arguments are fixed on the driving_log_replayer side so that they cannot be inconsistently set, such as localization:=false in the localization evaluation, even if they are displayed as launch arguments. Fixed arguments are ignored even if specified. See the following file for fixed arguments.</p> <pre><code>get_autoware_launch fucntion in driving_log_replayer/driving_log_replayer/launch_common.py\u3000\nargument of get_autoware_launch in driving_log_replayer/launch/${use_case}.launch.py\n</code></pre>"},{"location":"overview/command/#files-created-by-simulation-run","title":"Files created by simulation run","text":"<p>When the simulation run command is executed, a run time directory is created in the output folder of the profile, and the files are output under the directory. An example of the output file is shown below.</p> <pre><code># t4_dataset\u3092\u4f7f\u7528\u3057\u306a\u3044\u5834\u5408\noutput_direcotry\n\u2514\u2500\u2500 YYYY-mmDD-HHMMSS               // Execution time\n    \u2514\u2500\u2500 TC01                       // Name of test case\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 console.log           // Log output to the terminal\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 result.jsonl          // Original result file\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 result_bag            // recorded bag\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 metadata.yaml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 result_bag_0.db3\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 run.bash              // Simulation execution command\n    \u2514\u2500\u2500 TC02\n...\n</code></pre> <pre><code>output_direcotry\n\u2514\u2500\u2500 YYYY-mmDD-HHMMSS                         // Execution time\n    \u2514\u2500\u2500 TC01                                 // Name of test case\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 console.log                     // Log output to the terminal\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 run.bash                        // Simulation execution command\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 DATASET01\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 perception_eval_log        // Log files of perception_eval\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 ...\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 result.jsonl               // Original result file\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 result_archive             // Directory to output evaluation results other than json\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scene_result.pkl      // Object file of frame_results evaluated by perception_eval\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 result_bag                 // recorded bag\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0     \u251c\u2500\u2500 metadata.yaml\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0     \u2514\u2500\u2500 result_bag_0.db3\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 DATASET02\n...\n</code></pre>"},{"location":"overview/command/#run-driving_log_replayer-with-wasim","title":"Run driving_log_replayer with wasim","text":"<p>If you have access rights to Autoware Evaluator provided by TIER IV, you can also use wasim.</p> <p>Please see the wasim documentation site for an example of tool usage.</p> <p>Since wasim downloads and executes scenarios from Autoware Evaluator, it can only execute scenarios that are already registered in the cloud environment. For scenarios not registered in the cloud, use <code>driving_log_replayer_cli</code>.</p>"},{"location":"overview/","title":"Overview","text":"<p>Driving Log Replayer is a package that runs Autoware in an open loop by supplying previously recorded input data using log(rosbag2) API. The package gathers information and evaluates topics output produced by Autoware. Its use is to test the software regression and check Autoware's performance of sensing, localization, and perception components.</p>"},{"location":"overview/#related-documents","title":"Related Documents","text":"<ol> <li>AutowareDocumentation</li> <li>WebAutoDocumentation</li> </ol>"},{"location":"overview/#related-repositories","title":"Related repositories","text":"<ol> <li>ros2bag_extensions</li> <li>perception_eval</li> <li>perception_dataset</li> </ol>"},{"location":"overview/#architecture","title":"Architecture","text":"<p>Driving Log Replayer package contains an evaluation node that extends Autoware's standard functionality. The architecture graph is shown below.</p> <p></p>"},{"location":"overview/#package-structure","title":"Package structure","text":"<p>The evaluation node works in the following manner:</p> <ul> <li>reads a scenario describing the conditions of positive evaluation</li> <li>launches autoware</li> <li>outputs the evaluation result in a JSON file format</li> </ul> <p>The details of the node's operation are shown in the figure below.</p> <p></p>"},{"location":"overview/#example-usage-flow","title":"Example usage flow","text":"<ol> <li>Acquire rosbags for evaluation using a real-world vehicle.</li> <li>Filter the acquired rosbags to contain only sufficient input topics in required period of time<ul> <li>For this purpose please use ros2bag_extensions package (developed by TIER IV). To properly filter the input rosbag:<ul> <li>See docs/use_case/ documentations for which topics to leave in the filter.</li> </ul> </li> </ul> </li> <li>Create an evaluation scenario<ol> <li>Example scenarios could be found in the repository's sample folder</li> <li>Refer to the format definition section of this document for description contents.</li> </ol> </li> <li>If the node should test obstacle_segmentation, perception, perception_2d, or traffic_light stacks, please annotate with an annotation tool that supports conversion to t4_dataset.<ol> <li>Deepen.AI is available.</li> <li>By adding conversion functionality to perception_dataset, it becomes possible to use other annotation tools as well.</li> </ol> </li> <li>Perform the evaluation.</li> </ol>"},{"location":"overview/setup/","title":"Setup","text":"<p>This section describes the settings required to use driving_log_replayer.</p>"},{"location":"overview/setup/#cli-setting","title":"Cli setting","text":"<p>In order to reduce the number of arguments to be passed to <code>driving_log_replayer_cli</code>, the directories specified as arguments are described in a configuration file.</p> <p>Therefore, before using the cli, create a $HOME/.driving_log_replayer.config.toml file in the format presented below. You can create it manually or by using the dlr configuration command.</p> <pre><code># manual creation\nnano $HOME/.driving_log_replayer.config.toml\n\n# cli creation\ndlr configuration register -d ${data_directory} -o ${output_directory} -a ${autoware_path} [-p ${profile}]\n</code></pre> <p>At least one profile is required, and one must be named <code>default</code>.</p> <p>Specifying the profile name with <code>-p ${profile_name}</code> in the commands described below will load the settings specified in the profile. You can switch between multiple autoware profiles, and if no profile is specified, default is used.</p> <pre><code>[profile_name]\ndata_directory = \"path of the data folder used as input for the simulation\"\noutput_directory = \"path of the folder to output the simulation results\"\nautoware_path = \"path of the autoware workspace folder\"\n</code></pre> <p>example setting</p> <pre><code># default is required and selected when profile name is omitted\n[default]\ndata_directory = \"$HOME/driving_log_replayer_data/default\"\noutput_directory = \"$HOME/driving_log_replayer_output/default\"\nautoware_path = \"$HOME/autoware\"\n\n[localization]\ndata_directory = \"$HOME/driving_log_replayer_data/localization\"\noutput_directory = \"$HOME/driving_log_replayer_output/localization\"\nautoware_path = \"$HOME/autoware\"\n\n[yabloc]\ndata_directory = \"$HOME/driving_log_replayer_data/yabloc\"\noutput_directory = \"$HOME/driving_log_replayer_output/yabloc\"\nautoware_path = \"$HOME/autoware\"\n\n[ar_tag_based_localizer]\ndata_directory = \"$HOME/driving_log_replayer_data/ar_tag_based_localizer\"\noutput_directory = \"$HOME/driving_log_replayer_output/ar_tag_based_localizer\"\nautoware_path = \"$HOME/autoware\"\n\n[obstacle_segmentation]\ndata_directory = \"$HOME/driving_log_replayer_data/obstacle_segmentation\"\noutput_directory = \"$HOME/driving_log_replayer_output/obstacle_segmentation\"\nautoware_path = \"$HOME/autoware\"\n\n[perception]\ndata_directory = \"$HOME/driving_log_replayer_data/perception\"\noutput_directory = \"$HOME/driving_log_replayer_output/perception\"\nautoware_path = \"$HOME/autoware\"\n</code></pre>"},{"location":"overview/setup/#folder-structure-and-file-naming-rules","title":"Folder structure and file naming rules","text":"<p>This section describes the folder structure and file naming rules expected by <code>driving_log_replayer</code>.</p> <p>In <code>driving_log_replayer</code> the folder structure and file names are fixed to reduce the number of paths to be described in the scenario and the arguments to be passed to the command. Also, by placing multiple folders in <code>data_directory</code> multiple tests can be executed in succession.</p>"},{"location":"overview/setup/#data-folder","title":"Data Folder","text":"<p>A folder where resources used in the simulation are stored.</p> <p>For each test case: a scenario, rosbag, and dataset are placed.</p>"},{"location":"overview/setup/#data-folder-structure-for-use-case-without-t4_dataset","title":"Data Folder Structure for use case without t4_dataset","text":"<pre><code>profile_data_directory                // .driving_log_replayer.config \u306e data_directory\n\u2502\n\u251c\u2500\u2500 TC001                          // Test case directory. Directry name can be named arbitrarily\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 scenario.yaml             // Scenario\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 input_bag                 // Bag for input containing sensor data\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input_bag_0.db3       // Binary file of bag\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 metadata.yaml         // Metadata file of bag\n\u2502\n\u251c\u2500\u2500 TC002                          // Test case directory. Same structure as TC001\n...\n</code></pre>"},{"location":"overview/setup/#data-folder-structure-for-use-case-with-t4_dataset","title":"Data Folder Structure for use case with t4_dataset","text":"<pre><code>profile_data_directory                 // .driving_log_replayer.config \u306e data_directory\n\u2502\n\u251c\u2500\u2500 TC001                           // Test case directory. Directry name can be named arbitrarily\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 scenario.yaml              // Scenario\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 t4_dataset\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 T4D001                 // t4_dataset directory. If use case is sensing, t4_dataset is always one.\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 annotation\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 LIDAR_CONCAT\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 input_bag\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 T4D002                 // t4_dataset directory. If use case is peception, t4_dataset can be multiple.\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 annotation\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 LIDAR_CONCAT\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 input_bag\n\u2502          ...\n\u2502\n\u251c\u2500\u2500 TC002                           // Test case directory. Same structure as TC001\n...\n</code></pre>"},{"location":"overview/setup/#when-you-want-to-use-a-common-scenario-file-in-a-profile","title":"When you want to use a common scenario file in a profile","text":"<p>This is used when you want to evaluate bag files acquired with the same map, vehicle, and sensor configuration in one common scenario. It can be used when you want to run simulations that only require metrics to determine threshold values with annotationless_perception.</p> <p>For example, in the following case, TC001 is evaluated in base_scenario.yaml and TC002 uses scenario.yaml in the directory</p> <pre><code>profile_data_directory                // .driving_log_replayer.config \u306e data_directory\n\u251c\u2500\u2500 base_scenario.yaml\u3000\u3000\u3000\u3000\u3000\u3000 // Common scenario used when no scenario file exists in the directory\n\u2502\n\u251c\u2500\u2500 TC001                          // Test case directory. Directry name can be named arbitrarily\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 input_bag                 // Bag for input containing sensor data\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input_bag_0.db3       // Binary file of bag\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 metadata.yaml         // Metadata file of bag\n\u2502\n\u251c\u2500\u2500 TC002                          // Test case directory. Directry name can be named arbitrarily\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 scenario.yaml             // The scenario files in the directory are used. base_scenario.yaml is ignored\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 input_bag                 // Bag for input containing sensor data\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input_bag_0.db3       // Binary file of bag\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 metadata.yaml         // Metadata file of bag\n</code></pre>"},{"location":"overview/setup/#map-folder","title":"Map Folder","text":"<p>A folder where all the maps used in the simulation are stored.</p> <pre><code>autoware_map\n\u2502\n\u251c\u2500\u2500 LocalMapPath1            // Path specified by LocalMapPath in the scenario\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lanelet2_map.osm    // lanelet file\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 pointcloud_map.pcd  // pcd file\n\u2502\n\u251c\u2500\u2500 LocalMapPath2            // Path specified by LocalMapPath in the scenario\n...\n</code></pre>"},{"location":"quick_start/annotationless_perception/","title":"Annotationless Perception","text":""},{"location":"quick_start/annotationless_perception/#preparation","title":"Preparation","text":"<ol> <li> <p>Copy sample scenario</p> <pre><code>mkdir -p ~/driving_log_replayer_data/annotationless_perception/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/annotationless_perception/scenario.yaml ~/driving_log_replayer_data/annotationless_perception/sample\n</code></pre> </li> <li> <p>Copy bag file from dataset</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_dataset/input_bag ~/driving_log_replayer_data/annotationless_perception/sample\n</code></pre> </li> </ol>"},{"location":"quick_start/annotationless_perception/#how-to-run","title":"How to run","text":"<ol> <li> <p>Run the simulation</p> <pre><code>dlr simulation run -p annotationless_perception -l play_rate:=0.5\n</code></pre> </li> <li> <p>Check the results</p> <p>Results are displayed in the terminal like below.</p> <pre><code>scenario: sample\n--------------------------------------------------\nTestResult: Passed\nPassed:\nCAR (Success)\nBUS (Success)\nPEDESTRIAN (Success)\nBICYCLE (Success)\nMOTORCYCLE (Success)\nTRAILER (Success)\nUNKNOWN (Success)\nTRUCK (Success)\n</code></pre> </li> </ol>"},{"location":"quick_start/ar_tag_based_localizer/","title":"ArTagBasedLocalizer Evaluation","text":""},{"location":"quick_start/ar_tag_based_localizer/#preparation","title":"Preparation","text":"<ol> <li> <p>Copy sample scenario</p> <pre><code>mkdir -p ~/driving_log_replayer_data/ar_tag_based_localizer/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/ar_tag_based_localizer/scenario.yaml ~/driving_log_replayer_data/ar_tag_based_localizer/sample\n</code></pre> </li> <li> <p>Copy sample bag and map</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_bag/ar_tag_based_localizer/input_bag ~/driving_log_replayer_data/ar_tag_based_localizer/sample\ncp -r ~/driving_log_replayer_data/sample_bag/ar_tag_based_localizer/map ~/driving_log_replayer_data/ar_tag_based_localizer/sample\n</code></pre> </li> </ol>"},{"location":"quick_start/ar_tag_based_localizer/#how-to-run","title":"How to run","text":"<ol> <li> <p>Run the simulation</p> <pre><code>dlr simulation run -p ar_tag_based_localizer -l play_rate:=0.5\n</code></pre> </li> <li> <p>Check the results</p> <p>Results are displayed in the terminal like below.</p> <pre><code>test case 1 / 1 : use case: sample\n--------------------------------------------------\nTestResult: Passed\nPassed: ArTagBasedLocalizer Availability (Success): Detected 1 AR tags\n</code></pre> </li> </ol>"},{"location":"quick_start/eagleye/","title":"Eagleye Evaluation","text":""},{"location":"quick_start/eagleye/#preparation","title":"Preparation","text":"<ol> <li> <p>Copy sample scenario</p> <pre><code>mkdir -p ~/driving_log_replayer_data/eagleye/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/eagleye/scenario.yaml ~/driving_log_replayer_data/eagleye/sample\n</code></pre> </li> <li> <p>Copy sample bag</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_bag/eagleye/input_bag ~/driving_log_replayer_data/eagleye/sample\n</code></pre> </li> </ol>"},{"location":"quick_start/eagleye/#how-to-run","title":"How to run","text":"<ol> <li> <p>Run the simulation</p> <pre><code>dlr simulation run -p eagleye  -l play_rate:=0.5\n</code></pre> </li> <li> <p>Check the results</p> <p>Results are displayed in the terminal like below.</p> <pre><code>test case 1 / 1 : use case: sample\n--------------------------------------------------\nTestResult: Passed\nPassed: Eagleye Availability (Passed): OK\n</code></pre> </li> </ol>"},{"location":"quick_start/installation/","title":"Installation","text":"<p>This document contains step-by-step instruction on how to build AWF Autoware Core/Universe with <code>driving_log_replayer</code>.</p>"},{"location":"quick_start/installation/#requirements","title":"Requirements","text":"<ul> <li>CPU amd64</li> <li>Ubuntu 22.04</li> <li>ROS humble</li> <li>Python 3.10</li> <li>NVIDIA GPU (required if running perception)</li> <li>pipx</li> <li>zstd<ul> <li>sudo apt install zstd</li> </ul> </li> </ul>"},{"location":"quick_start/installation/#how-to-build","title":"How to build","text":"<ol> <li> <p>Navigate to the Autoware workspace:</p> <pre><code>cd autoware\n</code></pre> </li> <li> <p>Add dependency packages:</p> <pre><code>nano simulator.repos\n# add repositories below.\n</code></pre> <pre><code>  simulator/perception_eval:\n    type: git\n    url: https://github.com/tier4/autoware_perception_evaluation.git\n    version: main\n  simulator/driving_log_replayer:\n    type: git\n    url: https://github.com/tier4/driving_log_replayer.git\n    version: main\n  simulator/vendor/ros2_numpy:\n    type: git\n    url: https://github.com/Box-Robotics/ros2_numpy.git\n    version: humble\n  simulator/vendor/ros2bag_extensions:\n    type: git\n    url: https://github.com/tier4/ros2bag_extensions.git\n    version: main\n</code></pre> </li> <li> <p>Import Simulator dependencies:</p> <pre><code>vcs import src &lt; simulator.repos\n</code></pre> </li> <li> <p>Update rosdep:</p> <pre><code>rosdep update\n</code></pre> </li> <li> <p>Install dependent ROS packages:</p> <pre><code>rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n</code></pre> </li> <li> <p>Build the workspace:</p> <pre><code>colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release\n</code></pre> </li> <li> <p>Install cli to run driving_log_replayer:</p> <pre><code>pipx install git+https://github.com/tier4/driving_log_replayer.git\n</code></pre> </li> <li> <p>Install shell completion scripts</p> <pre><code># bash\n_DLR_COMPLETE=bash_source dlr &gt; $HOME/.dlr-complete.bash\n_DLR_COMPLETE=bash_source dlr &gt; $HOME/.dlr-analyzer-complete.bash\n\necho \"source $HOME/.dlr-complete.bash\" &gt;&gt; ~/.bashrc\necho \"source $HOME/.dlr-analyzer-complete.bash\" &gt;&gt; ~/.bashrc\n</code></pre> <pre><code># fish\n_DLR_COMPLETE=fish_source dlr &gt; $HOME/.config/fish/completions/dlr.fish\n_DLR_ANALYZER_COMPLETE=fish_source dlr-analyzer &gt; $HOME/.config/fish/completions/dlr-analyzer.fish\n</code></pre> </li> </ol>"},{"location":"quick_start/localization/","title":"NDT Localization Evaluation","text":""},{"location":"quick_start/localization/#preparation","title":"Preparation","text":"<ol> <li> <p>Copy sample scenario</p> <pre><code>mkdir -p ~/driving_log_replayer_data/localization/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/localization/scenario.yaml ~/driving_log_replayer_data/localization/sample\n</code></pre> </li> <li> <p>Copy bag file from dataset</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_dataset/input_bag ~/driving_log_replayer_data/localization/sample\n</code></pre> </li> <li> <p>Filter and slice bag</p> <pre><code>source ~/autoware/install/setup.bash\ncd ~/driving_log_replayer_data/localization/sample\nros2 bag filter input_bag -o filtered_bag -x \"/localization/.*\" \"/sensing/lidar/concatenated/pointcloud\" \"/tf\"\nros2 bag slice filtered_bag -o sliced_bag -b 1649138880 -e 1649138910\nrm -rf input_bag\nrm -rf filtered_bag\nmv sliced_bag input_bag\n</code></pre> </li> </ol>"},{"location":"quick_start/localization/#how-to-run","title":"How to run","text":"<ol> <li> <p>Run the simulation</p> <pre><code>dlr simulation run -p localization  -l play_rate:=0.5\n</code></pre> <p></p> </li> <li> <p>Check the results</p> <p>Results are displayed in the terminal like below.  The number of tests will vary slightly depending on PC performance and CPU load conditions, so slight differences are not a problem.</p> <pre><code> test case 1 / 1 : use case: sample\n --------------------------------------------------\n TestResult: Passed\n Passed: Convergence (Passed): 281 / 281 -&gt; 100.00%, Reliability (Passed): NVTL Sequential NG Count: 0 (Total Test: 283, Average: 2.476907772225963, StdDev: 0.042055602266257264), NDT Availability (Passed): NDT available\n</code></pre> </li> </ol>"},{"location":"quick_start/obstacle_segmentation/","title":"Obstacle Segmentation Evaluation","text":""},{"location":"quick_start/obstacle_segmentation/#preparation","title":"Preparation","text":"<ol> <li> <p>Copy sample scenario</p> <pre><code>mkdir -p ~/driving_log_replayer_data/obstacle_segmentation/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/obstacle_segmentation/scenario.yaml ~/driving_log_replayer_data/obstacle_segmentation/sample\n</code></pre> </li> <li> <p>Copy bag file from dataset</p> <pre><code>mkdir -p ~/driving_log_replayer_data/obstacle_segmentation/sample/t4_dataset\ncp -r ~/driving_log_replayer_data/sample_dataset ~/driving_log_replayer_data/obstacle_segmentation/sample/t4_dataset\n</code></pre> </li> </ol>"},{"location":"quick_start/obstacle_segmentation/#how-to-run","title":"How to run","text":"<ol> <li> <p>Run the simulation</p> <pre><code>dlr simulation run -p obstacle_segmentation  -l play_rate:=0.5\n</code></pre> <p></p> </li> <li> <p>Check the results</p> <p>Results are displayed in the terminal like below.  The number of tests will vary slightly depending on PC performance and CPU load conditions, so slight differences are not a problem.</p> <pre><code> test case 1 / 1 : use case: sample_dataset\n --------------------------------------------------\n TestResult: Failed\n Detection Failed: detection: 557 / 681 -&gt; 81.79% detection_warn: 0 non_detection: 681 / 681 -&gt; 100.00%\n</code></pre> </li> </ol>"},{"location":"quick_start/perception/","title":"Perception Evaluation","text":""},{"location":"quick_start/perception/#preparation","title":"Preparation","text":"<ol> <li> <p>Copy sample scenario</p> <pre><code>mkdir -p ~/driving_log_replayer_data/perception/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/perception/scenario.yaml ~/driving_log_replayer_data/perception/sample\n</code></pre> </li> <li> <p>Copy bag file from dataset</p> <pre><code>mkdir -p ~/driving_log_replayer_data/perception/sample/t4_dataset\ncp -r ~/driving_log_replayer_data/sample_dataset ~/driving_log_replayer_data/perception/sample/t4_dataset\n</code></pre> </li> <li> <p>Transform machine learning trained models</p> <pre><code>source ~/autoware/install/setup\nros2 launch autoware_launch logging_simulator.launch.xml map_path:=$HOME/autoware_map/sample-map-planning vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit\n# Wait until the following file is created in ~/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data\n# - pts_backbone_neck_head_centerpoint_tiny.engine\n# - pts_voxel_encoder_centerpoint_tiny.engine\n# When the file is output, press Ctrl+C to stop launch.\n</code></pre> </li> </ol>"},{"location":"quick_start/perception/#how-to-run","title":"How to run","text":"<ol> <li> <p>Run the simulation</p> <pre><code>dlr simulation run -p perception  -l play_rate:=0.5\n</code></pre> <p></p> </li> <li> <p>Check the results</p> <p>Results are displayed in the terminal like below.  The number of tests will vary slightly depending on PC performance and CPU load conditions, so slight differences are not a problem.</p> <pre><code>scenario: sample_dataset\n--------------------------------------------------\nTestResult: Passed\nPassed: criteria0 (Success): 215 / 215 -&gt; 100.00%, Passed: NotTested\n</code></pre> </li> </ol>"},{"location":"quick_start/setup/","title":"Setup","text":"<p>Note</p> <p>Running the Driving Log Replayer requires some additional steps on top of building and installing Autoware, so make sure that Driving Log Replayer installation has been completed first before proceeding.</p> <p>Sample map: Copyright 2020 TIER IV, Inc.</p> <p>Sample Dataset: Copyright 2022 TIER IV, Inc.</p>"},{"location":"quick_start/setup/#set-up-resources","title":"Set up resources","text":"<ol> <li> <p>Download and unpack sample maps.</p> <pre><code># annotationless_perception, localization, obstacle_segmentation, perception\nmkdir -p ~/autoware_map\ngdown -O ~/autoware_map/sample-map-planning.zip 'https://docs.google.com/uc?export=download&amp;id=1499_nsbUbIeturZaDj7jhUownh5fvXHd'\nunzip -d ~/autoware_map ~/autoware_map/sample-map-planning.zip\n\n# yabloc, eagleye\nwget -O ~/autoware_map/nishishinjuku_autoware_map.zip https://github.com/tier4/AWSIM/releases/download/v1.1.0/nishishinjuku_autoware_map.zip\nunzip -d ~/autoware_map ~/autoware_map/nishishinjuku_autoware_map.zip\n</code></pre> <p>You can also download manually.  sample-map-planning nishishinjuku_autoware_map</p> </li> <li> <p>Download and unpack datasets.</p> <pre><code># annotationless_perception, localization, obstacle_segmentation, perception\nmkdir -p ~/driving_log_replayer_data\ngdown -O ~/driving_log_replayer_data/sample_dataset_v2.tar.zst 'https://docs.google.com/uc?export=download&amp;id=1iCoykBBETI_rGfKEFYYb7LFydF-RJVkC'\ntar -I zstd -xvf ~/driving_log_replayer_data/sample_dataset_v2.tar.zst -C ~/driving_log_replayer_data/\n\n# yabloc, eagleye, artag\ngdown -O ~/driving_log_replayer_data/sample_bag.tar.zst 'https://docs.google.com/uc?export=download&amp;id=17ppdMKi4IC8J_2-_9nyYv-LAfW0M1re5'\ntar -I zstd -xvf ~/driving_log_replayer_data/sample_bag.tar.zst -C ~/driving_log_replayer_data/\n</code></pre> <p>You can also download manually.  dataset bag</p> </li> <li> <p>Copy sample setting</p> <pre><code># assuming that autoware is placed under ~/autoware directory\ncp ~/autoware/src/simulator/driving_log_replayer/sample/.driving_log_replayer.config.toml ~/\n</code></pre> </li> </ol>"},{"location":"quick_start/yabloc/","title":"YabLoc Evaluation","text":""},{"location":"quick_start/yabloc/#preparation","title":"Preparation","text":"<ol> <li> <p>Copy sample scenario</p> <pre><code>mkdir -p ~/driving_log_replayer_data/yabloc/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/yabloc/scenario.yaml ~/driving_log_replayer_data/yabloc/sample\n</code></pre> </li> <li> <p>Download bag file</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_bag/yabloc/input_bag ~/driving_log_replayer_data/yabloc/sample\n</code></pre> </li> </ol>"},{"location":"quick_start/yabloc/#how-to-run","title":"How to run","text":"<ol> <li> <p>Run the simulation</p> <pre><code>dlr simulation run -p yabloc -l play_rate:=0.5\n</code></pre> </li> <li> <p>Check the results</p> <p>Results are displayed in the terminal like below.</p> <pre><code>test case 1 / 1 : use case: sample\n--------------------------------------------------\nTestResult: Passed\nPassed: YabLoc Availability (Passed): OK\n</code></pre> </li> </ol>"},{"location":"result_format/","title":"Driving Log Replayer Result File Format","text":"<p>It is in JSONL format, with each line containing a string in JSON format.</p>"},{"location":"result_format/#format","title":"Format","text":"<p>Each line is output in the following format. The actual output is a single line of text, but it is formatted for ease of reading.</p> <pre><code>{\n  \"Result\": {\n    \"Success\": \"true or false\",\n    \"Summary\": \"summary of result\"\n  },\n  \"Stamp\": {\n    \"System\": \"system time\",\n    \"ROS\": \"simulation time\"\n  },\n  \"Frame\": {\n    \"Ego\": { \"TransformStamped\": \"transform_stamped from map to base_link\" },\n    \"Different configurations for each use case\": \"...\"\n  }\n}\n</code></pre> <p>Each evaluation output consists of the following attributes:</p> <ul> <li>Result: Result of the evaluation of the executed scenario</li> <li>Stamp: The time of the evaluation</li> <li>Frame: Evaluation results for one received frame (topic) and attached information such as values used for judgment.</li> </ul> <p>For more information on Frame, see the evaluation results file format for each use case.</p>"},{"location":"result_format/#analyze-the-result-files","title":"Analyze the result files","text":"<p>With vscode's JSONL Converter, you can easily convert jsonl &lt;-&gt; json with the push of a button</p> <p>https://marketplace.visualstudio.com/items?itemName=F-loat.jsonl-converter</p> <p>If you use python, you can read jsonl by setting lines=True in pandas.read_json.</p>"},{"location":"scenario_format/","title":"Driving Log Replayer Scenario Format Definition","text":"<p>This section describes the scenario format used in driving_log_replayer.</p>"},{"location":"scenario_format/#notes-on-the-format","title":"Notes on the format","text":"<ul> <li>Keys are defined in CamelCase.</li> <li>Unless otherwise specified, the coordinate system is <code>map</code> coordinate system.</li> <li>Unless otherwise specified, the following unit system is used.</li> </ul> <pre><code>Distance: m\nVelocity: m/s\nacceleration: m/s^2\nTime: s\n</code></pre>"},{"location":"scenario_format/#samples","title":"Samples","text":"<p>Sample scenarios are stored in the sample folder.</p>"},{"location":"scenario_format/#format","title":"Format","text":"<p>The basic structure is as follows. Details of each key are described below.</p>"},{"location":"scenario_format/#2xx-format","title":"2.x.x Format","text":"<p>For <code>localization</code>, <code>performance_diag</code>, <code>yabloc</code>, <code>eagleye</code> and <code>ar_tag_based_localizer</code> evaluation scenarios</p> <pre><code>ScenarioFormatVersion: 2.x.x\nScenarioName: String\nScenarioDescription: String\nSensorModel: String\nVehicleModel: String\nVehicleId: String\nLocalMapPath: String\nEvaluation:\n  UseCaseName: String\n  UseCaseFormatVersion: String\n  Conditions: Dictionary # refer use case\n</code></pre>"},{"location":"scenario_format/#3xx-format","title":"3.x.x Format","text":"<p>For <code>perception</code> and <code>obstacle_segmentation</code> evaluation scenarios.</p> <p>NOTE: VehicleId and LocalMapPath have been changed to be set for each id of t4_dataset.</p> <pre><code>ScenarioFormatVersion: 3.x.x\nScenarioName: String\nScenarioDescription: String\nSensorModel: String\nVehicleModel: String\nEvaluation:\n  UseCaseName: String\n  UseCaseFormatVersion: String\n  Datasets:\n    - DatasetName:\n        VehicleId: String\n        LocalMapPath: String\n  Conditions: Dictionary # refer use case\n</code></pre>"},{"location":"scenario_format/#scenarioformatversion","title":"ScenarioFormatVersion","text":"<p>Describe the version information of the scenario format. Use the semantic version.</p> <p><code>localization</code>, <code>performance_diag</code>, <code>yabloc</code>, <code>eagleye</code> and <code>ar_tag_based_localizer</code> scenarios use the 2.x.x series. The latest version of 2.x.x is 2.2.0. <code>perception</code> and <code>obstacle_segmentation</code> scenarios use 3.x.x series. The latest version of 3.x.x is 3.0.0</p> <p>Minor versions are updated each time the format is updated.</p>"},{"location":"scenario_format/#scenarioname","title":"ScenarioName","text":"<p>Describes the name of the scenario, used as the display name of the scenario on the Autoware Evaluator.</p>"},{"location":"scenario_format/#scenariodescription","title":"ScenarioDescription","text":"<p>Describes a scenario, used as a scenario description on the Autoware Evaluator.</p>"},{"location":"scenario_format/#sensormodel","title":"SensorModel","text":"<p>Specify <code>sensor_model</code> as argument in <code>autoware_launch/launch/logging_simulator.launch.xml</code></p>"},{"location":"scenario_format/#vehiclemodel","title":"VehicleModel","text":"<p>Specify <code>vehicle_model</code> as an argument in <code>autoware_launch/launch/logging_simulator.launch.xml</code></p>"},{"location":"scenario_format/#vehicleid","title":"VehicleId","text":"<p>Specify <code>vehicle_id</code> as an argument in <code>autoware_launch/launch/logging_simulator.launch.xml</code></p> <p>If you don't know <code>vehicle_id</code>, set <code>default</code>.</p>"},{"location":"scenario_format/#localmappath","title":"LocalMapPath","text":"<p>Describes the path of the map folder to be used in the local environment.</p> <p>Environment variables such as <code>$HOME</code> can be used.</p>"},{"location":"scenario_format/#evaluation","title":"Evaluation","text":"<p>Define the evaluation conditions for the simulation.</p>"},{"location":"scenario_format/#usecasename","title":"UseCaseName","text":"<p>Specify an evaluation program.</p> <p>The evaluation is executed by calling the launch file with the name specified here. The <code>launch.py</code> file with the same name as specified must exist in the <code>driving_log_replayer/launch</code> folder.</p>"},{"location":"scenario_format/#usecaseformatversion","title":"UseCaseFormatVersion","text":"<p>Describe the version information of the use case format. The semantic version shall be used. Until the major version becomes 1, the minor version is updated every time the format is updated. The initial version is 0.1.0.</p>"},{"location":"scenario_format/#conditions","title":"Conditions","text":"<p>Specify conditions that can be set for each use case.</p> <p>Refer to each use case for the conditions that can be specified.</p>"},{"location":"trouble_shooting/","title":"Troubleshooting","text":"<p>Check if simulation does not work as expected</p>"},{"location":"trouble_shooting/#autoware-does-not-start","title":"Autoware does not start","text":""},{"location":"trouble_shooting/#cause-1","title":"Cause 1","text":"<p>The sensor_model, vehicle_model, and vehicle_id specified in the scenario are not included in the Autoware workspace used.</p>"},{"location":"trouble_shooting/#example-1","title":"Example 1","text":"<pre><code>\u276f dlr simulation run -p localization\n[INFO] [launch]: All log files can be found below /home/hyt/.ros/log/2024-06-07-12-37-19-365597-dpc2405001-1360746\n[INFO] [launch]: Default logging verbosity is set to INFO\n1717731451.040883 [77]       ros2: determined eno1 (udp/10.0.55.137) as highest quality interface, selected for automatic interface.\n[ERROR] [launch]: Caught exception in launch (see debug for traceback): executed command failed. Command: xacro /home/hyt/ros_ws/pilot-auto/install/tier4_vehicle_launch/share/tier4_vehicle_launch/urdf/vehicle.xacro vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit config_dir:=/home/hyt/ros_ws/pilot-auto/install/individual_params/share/individual_params/config/default/sample_sensor_kit\nCaptured stderr output: error: package not found: \"package 'sample_sensor_kit_description' not found, searching: ...\n...\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-1","title":"Correction method, Check area 1","text":"<p>Check whether sensor_model, vehicle_model, and vehicle_id specified in the scenario exist in the autoware_path specified in the profile.</p>"},{"location":"trouble_shooting/#cause-2","title":"Cause 2","text":"<p>The version of cli does not match the version of driving_log_replayer.</p>"},{"location":"trouble_shooting/#example-2","title":"Example 2","text":"<pre><code>\u276f dlr simulation run -p yabloc -l play_rate:=0.5\nUsage: dlr simulation run [OPTIONS]\nTry 'dlr simulation run -h' for help.\n\nError: No such option: -l\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-2","title":"Correction method, Check area 2","text":"<p>Check that the value of the version tag in the package.xml of the installed driving_log_replayer matches the version output by the CLI.</p> <pre><code>\u276f dlr --version\n1.18.0\n</code></pre>"},{"location":"trouble_shooting/#autoware-exits-immediately-after-startup","title":"Autoware exits immediately after startup","text":""},{"location":"trouble_shooting/#cause","title":"Cause","text":"<p>Incorrect scenario format</p>"},{"location":"trouble_shooting/#example","title":"Example","text":"<pre><code>[localization_evaluator_node.py-55] [ERROR] [1717734608.157798307] [driving_log_replayer.localization_evaluator]: An error occurred while loading the scenario. 1 validation error for LocalizationScenario\n[localization_evaluator_node.py-55] Evaluation.UseCaseFormatVersion\n[localization_evaluator_node.py-55]   Input should be '1.2.0' or '1.3.0' [type=literal_error, input_value='1.0.0', input_type=str]\n[localization_evaluator_node.py-55]     For further information visit https://errors.pydantic.dev/2.7/v/literal_error\n\nscenario: direct\n--------------------------------------------------\nTestResult: Failed\nScenarioFormatError\n--------------------------------------------------\n</code></pre> <pre><code>{\"Condition\":{}}\n{\"Result\":{\"Success\":false,\"Summary\":\"NoData\"},\"Stamp\":{\"System\":1717734608.157981},\"Frame\":{}}\n{\"Result\":{\"Success\":false,\"Summary\":\"ScenarioFormatError\"},\"Stamp\":{\"System\":0},\"Frame\":{\"ErrorMsg\":\"1 validation error for LocalizationScenario\\nEvaluation.UseCaseFormatVersion\\n  Input should be '1.2.0' or '1.3.0' [type=literal_error, input_value='1.0.0', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.7/v/literal_error\"}}\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area","title":"Correction method, Check area","text":"<p>The result.jsonl file shows what the problem is, so fix it as instructed. In the example, UseCaseFormatVersion should be 1.2.0 or 1.3.0, but it is 1.0.0, so it cannot be used. Since the old format is used, you should fix it by referring to the scenario in the sample directory of the repository.</p>"},{"location":"trouble_shooting/#the-evaluation-result-is-nodata","title":"The evaluation result is NoData","text":""},{"location":"trouble_shooting/#cause-1_1","title":"Cause 1","text":"<p>Autoware is not outputting the topic to be evaluated.</p>"},{"location":"trouble_shooting/#example-1-1","title":"Example 1-1","text":"<p>The node that outputs the topic to be evaluated is not invoked from launch. The true/false value in the launch file is incorrectly set.</p>"},{"location":"trouble_shooting/#correction-method-check-area-1-1","title":"Correction method, Check area 1-1","text":"<p>Find the topic to be evaluated in the document and check if the publisher exists by doing topic info. If the Publisher count: 0, it is highly likely that the system has not been started in the first place.</p> <pre><code>\u276f ros2 topic info /perception/traffic_light_recognition/traffic_signals -v\nType: autoware_auto_perception_msgs/msg/TrafficSignalArray\n\nPublisher count: 1 &lt;- Make sure it's not 0.\n\nNode name: crosswalk_traffic_light_estimator\nNode namespace: /perception/traffic_light_recognition\nTopic type: autoware_auto_perception_msgs/msg/TrafficSignalArray\nEndpoint type: PUBLISHER\nGID: 01.10.d8.43.57.21.7c.2d.98.25.db.df.00.00.46.03.00.00.00.00.00.00.00.00\nQoS profile:\n  Reliability: RELIABLE\n  History (Depth): KEEP_LAST (1)\n  Durability: VOLATILE\n  Lifespan: Infinite\n  Deadline: Infinite\n  Liveliness: AUTOMATIC\n  Liveliness lease duration: Infinite\n</code></pre>"},{"location":"trouble_shooting/#example-1-2","title":"Example 1-2","text":"<p>The node is running at launch, but dies immediately after startup.</p>"},{"location":"trouble_shooting/#correction-method-check-area-1-2","title":"Correction method, Check area 1-2","text":"<p>Search the terminal you started or console.log with ERROR.</p> <p>The following is a log of a case in which no point cloud was produced at all. Searching by ERROR shows that pointcloud_preprocessor is dead. Check if component_container, which outputs topics, is not throwing an error.</p> <pre><code>[ERROR] [component_container_mt-18]: process has died [pid 95, exit code -6, cmd '/opt/ros/galactic/lib/rclcpp_components/component_container_mt --ros-args -r __node:=pointcloud_preprocessor_container -r __ns:=/sensing/lidar/pointcloud_preprocessor --params-file /tmp/launch_params_rh_9gxcs'].\n</code></pre>"},{"location":"trouble_shooting/#example-1-3","title":"Example 1-3","text":"<p>Inconsistency between cuda, cuDNN, and TensorRT resulting in no perception recognition results. This may occur when nvidia driver is updated by apt upgrade.</p> <pre><code>hyt@dpc1909014-2204:~/ros_ws/awf$ ros2 launch lidar_centerpoint lidar_centerpoint.launch.xml model_name:=centerpoint_tiny model_path:=/home/hyt/autoware_data/lidar_centerpoint model_param_path:=$(ros2 pkg prefix lidar_centerpoint --share)/config/centerpoint_tiny.param.yaml build_only:=true\n[INFO] [launch]: All log files can be found below /home/hyt/.ros/log/2024-01-22-14-36-04-069409-dpc1909014-2204-3835027\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [lidar_centerpoint_node-1]: process started with pid [3835028]\n[lidar_centerpoint_node-1] 1705901764.307868 [77] lidar_cent: determined enp4s0 (udp/10.0.53.59) as highest quality interface, selected for automatic interface.\n[lidar_centerpoint_node-1] terminate called after throwing an instance of 'thrust::system::system_error'\n[lidar_centerpoint_node-1]   what():  This program was not compiled for SM 75\n[lidar_centerpoint_node-1] : cudaErrorInvalidDevice: invalid device ordinal\n[ERROR] [lidar_centerpoint_node-1]: process has died [pid 3835028, exit code -6, cmd '/home/hyt/ros_ws/awf/install/lidar_centerpoint/lib/lidar_centerpoint/lidar_centerpoint_node --ros-args -r __node:=lidar_centerpoint --params-file /tmp/launch_params_60_o26mq --params-file /tmp/launch_params_79jodq9o --params-file /tmp/launch_params_spwl7uq2 --params-file /tmp/launch_params_ur_yt_y2 --params-file /tmp/launch_params_iqs0hf9o --params-file /tmp/launch_params_t6bo4aow --params-file /tmp/launch_params_ufdn98_7 --params-file /tmp/launch_params_7m7aj130 --params-file /tmp/launch_params_yr4emr64 --params-file /tmp/launch_params_u4_e0ngh --params-file /home/hyt/ros_ws/awf/install/lidar_centerpoint/share/lidar_centerpoint/config/centerpoint_tiny.param.yaml --params-file /home/hyt/ros_ws/awf/install/lidar_centerpoint/share/lidar_centerpoint/config/detection_class_remapper.param.yaml -r ~/input/pointcloud:=/sensing/lidar/pointcloud -r ~/output/objects:=objects'].\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-1-3","title":"Correction method, Check area 1-3","text":"<p>Check to see if <code>cudaErrorInvalidDevice: invalid device ordinal</code> is not showing. If so, reinstall nvidia-driver, cuda, cuDNN, and TensorRT.</p> <pre><code>sudo apt-mark unhold cuda-*\nsudo apt-mark unhold nvidia-*\nsudo apt-mark unhold libcudnn*\nsudo apt-mark unhold libnv*\n\nsudo apt purge cuda-*\nsudo apt purge nvidia-*\nsudo apt purge libcudnn*\nsudo apt purge libnv*\n\n# install nvidia driver and run Autoware's setup-dev-env.sh\n</code></pre>"},{"location":"trouble_shooting/#cause-2_1","title":"Cause 2","text":"<p>Autoware is outputting the topic to be evaluated, but the node cannot subscribe.</p>"},{"location":"trouble_shooting/#example-2-1","title":"Example 2-1","text":"<p>Not obtained due to QoS mismatch</p> <pre><code>[component_container_mt-13] [WARN 1633081042.510824100] [localization.util.random_downsample_filter]: New subscription discovered on topic '/localization/util/downsample/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n[component_container_mt-19] [WARN 1633081042.593132498] [sensing.lidar.occupancy_grid_map_outlier_filter]: New subscription discovered on topic '/sensing/lidar/no_ground/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n[component_container_mt-19] [WARN 1633081042.597116410] [sensing.lidar.concatenate_data]: New subscription discovered on topic '/sensing/lidar/concatenated/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-2-1","title":"Correction method, Check area 2-1","text":"<p>Search for QoS in the terminal or console.log.</p> <p>Check that the version of Autoware and the version of driving_log_replayer are compatible. If you are experiencing this problem using Autoware Foundation main and driving_log_replayer main, please report it in a github issue.</p>"},{"location":"trouble_shooting/#example-2-2","title":"Example 2-2","text":"<p>Not retrieved due to message type mismatch. This occurs because the type output by Autoware is different from the type expected by driving_log_replayer.</p> <p>In June 2024, autoware_auto_msg was changed to autoware_msg. As a result, if the version of autoware and the version of driving_log_replayer do not correspond, this message will appear.</p> <pre><code>[ros2-67] [ERROR] [1717610261.542314281] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610261.721551659] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610261.903905941] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.084860123] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.263855979] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.442275790] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-2-2","title":"Correction method, Check area 2-2","text":"<p>If there are major functionality changes, the required Autoware features (PR numbers, etc.) are listed in driving_log_replayer's ReleaseNotes.md. Check if the required functions are included in the Autoware you are using.</p> <p>If you are using Autoware Foundation's main and driving_log_replayer's main and are experiencing this issue, please report it in an issue on github.</p>"},{"location":"trouble_shooting/#unusually-low-number-of-evaluations","title":"Unusually low number of evaluations","text":""},{"location":"trouble_shooting/#cause-1_2","title":"Cause 1","text":"<p>Due to insufficient PC performance, Autoware is not able to publish the topic at the required period (10 Hz for point clouds).</p>"},{"location":"trouble_shooting/#example-1_1","title":"Example 1","text":"<pre><code>\u276f ros2 topic hz /perception/obstacle_segmentation/pointcloud\n1718083964.779455 [77]       ros2: determined eno1 (udp/10.0.55.137) as highest quality interface, selected for automatic interface.\naverage rate: 5.619\n min: 0.109s max: 0.207s std dev: 0.03246s window: 7\naverage rate: 5.333\n min: 0.109s max: 0.214s std dev: 0.02783s window: 12\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area1","title":"Correction method, Check area1","text":"<p>Check with ros2 topic hz to see if the target topic is being output at the expected period. Note that if play_rate is 0.5, 10*0.5=5, which is normal.</p> <p>If not, lower the play_rate argument in dlr simulation run</p> <pre><code>dlr simulation run -p perception -l play_rate:=0.2\n</code></pre>"},{"location":"trouble_shooting/#cause-2_2","title":"Cause 2","text":"<p>The topic does not appear at the beginning of the simulation, but appears at the end of the simulation. If the ml model has not been converted to an engine in advance, the engine conversion starts when the simulation is executed, and the topic appears after the engine conversion is finished.</p>"},{"location":"trouble_shooting/#example2","title":"Example2","text":"<pre><code>[component_container_mt-52] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +894, GPU +174, now: CPU 1009, GPU 852 (MiB)\n[component_container_mt-52] [I] [TRT] ----------------------------------------------------------------\n[component_container_mt-52] [I] [TRT] Input filename:   /home/autoware/autoware_data/traffic_light_classifier/traffic_light_classifier_mobilenetv2_batch_6.onnx\n[component_container_mt-52] [I] [TRT] ONNX IR version:  0.0.8\n[component_container_mt-52] [I] [TRT] Opset version:    11\n[component_container_mt-52] [I] [TRT] Producer name:    pytorch\n[component_container_mt-52] [I] [TRT] Producer version: 1.13.1\n[component_container_mt-52] [I] [TRT] Domain:\n[component_container_mt-52] [I] [TRT] Model version:    0\n[component_container_mt-52] [I] [TRT] Doc string:\n[component_container_mt-52] [I] [TRT] ----------------------------------------------------------------\n[component_container_mt-52] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 116, GPU 678 (MiB)\n\n[component_container_mt-52] [I] [TRT] Applying optimizations and building TRT CUDA engine. Please wait for a few minutes...\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area-2_1","title":"Correction method, Check area 2","text":"<p>Check if the terminal or console.log outputs a log like the one shown in the example. If so, convert the engine file from onnx in advance before evaluation by driving_Log_replayer.</p> <p>Start logging_simulator.launch.xml with \u201cpermission:=true\u201d and leave it for a while. Or, launch a launch that builds only models.</p> <pre><code># Start logging_simulator.launch.xml and leave it for a while.\nros2 launch autoware_launch logging_simulator.launch.xml map_path:=$HOME/autoware_map/sample-map-planning vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit\n\n# launch lidar_centerpoint with build_only option\nros2 launch lidar_centerpoint lidar_centerpoint.launch.xml model_name:=centerpoint_tiny model_path:=$HOME/autoware_data/lidar_centerpoint model_param_path:=$(ros2 pkg prefix lidar_centerpoint --share)/config/centerpoint_tiny.param.yaml build_only:=true\n</code></pre>"},{"location":"trouble_shooting/#not-terminating-or-terminating-in-the-middle-of-the-process","title":"Not terminating or terminating in the middle of the process","text":""},{"location":"trouble_shooting/#cause_1","title":"Cause","text":"<p>An exception occurs due to unintended input data, etc., and the node stops. or terminate.</p>"},{"location":"trouble_shooting/#example_1","title":"Example","text":"<p>The contents of the object in PERCEPTION were not as expected and an exception was output.</p> <pre><code>[perception_evaluator_node.py-115] [ERROR] [1711460672.978143229] [driving_log_replayer.perception_evaluator]: Unexpected footprint length: len(perception_object.shape.footprint.points)=2\n[perception_evaluator_node.py-115] Exception in thread Thread-2 (run_func):\n[perception_evaluator_node.py-115] Traceback (most recent call last):\n[perception_evaluator_node.py-115]   File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n[perception_evaluator_node.py-115]     self.run()\n[perception_evaluator_node.py-115]   File \"/usr/lib/python3.10/threading.py\", line 953, in run\n[perception_evaluator_node.py-115]     self._target(*self._args, **self._kwargs)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/lib/python3.10/site-packages/tf2_ros/transform_listener.py\", line 95, in run_func\n[perception_evaluator_node.py-115]     self.executor.spin()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 294, in spin\n[perception_evaluator_node.py-115]     self.spin_once()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 739, in spin_once\n[perception_evaluator_node.py-115]     self._spin_once_impl(timeout_sec)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 728, in _spin_once_impl\n[perception_evaluator_node.py-115]     handler, entity, node = self.wait_for_ready_callbacks(timeout_sec=timeout_sec)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 711, in wait_for_ready_callbacks\n[perception_evaluator_node.py-115]     return next(self._cb_iter)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 612, in _wait_for_ready_callbacks\n[perception_evaluator_node.py-115]     raise ExternalShutdownException()\n[perception_evaluator_node.py-115] rclpy.executors.ExternalShutdownException\n[ros2-117] [INFO] [1711460673.168213400] [rosbag2_recorder]: Subscribed to topic '/driving_log_replayer/marker/results'\n[ros2-117] [INFO] [1711460673.174638594] [rosbag2_recorder]: Subscribed to topic '/driving_log_replayer/marker/ground_truth'\n[simple_object_merger_node-69] [INFO] [1711460673.191825620] [sensing.radar.simple_object_merger]: waiting for object msg...\n[perception_evaluator_node.py-115] Traceback (most recent call last):\n[perception_evaluator_node.py-115]   File \"/home/autoware/autoware.proj/install/driving_log_replayer/lib/driving_log_replayer/perception_evaluator_node.py\", line 336, in &lt;module&gt;\n[perception_evaluator_node.py-115]     main()\n[perception_evaluator_node.py-115]   File \"/home/autoware/autoware.proj/install/driving_log_replayer/local/lib/python3.10/dist-packages/driving_log_replayer/evaluator.py\", line 448, in wrapper\n[perception_evaluator_node.py-115]     rclpy.shutdown()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py\", line 126, in shutdown\n[perception_evaluator_node.py-115]     _shutdown(context=context)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/utilities.py\", line 58, in shutdown\n[perception_evaluator_node.py-115]     return context.shutdown()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/context.py\", line 100, in shutdown\n[perception_evaluator_node.py-115]     raise RuntimeError('Context must be initialized before it can be shutdown')\n[perception_evaluator_node.py-115] RuntimeError: Context must be initialized before it can be shutdown\n[perception_evaluator_node.py-115] The following exception was never retrieved: Expected BOUNDING_BOX, but got polygon, which should have footprint.\n</code></pre>"},{"location":"trouble_shooting/#correction-method-check-area_1","title":"Correction method, Check area","text":"<p>Search the terminal you started or console.log for the string of <code>evaluator</code> to see if an exception is output as shown in the example.</p>"},{"location":"use_case/annotationless_perception/","title":"Evaluate Annotationless Perception","text":"<p>Evaluate Autoware's recognition features (perception) without annotations using the perception_online_evaluator.</p> <p>Requires Autoware with the following PR features. https://github.com/autowarefoundation/autoware.universe/pull/6556</p>"},{"location":"use_case/annotationless_perception/#evaluation-method","title":"Evaluation method","text":"<p>The annotationless_perception evaluation is executed by launching the <code>annotationless_perception.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>annotationless_perception_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and the perception module performs recognition.</li> <li>The perception_online_evaluator publishes diagnostic topic to <code>/perception/perception_online_evaluator/metrics</code></li> <li>The evaluation node subscribes to the topic and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/annotationless_perception/#evaluation-results","title":"Evaluation results","text":"<p>The output topic of perception_online_evaluator is in the form of the following sample. topic sample</p> <p>For each subscription, the following judgment results are output for each recognition class.</p> <p>If all classes are normal, the test is successful.</p>"},{"location":"use_case/annotationless_perception/#normal","title":"Normal","text":"<p>The following two values specified in the scenario or launch argument are used to judge</p> <ul> <li>Threshold</li> <li>PassRange(Coefficient to correct threshold)</li> </ul> <p>Success or failure is determined for each status.name in <code>/perception/perception_online_evaluator/metrics</code> according to the following rules. Items for which no threshold is set (min, max, mean) are always judged as normal. Only those items for which a threshold is specified are subject to evaluation.</p>"},{"location":"use_case/annotationless_perception/#min","title":"min","text":"<p>If <code>threshold * lower_limit</code> &lt;= <code>minimum value of min</code> &lt;= <code>threshold * upper_limit</code>, it is assumed to be normal.</p>"},{"location":"use_case/annotationless_perception/#max","title":"max","text":"<p>If <code>threshold * lower_limit</code> &lt;= <code>maximum value of max</code> &lt;= <code>threshold * upper_limit</code>, it is assumed to be normal.</p> <p>Lower limit recommended to be 0.0</p>"},{"location":"use_case/annotationless_perception/#mean","title":"mean","text":"<p>If <code>threshold * lower_limit</code> &lt;= <code>average value of mean</code> &lt;= <code>threshold * upper_limit</code>, it is assumed to be normal.</p>"},{"location":"use_case/annotationless_perception/#metric_value","title":"metric_value","text":"<p>If <code>threshold * lower_limit</code> &lt;= <code>value of metric_value</code> &lt;= <code>threshold * upper_limit</code>, it is assumed to be normal. metric_value is determined by the current topic value only and does not update the values of min, max, and mean metrics.</p> <p>An illustration is shown below.</p> <p></p>"},{"location":"use_case/annotationless_perception/#error","title":"Error","text":"<p>When the normal condition is not met</p>"},{"location":"use_case/annotationless_perception/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/perception_online_evaluator/metrics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/annotationless_perception/#method-of-specifying-conditions","title":"Method of specifying conditions","text":"<p>The conditions can be given in two ways</p>"},{"location":"use_case/annotationless_perception/#describe-in-scenario","title":"Describe in scenario","text":"<pre><code>Evaluation:\n  UseCaseName: annotationless_perception\n  UseCaseFormatVersion: 0.3.0\n  Conditions:\n    ClassConditions:\n      # Describe the conditions for each class. If a class with no conditions is output, only the metrics are calculated. It does not affect the evaluation.\n      # In the sample data, the class of TRUCK is also output, but the condition is not described, so TRUCK is always Success.\n      # When specifying conditions from result.jsonl, only keys described here will be updated.\n      # Even though TRUCK metrics appear in result.jsonl, they are not added to the evaluation condition because the TRUCK key is not specified in this example.\n      CAR: # classification key\n        Threshold:\n          # Keys not described will not be evaluated (will always be a success)\n          lateral_deviation: { max: 0.4, mean: 0.019 }\n          yaw_deviation: { max: 3.1411, mean: 0.05 }\n          predicted_path_deviation_5.00: { max: 16.464, mean: 1.8 }\n          total_objects_count_r60.00_h10.00: { metric_value: 10 }\n        PassRange:\n          min: 0.0-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          max: 0.0-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          mean: 0.5-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          metric_value: 0.9-1.1\n      BUS: # classification key\n        Threshold:\n          # Only lateral_deviation is evaluated.\n          yaw_rate: { max: 0.05 } # Only max is evaluated.\n        PassRange:\n          min: 0.0-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          max: 0.0-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          mean: 0.5-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          metric_value: 0.9-1.1\n</code></pre>"},{"location":"use_case/annotationless_perception/#specify-by-launch-argument","title":"Specify by launch argument","text":"<p>This method is assumed to be used mainly.</p> <p>If the file path of result.jsonl output from past tests is specified, the metrics values from past tests are used as threshold values. The values are updated from result.jsonl only for the thresholds listed in the scenario.</p> <p>The passing range can also be specified as an argument.</p> <p>An image of its use is shown below.</p> <p></p>"},{"location":"use_case/annotationless_perception/#driving-log-replayer-cli","title":"driving-log-replayer-cli","text":"<pre><code>dlr simulation run -p annotationless_perception -l annotationless_threshold_file:=${previous_test_result.jsonl_path} -l 'annotationless_pass_range:={\"KEY1\":VALUE1\"[,\"KEY2\":\"VALUE2\"...]}'\n\n# example\ndlr simulation run -p annotationless_perception -l annotationless_threshold_file:=$HOME/out/annotationless/2024-0314-155106/sample/result.jsonl -l 'annotationless_pass_range:={\"CAR\":{\"min\":\"0.0-1.1\",\"max\":\"0.0-1.2\",\"mean\":\"0.5-1.3\"},\"BUS\":{\"min\":\"0.0-1.1\",\"max\":\"0.0-1.2\",\"mean\":\"0.5-1.3\"}}'\n</code></pre>"},{"location":"use_case/annotationless_perception/#webautocli","title":"WebAutoCLI","text":"<pre><code>webauto ci scenario run --project-id ${project-id} --scenario-id ${scenario-id} --scenario-version-id ${scenario-version-id} --simulator-parameter-overrides 'annotationless_threshold_file=${previous_test_result.jsonl_path},annotationless_pass_range:={\"KEY1\":VALUE1\"[,\"KEY2\":\"VALUE2\"...]}'\n</code></pre>"},{"location":"use_case/annotationless_perception/#autoware-evaluator","title":"Autoware Evaluator","text":"<p>Add to parameters in the simulator configuration in <code>.webauto-ci.yml</code>.</p> <pre><code>simulations:\n  - name: annotationless_perception\n    type: annotationless_perception\n    simulator:\n      deployment:\n        type: container\n        artifact: main\n      runtime:\n        type: simulator/standard1/amd64/medium\n      parameters:\n        annotationless_threshold_file: ${previous_test_result.jsonl_path}\n        annotationless_pass_range:\n          KEY1: VALUE1\n          KEY2: VALUE2\n</code></pre>"},{"location":"use_case/annotationless_perception/#how-to-update-scenario-conditions","title":"How to update scenario conditions","text":"<p>The driving-log-replayer-cli has the ability to run multiple scenarios in succession that exist under the data_directory of a profile. On the other hand, when evaluation conditions are given as arguments, the same arguments are applied to multiple scenarios, which is inconvenient.</p> <p>In the case of local testing using driving-log-replayer-cli, instead of specifying arguments, the following commands are provided so that scenario conditions can be updated as needed.</p> <ul> <li>update-condition command to manually update scenario conditions</li> <li>run's -u option to automatically update scenario conditions after a simulation run</li> </ul> <p>There are two ways to update</p> <ul> <li>existing Update only those items that appear in the scenario</li> <li>all Update all values in the metrics</li> </ul> <pre><code># manual update\ndlr simulation update-condition -s ${scenario_path} -r ${result.jsonl_path} -u ${existing|all}\n\n# automatically update scenario after simulation run\ndlr simulation run -p annotationless_perception -u ${existing|all}\n</code></pre>"},{"location":"use_case/annotationless_perception/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>perception: true</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false / true (default false, set by launch argument)</li> </ul>"},{"location":"use_case/annotationless_perception/#how-to-specify-the-sensing-argument","title":"How to specify the sensing argument","text":""},{"location":"use_case/annotationless_perception/#driving-log-replayer-cli_1","title":"driving-log-replayer-cli","text":"<pre><code>dlr simulation run -p annotationless_perception -l sensing:=true\n</code></pre>"},{"location":"use_case/annotationless_perception/#webautocli_1","title":"WebAutoCLI","text":"<pre><code>webauto ci scenario run --project-id ${project-id} --scenario-id ${scenario-id} --scenario-version-id ${scenario-version-id} --simulator-parameter-overrides 'sensing=true'\n</code></pre>"},{"location":"use_case/annotationless_perception/#autoware-evaluator_1","title":"Autoware Evaluator","text":"<p>Add to parameters in the simulator configuration in <code>.webauto-ci.yml</code>.</p> <pre><code>simulations:\n  - name: annotationless_perception\n    type: annotationless_perception\n    simulator:\n      deployment:\n        type: container\n        artifact: main\n      runtime:\n        type: simulator/standard1/amd64/medium\n      parameters:\n        sensing: \"true\"\n</code></pre>"},{"location":"use_case/annotationless_perception/#simulation","title":"simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/annotationless_perception/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_auto_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_auto_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_auto_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_auto_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_auto_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/annotationless_perception/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/annotationless_perception/#evaluation","title":"evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/annotationless_perception/#scenario-format","title":"Scenario Format","text":"<p>See sample</p>"},{"location":"use_case/annotationless_perception/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <pre><code>{\n  \"Frame\": {\n    \"Ego\": {},\n    \"OBJECT_CLASSIFICATION\": {\n      // Recognized class\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" }, // The results for Total and Frame are the same. The same values are output to make the data structure the same as other evaluations.\n      \"Info\": {\n        \"name_min_max_mean\": { \"min\": \"min value\", \"max\": \"max value\", \"mean\": \"average value\" },\n        \"name_metric_value\": { \"metric_value\": \"value\"},\n        ...\n      },\n      \"Metrics\": {\n        \"name_min_max_mean\": {\n          \"min\": \"Minimum value of min\",\n          \"max\": \"Maximum value of max\",\n          \"mean\": \"Average value of mean\"\n        },\n        ...\n      }\n    }\n  }\n}\n</code></pre> <p>See the figure below for the meaning of items</p> <p></p> <p></p>"},{"location":"use_case/ar_tag_based_localizer/","title":"Evaluate ArTagBasedLocalizer estimation","text":"<p>Evaluate whether Autoware's ArTagBasedLocalizer, a camera based pcd-less localization, is working stably.</p>"},{"location":"use_case/ar_tag_based_localizer/#evaluation-method","title":"Evaluation method","text":"<p>The localization's evaluation is executed by launching the <code>ar_tag_based_localizer.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>ar_tag_based_localizer_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data input from prepared rosbag and performs localization estimation</li> <li>Evaluation node subscribes to Autoware's output topics, determines whether the outputs meet the criteria, and outputs the results</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/ar_tag_based_localizer/#availability-of-artagbasedlocalizer","title":"Availability of ArTagBasedLocalizer","text":"<p>We use the output from <code>ar_tag_based_localizer</code> via <code>/diagnostics</code> to evaluate whether ArTagBasedLocalizer is available.</p> <ul> <li><code>/diagnostics</code></li> </ul>"},{"location":"use_case/ar_tag_based_localizer/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/ar_tag_based_localizer/#artagbasedlocalizer-availability-normal","title":"ArTagBasedLocalizer Availability Normal","text":"<p>Information related to the monitored topic is extracted from <code>/diagnostics</code> which Component State Monitor outputs. If the most recent information of \"Number of Detected AR Tags\" is greater than or equal to 0, it is considered as pass.</p>"},{"location":"use_case/ar_tag_based_localizer/#artagbasedlocalizer-availability-error","title":"ArTagBasedLocalizer Availability Error","text":"<p>The ArTagBasedLocalizer availability evaluation output is marked as <code>Error</code> when conditions for <code>ArTagBasedLocalizer Availability Normal</code> are not met.</p>"},{"location":"use_case/ar_tag_based_localizer/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/ar_tag_based_localizer/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /api/localization/initialize InitializeLocalization"},{"location":"use_case/ar_tag_based_localizer/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"use_case/ar_tag_based_localizer/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/ar_tag_based_localizer/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The following example shows the topic list available in evaluation input rosbag.</p> Topic name Data type /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/ar_tag_based_localizer/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must NOT be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/ar_tag_based_localizer/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/ar_tag_based_localizer/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/ar_tag_based_localizer/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>Examples of each evaluation are described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Availability Result example:</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"use_case/eagleye/","title":"Evaluate Eagleye estimation","text":"<p>Evaluate whether Eagleye, a GNSS-IMU based map-less localization, is working stably.</p>"},{"location":"use_case/eagleye/#evaluation-method","title":"Evaluation method","text":"<p>The localization's evaluation is executed by launching the <code>eagleye.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>eagleye_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data input from prepared rosbag and performs localization estimation</li> <li>Evaluation node subscribes to Autoware's output topics, determines whether the outputs meet the criteria, and outputs the results</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/eagleye/#availability-of-eagleye","title":"Availability of Eagleye","text":"<p>We use the output from <code>eagleye_monitor</code> via <code>/diagnostics</code> to evaluate whether Eagleye is available.</p> <ul> <li><code>/diagnostics</code></li> </ul>"},{"location":"use_case/eagleye/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/eagleye/#eagleye-availability-normal","title":"Eagleye Availability Normal","text":"<p>Information related to the monitored topic is extracted from <code>/diagnostics</code> which Component State Monitor outputs. If the most recent information is \"OK\", it is considered as pass.</p>"},{"location":"use_case/eagleye/#eagleye-availability-error","title":"Eagleye Availability Error","text":"<p>The Eagleye availability evaluation output is marked as <code>Error</code> when conditions for <code>Eagleye Availability Normal</code> are not met.</p>"},{"location":"use_case/eagleye/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/eagleye/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /api/localization/initialize InitializeLocalization"},{"location":"use_case/eagleye/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"use_case/eagleye/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/eagleye/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The following example shows the topic list available in evaluation input rosbag.</p> Topic name Data type /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/eagleye/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must NOT be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/eagleye/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/eagleye/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/eagleye/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>Examples of each evaluation are described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Availability Result example:</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"use_case/","title":"Evaluation Use Cases","text":"<p>This section describes how driving_log_replayer can be used for evaluation.</p>"},{"location":"use_case/#list-of-driving-log-replayer-use-cases","title":"List of Driving Log Replayer use cases","text":"<ul> <li>Localization</li> <li>YabLoc</li> <li>Eagleye</li> <li>AR-Tag Based Localizer</li> <li>Obstacle Segmentation</li> <li>Perception</li> <li>Performance Diag</li> <li>Annotationless Perception</li> </ul>"},{"location":"use_case/localization/","title":"Evaluate NDT estimation","text":"<p>Evaluate whether Autoware's localization by NDT is working stably.</p> <p>In the evaluation of NDT, the reliability, convergence, and availability of NDT are evaluated.</p>"},{"location":"use_case/localization/#evaluation-method","title":"Evaluation method","text":"<p>The localization's evaluation is executed by launching the <code>localization.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>localization_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data input from previously prepared rosbag and performs localization estimation</li> <li>Evaluation node subscribes to Autoware's output topics, determines whether NDT reliability, convergence, and availability meet the criteria, and dumps the results to a file</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/localization/#reliability-of-ndt","title":"Reliability of NDT","text":"<p>Of the following two topics, the one specified in the scenario will be used for evaluation.</p> <ul> <li><code>/localization/pose_estimator/transform_probability</code></li> <li><code>/localization/pose_estimator/nearest_voxel_transformation_likelihood</code></li> </ul>"},{"location":"use_case/localization/#convergence-of-ndt","title":"Convergence of NDT","text":"<p>Convergence evaluation is based on the following topics:</p> <ul> <li><code>/localization/pose_estimator/initial_to_result_relative_pose</code></li> </ul>"},{"location":"use_case/localization/#availability-of-ndt","title":"Availability of NDT","text":"<p>We also evaluate whether the output of <code>ndt_scan_matcher</code> is available. This is mainly useful for detecting some cases where NDT is not capable of publishing the appropriate outputs, for example due to:</p> <ul> <li>failure in <code>pointcloud_preprocessor</code> due to runtime error (which would result in unavailability of LiDAR scan inputs for <code>ndt_scan_matcher</code>)</li> <li>failure in <code>ndt_scan_matcher</code> due to runtime error</li> </ul> <p>Here we evaluate whether the following output is being output regularly:</p> <ul> <li><code>/localization/pose_estimator/exe_time_ms</code></li> </ul> <p>This is accomplished by indirectly using a package within Autoware called Component State Monitor. The evaluator subscribes the following topic for the information:</p> <ul> <li><code>/diagnostics</code></li> </ul> <p>The reason why <code>/localization/pose_estimator/exe_time_ms</code> was chosen from the output topics of NDT is that it is possible to detect the aforementioned failure by confirming that messages are being output to the topic regularly. For example, <code>/localization/pose_estimator/pose</code> is not suitable as a monitoring topic this time. This is because the topic may not output if the score of NVTL or TP is low, and it is difficult to isolate the cause to the failure by just monitoring the output.</p>"},{"location":"use_case/localization/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/localization/#reliability-normal","title":"Reliability Normal","text":"<p>If the data in <code>/localization/pose_estimator/transform_probability</code> or <code>/localization/pose_estimator/nearest_voxel_transformation_likelihood</code> is greater than or equal the <code>AllowableLikelihood</code> described in the scenario.</p>"},{"location":"use_case/localization/#reliability-error","title":"Reliability Error","text":"<p>If the data in <code>/localization/pose_estimator/transform_probability</code> or <code>/localization/pose_estimator/nearest_voxel_transformation_likelihood</code> is less than the <code>AllowableLikelihood</code> described in the scenario.</p>"},{"location":"use_case/localization/#convergence-normal","title":"Convergence Normal","text":"<p>If all of the following conditions are met, the convergence is reported as Normal:</p> <ol> <li>The lateral distance of <code>/localization/pose_estimator/initial_to_result_relative_pose</code> is less than or equal to <code>AllowableDistance</code> described in the scenario</li> <li>Execution time published to <code>/localization/pose_estimator/exe_time_ms</code> is less than or equal to <code>AllowableExeTimeMs</code> described in the scenario</li> <li>Number of iterations published to <code>/localization/pose_estimator/iteration_num</code> is less than or equal to <code>AllowableIterationNum</code> described in the scenario</li> </ol> <p>The lateral distance obtained in the step 1 is published as <code>/driving_log_replayer/localization/lateral_distance</code>.</p>"},{"location":"use_case/localization/#convergence-error","title":"Convergence Error","text":"<p>The convergence evaluation output is marked as <code>Error</code> when conditions for <code>Convergence Normal</code> are not met.</p>"},{"location":"use_case/localization/#ndt-availability-normal","title":"NDT Availability Normal","text":"<p>Information related to the monitored topic is extracted from <code>/diagnostics</code> which Component State Monitor outputs. If the most recent information NOT Timeout nor NotReceived, it is considered as pass.</p>"},{"location":"use_case/localization/#ndt-availability-error","title":"NDT Availability Error","text":"<p>The NDT availability evaluation output is marked as <code>Error</code> when conditions for <code>NDT Availability Normal</code> are not met.</p>"},{"location":"use_case/localization/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray /localization/pose_estimator/transform_probability autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/nearest_voxel_transformation_likelihood autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/initial_to_result_relative_pose geometry_msgs::msg::PoseStamped /localization/pose_estimator/exe_time_ms autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/iteration_num autoware_internal_debug_msgs::msg::Int32Stamped /tf tf2_msgs/msg/TFMessage /localization/util/downsample/pointcloud sensor_msgs::msg::PointCloud2 /localization/pose_estimator/points_aligned sensor_msgs::msg::PointCloud2 <p>Published topics:</p> Topic name Data type /driving_log_replayer/localization/lateral_distance example_interfaces::msg::Float64"},{"location":"use_case/localization/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /api/localization/initialize InitializeLocalization"},{"location":"use_case/localization/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"use_case/localization/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/localization/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs are used in a real-world vehicle configuration.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/localization/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/localization/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/localization/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/localization/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>Since localization evaluates convergence, reliability, and availability, each line contains the result of convergence, reliability, or availability. The Result is <code>true</code> if convergence, reliability, and availability all pass, and <code>false</code> otherwise.</p> <p>Examples of each evaluation are described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Convergence Result example:</p> <pre><code>{\n  \"Convergence\": {\n    \"Result\": \"Success or Fail\",\n    \"Info\": {\n      \"LateralDistance\": \"initial_to_result_relative_pose.pose.position.y\",\n      \"HorizontalDistance\": \"Horizontal distance of initial_to_result_relative_pose.pose.position\",\n      \"ExeTimeMs\": \"Time taken to calculate ndt\",\n      \"IterationNum\": \"Number of recalculations of ndt\"\n    }\n  }\n}\n</code></pre> <p>Reliability Result example:</p> <pre><code>{\n  \"Reliability\": {\n    \"Result\": \"Success or Fail\",\n    \"Info\": {\n      \"Value\": {\n        \"stamp\": {\n          \"sec\": \"sec of stamp\",\n          \"nanosec\": \"nanosec of stamp\"\n        },\n        \"data\": \"Value of NVTL or TP\"\n      },\n      \"Reference\": {\n        \"stamp\": {\n          \"sec\": \"sec of stamp\",\n          \"nanosec\": \"nanosec of stamp\"\n        },\n        \"data\": \"Likelihood not used in the evaluation. Reference value; if Value is NVTL, TP is entered.\"\n      }\n    }\n  }\n}\n</code></pre> <p>Availability Result example:</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"use_case/obstacle_segmentation/","title":"Evaluate point cloud generation","text":"<p>Evaluate if the Autoware point cloud generation process (if there is a connection between sensing and perception nodes) runs, and if data is being published to the <code>/perception/obstacle_segmentation/pointcloud</code> topic as intended.</p> <p>The following evaluations are performed simultaneously to check if point cloud published by perception nodes is valid.</p> <ul> <li>Check whether vehicles, pedestrians and other traffic participants, annotated in advance, are detected (detection step).</li> <li>Check whether extra point clouds appear in the overlapping area between the lane and the polygons around the vehicle defined in the scenario (non_detection step).</li> </ul> <p>It is also possible not to evaluate if null is specified as the evaluation condition. In other words, evaluation can be performed in the following three modes.</p> <ol> <li>evaluate detection and non_detection at the same time</li> <li>evaluate only detection (NonDetection: null)</li> <li>Evaluate only non_detection (Detection: null)</li> </ol> <p>The recommended annotation tool is Deepen, but any tool that supports conversion to <code>t4_dataset</code> format can be used. Multiple annotation tools can be used as long as a conversion tool can be created.</p>"},{"location":"use_case/obstacle_segmentation/#evaluation-method","title":"Evaluation method","text":"<p>The obstacle segmentation evaluation is executed by launching the <code>obstacle_segmentation.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>obstacle_segmentation_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and outputs <code>/perception/obstacle_segmentation/pointcloud</code> topic.</li> <li>The evaluation node subscribes <code>/perception/obstacle_segmentation/pointcloud</code> topic and calculates the polygon of the non-detection area at the time specified in the header.</li> <li>The evaluation node passes the point cloud and the polygon of the non-detected area to perception_eval for evaluation. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/obstacle_segmentation/#how-to-calculate-polygon-for-non-detectable-area","title":"How to calculate polygon for non-detectable area","text":"<p>The non-detect area is calculated as the area where the polygon given in the scenario overlaps with the road_lanelet. It is calculated according to the following steps:</p> <ol> <li>get the transform of map_to_base_link at the time of the header.stamp in pointcloud, and transform the polygon to the map coordinate system.</li> <li>get the road_lanelet in the range of search_range (see the figure below) from the point where the vehicle is.</li> <li>take the intersection of the road_lanelet and polygon obtained in step 2.</li> <li>return the array of polygons obtained in step 3 to the base_link coordinate system (to match the coordinate system to filter the pointcloud).</li> </ol> <p></p> <p>In step 2, by narrowing down to the lanelets in the range where polygons can exist, the intersection process with lanelets that are obvious to return empty polygons in step 3 is omitted.</p>"},{"location":"use_case/obstacle_segmentation/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/obstacle_segmentation/#detection-normal","title":"Detection Normal","text":"<p>If all of the following conditions are met, the evaluation is reported as normal:</p> <ol> <li>A bounding box with the UUID specified in the scenario must contain a point cloud (topic <code>/perception/obstacle_segmentation/pointcloud</code>) with at least a number of points equal to the specified number.<ul> <li>If multiple UUIDs are specified, the condition must be satisfied for all the specified bounding boxes.</li> </ul> </li> <li>The output rate of the point cloud cannot be in error state (this data is provided by Autoware's diagnostic function). The default frequency value is 1.0Hz.</li> </ol>"},{"location":"use_case/obstacle_segmentation/#detection-warning","title":"Detection Warning","text":"<p>The state is achieved when the visibility of the bounding box with the UUID specified in the scenario is none (bounding box is occluded) and cannot be evaluated.</p>"},{"location":"use_case/obstacle_segmentation/#detection-error","title":"Detection Error","text":"<p>The detection state is <code>Error</code> when neither conditions for <code>Normal</code> nor <code>Warning</code> state cannot be met.</p>"},{"location":"use_case/obstacle_segmentation/#non-detection-normal","title":"Non-Detection Normal","text":"<p>The state is <code>Normal</code> when no point is contained in the non-detection area, which is calculated by the node in step 3 of the evaluation method.</p>"},{"location":"use_case/obstacle_segmentation/#non-detection-error","title":"Non-Detection Error","text":"<p>The state is <code>Error</code> when any point was found in the non-detection area.</p>"},{"location":"use_case/obstacle_segmentation/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/obstacle_segmentation/pointcloud sensor_msgs::msg::PointCloud2 /diagnostics diagnostic_msgs::msg::DiagnosticArray /tf tf2_msgs/msg/TFMessage /planning/scenario_planning/status/stop_reasons tier4_planning_msgs::msg::StopReasonArray /planning/scenario_planning/trajectory autoware_planning_msgs::msg::Trajectory <p>Published topics:</p> Topic name Data type /driving_log_replayer/marker/detection visualization_msgs::msg::MarkerArray /driving_log_replayer/marker/non_detection visualization_msgs::msg::MarkerArray /driving_log_replayer/pcd/detection sensor_msgs::msg::PointCloud2 /driving_log_replayer/pcd/non_detection sensor_msgs::msg::PointCloud2 /planning/mission_planning/goal geometry_msgs::msg::PoseStamped"},{"location":"use_case/obstacle_segmentation/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>localization: false</li> <li>control: false</li> </ul>"},{"location":"use_case/obstacle_segmentation/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/obstacle_segmentation/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Must contain the required topics in <code>t4_dataset</code> format.</p> <p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state Type: nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /localization/kinematic_state Type: nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/obstacle_segmentation/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/obstacle_segmentation/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/obstacle_segmentation/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/obstacle_segmentation/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>In <code>obstacle_segmentation</code> evaluation scenario, two types of checks, detection (Detection) and non-detection (NonDetection), are evaluated. Although they are evaluated simultaneously, in one callback function, they are counted separately. The <code>Result</code> is <code>true</code> if both detection and non-detection evaluation steps have passed. Otherwise the <code>Result</code> is <code>false</code>.</p> <p>An example of evaluation is described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"Frame number of t4_dataset used for evaluation\",\n    \"FrameSkip\": \"Number of times that an object was requested to be evaluated but the evaluation was skipped because there was no ground truth in the dataset within 75msec\",\n    \"StopReasons\": \"Reasons for stopping output by the Planning module. Reference value\",\n    \"TopicRate\": \"Result of diag indicating whether the output rate of the point cloud is normal or not.\",\n    \"Detection\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, Warn or Invalid\" },\n      \"Info\": {\n        \"DetectionSuccess or DetectionFail or DetectionWarn\": {\n          \"Annotation\": {\n            \"Scale\": {\n              \"x\": \"Length of bounding box in x-direction\",\n              \"y\": \"Length of bounding box in y-direction\",\n              \"z\": \"Length of bounding box in z-direction\"\n            },\n            \"Position\": {\n              \"position\": {\n                \"x\": \"Bounding box position x\",\n                \"y\": \"Bounding box position y\",\n                \"z\": \"Bounding box position z\"\n              },\n              \"orientation\": {\n                \"x\": \"Bounding box direction x\",\n                \"y\": \"Bounding box direction y\",\n                \"z\": \"Bounding box direction z\",\n                \"w\": \"Bounding box direction w\"\n              }\n            },\n            \"UUID\": \"UUID of the bounding box\",\n            \"StampFloat\": \"Bounding box unix_time[us] made into a float.\"\n          },\n          \"PointCloud\": {\n            \"NumPoints\": \"Number of point clouds contained within the bounding box.\",\n            \"Nearest\": \"[x,y,z] coordinates of the closest point in the bounding box from the base_link\",\n            \"Stamp\": {\n              \"sec\": \"Sec of header.stamp of the point cloud\",\n              \"nanosec\": \"NanoSec of header.stamp of the point cloud\"\n            }\n          }\n        }\n      }\n    },\n    \"NonDetection\": {\n      \"Result\": \"Success, Fail, or Invalid\",\n      \"Info\": {\n        \"PointCloud\": {\n          \"NumPoints\": \"Number of point clouds out in non-detected areas.\",\n          \"Distance\": {\n            \"0-1\": \"Number of point clouds out in non-detected areas between 0-1 m from base_link\",\n            \"x-x+1\": \"Distribution of point clouds appearing in non-detected areas by distance\",\n            \"99-100\": \"Number of point clouds out in non-detected areas between 99-100 m from base_link\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/perception/","title":"Evaluate perception","text":"<p>The performance of Autoware's recognition function (perception) is evaluated by calculating mAP (mean Average Precision) and other indices from the recognition results.</p> <p>Run the perception module and pass the output perception topic to the evaluation library for evaluation.</p> <p>Since it is activated in the perception_mode described in the scenario, change the scenario if you want to change the sensor to be evaluated.</p>"},{"location":"use_case/perception/#preparation","title":"Preparation","text":"<p>In perception evaluation, machine learning pre-trained models are used. If the model is not prepared in advance, Autoware will not output recognition results. If no evaluation results are produced, check to see if this has been done correctly.</p>"},{"location":"use_case/perception/#downloading-model-files","title":"Downloading Model Files","text":"<p>Models are downloaded during Autoware setup. The method of downloading models depends on the version of Autoware you are using, so check which method is used. The following patterns exist.</p>"},{"location":"use_case/perception/#download-with-ansible","title":"Download with ansible","text":"<p>When you run the ansible setup script, you will see <code>Download artifacts? [y/N]</code>, type <code>y</code> and press enter (Autoware foundation's main branch use this method) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"use_case/perception/#automatically-downloaded-when-the-package-is-built","title":"Automatically downloaded when the package is built","text":"<p>If you are using a slightly older Autoware.universe, this is the one to use, until the commit hash of <code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>. lidar_centerpoint/CMakeList.txt</p>"},{"location":"use_case/perception/#conversion-of-model-files","title":"Conversion of model files","text":"<p>The downloaded onnx file is not to be used as-is, but to be converted to a TensorRT engine file for use. A conversion command is available, so source the autoware workspace and execute the command.</p> <p>Let's assume that autoware is installed in <code>$HOME/autoware</code>.</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch lidar_centerpoint lidar_centerpoint.launch.xml build_only:=true\n</code></pre> <p>When the conversion command finishes, the engine file is output. The output destination changes according to the model download method, so check that the output is in the appropriate directory.</p>"},{"location":"use_case/perception/#download-with-ansible_1","title":"Download with ansible","text":"<p>An example of the use of autowarefoundation's autoware.universe is shown below.</p> <p>The following file is output.</p> <pre><code>$HOME/autoware_data/lidar_centerpoint/pts_backbone_neck_head_centerpoint_tiny.engine\n$HOME/autoware_data/lidar_centerpoint/pts_voxel_encoder_centerpoint_tiny.engine\n</code></pre>"},{"location":"use_case/perception/#automatic-download-at-package-build-time","title":"Automatic download at package build time","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data/pts_backbone_neck_head_centerpoint_tiny.engine\n$HOME/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data/pts_voxel_encoder_centerpoint_tiny.engine\n</code></pre>"},{"location":"use_case/perception/#evaluation-method","title":"Evaluation method","text":"<p>The perception evaluation is executed by launching the <code>perception.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>perception_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and outputs point cloud data, and the perception module performs recognition.</li> <li>The evaluation node subscribes to <code>/perception/object_recognition/{detection, tracking}/objects</code> and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/perception/#evaluation-results","title":"Evaluation results","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/perception/#perception-normal","title":"Perception Normal","text":"<p>Satisfy Criteria in the Criterion tag of the scenario.</p> <p>The scenario.yaml of the sample is as follows,</p> <pre><code>Criterion:\n  - PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n    CriteriaMethod: num_gt_tp # refer https://github.com/tier4/driving_log_replayer/blob/develop/driving_log_replayer/driving_log_replayer/criteria/perception.py#L136-L152\n    CriteriaLevel: hard # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)\n    Filter:\n      Distance: 0.0-50.0 # [m] null [Do not filter by distance] or lower_limit-(upper_limit) [Upper limit can be omitted. If omitted value is 1.7976931348623157e+308]\n  - PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n    CriteriaMethod: num_gt_tp # refer https://github.com/tier4/driving_log_replayer/blob/develop/driving_log_replayer/driving_log_replayer/criteria/perception.py#L136-L152\n    CriteriaLevel: easy # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)\n    Filter:\n      Distance: 50.0- # [m] null [Do not filter by distance] or lower_limit-(upper_limit) [Upper limit can be omitted. If omitted value is 1.7976931348623157e+308]\n</code></pre> <ul> <li>For each subscription of <code>/perception/object_recognition/{detection, tracking}/objects</code>, the number of objects in tp is hard (75.0%) or more for objects at a distance of 0.0-50.0[m]. Frame of Result becomes Success.</li> <li>For one subscription of <code>/perception/object_recognition/{detection, tracking}/objects</code>, the number of objects in tp is easy (25.0%) or more for objects at a distance of 50.0-1.7976931348623157e+308[m]. Frame of Result becomes Success.</li> <li>If the condition <code>PassRate &gt;= Normal / Total Received * 100</code> is satisfied, the Total of Result becomes Success.</li> </ul>"},{"location":"use_case/perception/#perception-error","title":"Perception Error","text":"<p>The perception evaluation output is marked as <code>Error</code> when condition for <code>Normal</code> is not met.</p>"},{"location":"use_case/perception/#skipping-evaluation","title":"Skipping evaluation","text":"<p>Only add 1 to FrameSkip in the following cases. FrameSkip is a counter for the number of times evaluation is skipped.</p> <ul> <li>No Ground Truth exists within 75msec before or after the received object's header time.</li> <li>If the number of footprint.points of the received object is 1 or 2 (this condition will be removed when \"perception_eval\" is updated)</li> </ul>"},{"location":"use_case/perception/#skipping-evaluationnogtnoobject","title":"Skipping evaluation(NoGTNoObject)","text":"<ul> <li>When the Ground Truth and the recognition objects are filtered by the filter condition and not evaluated (when the content of the evaluation result PassFail object is empty).</li> </ul>"},{"location":"use_case/perception/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/object_recognition/detection/objects autoware_perception_msgs/msg/DetectedObjects /perception/object_recognition/tracking/objects autoware_perception_msgs/msg/TrackedObjects <p>Published topics:</p> Topic name Data type /driving_log_replayer/marker/ground_truth visualization_msgs::msg::MarkerArray /driving_log_replayer/marker/results visualization_msgs::msg::MarkerArray"},{"location":"use_case/perception/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false / true (default value is false. Specify by <code>LaunchSensing</code> key for each t4_dataset in the scenario)</li> </ul> <p>NOTE: The <code>tf</code> in the bag is used to align the localization during annotation and simulation. Therefore, localization is invalid.</p>"},{"location":"use_case/perception/#dependent-libraries","title":"Dependent libraries","text":"<p>The perception evaluation step bases on the perception_eval library.</p>"},{"location":"use_case/perception/#division-of-roles-of-driving_log_replayer-with-dependent-libraries","title":"Division of roles of driving_log_replayer with dependent libraries","text":"<p><code>driving_log_replayer</code> package is in charge of the connection with ROS. The actual perception evaluation is conducted in perception_eval library. The perception_eval is a ROS-independent library, it cannot receive ROS objects. Also, ROS timestamps use nanoseconds while the <code>t4_dataset</code> format is based on milliseconds (because it uses <code>nuScenes</code>), so the values must be properly converted before using the library's functions.</p> <p><code>driving_log_replayer</code> subscribes the topic output from the perception module of Autoware, converts it to the data format defined in perception_eval, and passes it on. It is also responsible for publishing and visualizing the evaluation results from perception_eval on proper ROS topic.</p> <p>perception_eval is in charge of the part that compares the detection results passed from <code>driving_log_replayer</code> with ground truth data, calculates the index, and outputs the results.</p>"},{"location":"use_case/perception/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/perception/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Must contain the required topics in <code>t4_dataset</code> format.</p> <p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs and Cameras are used in a real-world vehicle configuration.</p> <p>/sensing/lidar/concatenated/pointcloud is used if the scenario LaunchSensing: false.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state nav_msgs/msg/Odometry /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /localization/kinematic_state nav_msgs/msg/Odometry /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/perception/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/perception/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/perception/#scenario-format","title":"Scenario Format","text":"<p>There are two types of evaluation: use case evaluation and database evaluation. Use case evaluation is performed on a single dataset, while database evaluation uses multiple datasets and takes the average of the results for each dataset.</p> <p>In the database evaluation, the <code>vehicle_id</code> should be able to be set for each data set, since the calibration values may change. Also, it is necessary to set whether or not to activate the sensing module.</p> <p>See sample.</p>"},{"location":"use_case/perception/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>The evaluation results by perception_eval under the conditions specified in the scenario are output for each frame. Only the final line has a different format from the other lines since the final metrics are calculated after all data has been flushed.</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Format of each frame:</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"Frame number of t4_dataset used for evaluation\",\n    \"FrameSkip\": \"The total number of times the evaluation was skipped, which occurs when the evaluation of an object is requested but there is no Ground Truth in the dataset within 75msec, or when the number of footprint.points is 1 or 2.\",\n    \"criteria0\": {\n      // result of criteria 0, If the Ground Truth and recognition objects exist\n      \"PassFail\": {\n        \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n        \"Info\": {\n          \"TP\": \"Number of filtered objects determined to be TP\",\n          \"FP\": \"Number of filtered objects determined to be FP\",\n          \"FN\": \"Number of filtered objects determined to be FN\"\n        },\n        \"Objects\": {\n          // Evaluated objects information. See the [json schema](../../driving_log_replayer/config/object_output_schema.json) for details.\n        }\n      }\n    },\n    \"criteria1\": {\n      // result of criteria 1. If the Ground Truth and the recognition objects do not exist\n      \"NoGTNoObj\": \"Number of times that the Ground Truth and the recognition objects were filtered and could not be evaluated.\"\n    }\n  }\n}\n</code></pre> <p>Warning Data Format:</p> <pre><code>{\n  \"Frame\": {\n    \"Warning\": \"Warning Message\",\n    \"FrameSkip\": \"The total number of times the evaluation was skipped, which occurs when the evaluation of an object is requested but there is no Ground Truth in the dataset within 75msec, or when the number of footprint.points is 1 or 2.\"\n  }\n}\n</code></pre> <p>Objects Data Format:</p> <p>See json schema</p> <p>Metrics Data Format:</p> <p>When the <code>evaluation_task</code> is detection or tracking</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"TP rate for all labels\",\n          \"label0\": \"TP rate of label0\",\n          \"label1\": \"TP rate of label1\"\n        },\n        \"FP\": {\n          \"ALL\": \"FP rate for all labels\",\n          \"label0\": \"FP rate of label0\",\n          \"label1\": \"FP rate of label1\"\n        },\n        \"FN\": {\n          \"ALL\": \"FN rate for all labels\",\n          \"label0\": \"FN rate of label0\",\n          \"label1\": \"FN rate of label1\"\n        },\n        \"TN\": {\n          \"ALL\": \"TN rate for all labels\",\n          \"label0\": \"TN rate of label0\",\n          \"label1\": \"TN rate of label1\"\n        },\n        \"AP(Center Distance)\": {\n          \"ALL\": \"AP(Center Distance) rate for all labels\",\n          \"label0\": \"AP(Center Distance) rate of label0\",\n          \"label1\": \"AP(Center Distance) rate of label1\"\n        },\n        \"APH(Center Distance)\": {\n          \"ALL\": \"APH(Center Distance) rate for all labels\",\n          \"label0\": \"APH(Center Distance) rate of label0\",\n          \"label1\": \"APH(Center Distance) rate of label1\"\n        },\n        \"AP(IoU 2D)\": {\n          \"ALL\": \"AP(IoU 2D) rate for all labels\",\n          \"label0\": \"AP(IoU 2D) rate of label0\",\n          \"label1\": \"AP(IoU 2D) rate of label1\"\n        },\n        \"APH(IoU 2D)\": {\n          \"ALL\": \"APH(IoU 2D) rate for all labels\",\n          \"label0\": \"APH(IoU 2D) rate of label0\",\n          \"label1\": \"APH(IoU 2D) rate of label1\"\n        },\n        \"AP(IoU 3D)\": {\n          \"ALL\": \"AP(IoU 3D) rate for all labels\",\n          \"label0\": \"AP(IoU 3D) rate of label0\",\n          \"label1\": \"AP(IoU 3D) rate of label1\"\n        },\n        \"APH(IoU 3D)\": {\n          \"ALL\": \"APH(IoU 3D) rate for all labels\",\n          \"label0\": \"APH(IoU 3D) rate of label0\",\n          \"label1\": \"APH(IoU 3D) rate of label1\"\n        },\n        \"AP(Plane Distance)\": {\n          \"ALL\": \"AP(Plane Distance) rate for all labels\",\n          \"label0\": \"AP(Plane Distance) rate of label0\",\n          \"label1\": \"AP(Plane Distance) rate of label1\"\n        },\n        \"APH(Plane Distance)\": {\n          \"ALL\": \"APH(Plane Distance) rate for all labels\",\n          \"label0\": \"APH(Plane Distance) rate of label0\",\n          \"label1\": \"APH(Plane Distance) rate of label1\"\n        }\n      },\n      \"MOTA\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/en/perception/metrics.md#tracking\"},\n      \"MOTA\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/en/perception/metrics.md#tracking\"},\n      \"IDswitch\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/en/perception/metrics.md#id-switch\"},\n      \"Error\": {\n        \"ALL\": {\n          \"average\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          },\n          \"rms\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          },\n          \"std\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          },\n          \"max\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          },\n          \"min\": {\n            \"x\": \"x position\",\n            \"y\": \"y position\",\n            \"yaw\": \"yaw\",\n            \"length\": \"length\",\n            \"width\": \"width\",\n            \"vx\": \"x velocity\",\n            \"vy\": \"y velocity\",\n            \"nn_plane\": \"Nearest neighbor plane distance\"\n          }\n        },\n        \"label0\": \"Error metrics for the label0\"\n      }\n    }\n  }\n}\n</code></pre> <p>When the <code>evaluation_task</code> is fp_validation</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"GroundTruthStatus\": {\n        \"UUID\": {\n          \"rate\": {\n            \"TP\": \"TP rate of the displyed UUID\",\n            \"FP\": \"FP rate of the displyed UUID\",\n            \"TN\": \"TN rate of the displyed UUID\",\n            \"FN\": \"FN rate of the displyed UUID\"\n          },\n          \"frame_nums\": {\n            \"total\": \"List of frame numbers, which GT is evaluated\",\n            \"TP\": \"List of frame numbers, which GT is evaluated as TP\",\n            \"FP\": \"List of frame numbers, which GT is evaluated as FP\",\n            \"TN\": \"List of frame numbers, which GT is evaluated as TN\",\n            \"FN\": \"List of frame numbers, which GT is evaluated as FN\"\n          }\n        }\n      },\n      \"Scene\": {\n        \"TP\": \"TP rate of the scene\",\n        \"FP\": \"FP rate of the scene\",\n        \"TN\": \"TN rate of the scene\",\n        \"FN\": \"FN rate of the scene\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/perception/#pickle-file","title":"pickle file","text":"<p>In database evaluation, it is necessary to replay multiple rosbags, but due to the ROS specification, it is impossible to use multiple bags in a single launch. Since one rosbag, i.e., one <code>t4_dataset</code>, requires one launch, it is necessary to execute as many launches as the number of datasets contained in the database evaluation.</p> <p>Since database evaluation cannot be done in a single launch, perception outputs a file <code>scene_result.pkl</code> in addition to <code>result.jsonl</code> file. A pickle file is a python object saved as a file, PerceptionEvaluationManager.frame_results of perception_eval. The dataset evaluation can be performed by reading all the objects recorded in the pickle file and outputting the index of the dataset's average.</p>"},{"location":"use_case/perception/#result-file-of-database-evaluation","title":"Result file of database evaluation","text":"<p>In the case of a database evaluation with multiple datasets in the scenario, a file named <code>database_result.json</code> is output to the results directory.</p> <p>The format is the same as the Metrics Data Format.</p>"},{"location":"use_case/perception_2d/","title":"Evaluate perception(Camera)","text":"<p>The performance of Autoware's recognition function (perception) is evaluated by calculating mAP (mean Average Precision) and other indices from the recognition results.</p> <p>Run the perception module and pass the output perception topic to the evaluation library for evaluation.</p>"},{"location":"use_case/perception_2d/#preparation","title":"Preparation","text":"<p>In perception evaluation, machine-learning pre-trained models are used. If the model is not prepared in advance, Autoware will not output recognition results. If no evaluation results are produced, check to see if this has been done correctly.</p>"},{"location":"use_case/perception_2d/#downloading-model-files","title":"Downloading Model Files","text":"<p>Models are downloaded during Autoware setup. The method of downloading models depends on the version of Autoware you are using, so check which method is used. The following patterns exist.</p>"},{"location":"use_case/perception_2d/#download-with-ansible","title":"Download with ansible","text":"<p>When you run the ansible setup script, you will see <code>Download artifacts? [y/N]</code>, type <code>y</code> and press enter (Autoware foundation's main branch use this method) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"use_case/perception_2d/#automatically-downloaded-when-the-package-is-built","title":"Automatically downloaded when the package is built","text":"<p>If you are using a slightly older Autoware.universe, this is the one to use, until the commit hash of <code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>. tensorrt_yolox/CMakeList.txt</p>"},{"location":"use_case/perception_2d/#conversion-of-model-files","title":"Conversion of model files","text":"<p>The downloaded onnx file is not to be used as-is, but to be converted to a TensorRT engine file for use. A conversion command is available, so source the autoware workspace and execute the command.</p> <p>Let's assume that autoware is installed in <code>$HOME/autoware</code>.</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch tensorrt_yolox yolox.launch.xml use_decompress:=false build_only:=true\n</code></pre> <p>When the conversion command finishes, the engine file is output. The output destination changes according to the model download method, so check that the output is in the appropriate directory.</p>"},{"location":"use_case/perception_2d/#download-with-ansible_1","title":"Download with ansible","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware_data/tensorrt_yolox/yolox-sPlus-T4-960x960-pseudo-finetune.EntropyV2-int8-batch1.engine\n</code></pre>"},{"location":"use_case/perception_2d/#automatic-download-at-package-build-time","title":"Automatic download at package build time","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware/install/tensorrt_yolox/share/tensorrt_yolox/data/yolox-sPlus-T4-960x960-pseudo-finetune.EntropyV2-int8-batch1.engine\n</code></pre>"},{"location":"use_case/perception_2d/#for-evaluation-on-a-single-pc-modify-the-launch-file","title":"(For evaluation on a single PC) modify the launch file","text":"<p>To evaluate on a single PC, it is necessary to modify launch to output the recognition results of the camera. Change launch as follows.</p> <pre><code>\u276f vcs diff src/\n.................................\ndiff --git a/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml b/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\nindex 9ca8ea3df..a35e8d00f 100644\n--- a/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\n+++ b/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\n@@ -30,6 +30,14 @@\n   &lt;arg name=\"remove_unknown\" default=\"true\"/&gt;\n   &lt;arg name=\"trust_distance\" default=\"30.0\"/&gt;\n\n+  &lt;group&gt;\n+    &lt;include file=\"$(find-pkg-share tensorrt_yolox)/launch/yolox.launch.xml\" /&gt;\n+  &lt;/group&gt;\n+\n+  &lt;group&gt;\n+    &lt;include file=\"$(find-pkg-share bytetrack)/launch/bytetrack.launch.xml\" /&gt;\n+  &lt;/group&gt;\n+\n   &lt;!-- Jetson AGX --&gt;\n   &lt;!-- &lt;include file=\"$(find-pkg-share tensorrt_yolo)/launch/yolo.launch.xml\"&gt;\n     &lt;arg name=\"image_raw0\" value=\"$(var image_raw0)\"/&gt;\ndiff --git a/launch/tier4_perception_launch/launch/perception.launch.xml b/launch/tier4_perception_launch/launch/perception.launch.xml\nindex 0a2ef57f6..9a9b06379 100644\n--- a/launch/tier4_perception_launch/launch/perception.launch.xml\n+++ b/launch/tier4_perception_launch/launch/perception.launch.xml\n@@ -33,7 +33,7 @@\n   &lt;arg name=\"camera_info6\" default=\"/sensing/camera/camera6/camera_info\"/&gt;\n   &lt;arg name=\"image_raw7\" default=\"/sensing/camera/camera7/image_rect_color\"/&gt;\n   &lt;arg name=\"camera_info7\" default=\"/sensing/camera/camera7/camera_info\"/&gt;\n-  &lt;arg name=\"image_number\" default=\"6\" description=\"choose image raw number(0-7)\"/&gt;\n+  &lt;arg name=\"image_number\" default=\"1\" description=\"choose image raw number(0-7)\"/&gt;\n   &lt;arg name=\"use_vector_map\" default=\"true\" description=\"use vector map in prediction\"/&gt;\n   &lt;arg name=\"use_pointcloud_map\" default=\"true\" description=\"use pointcloud map in detection\"/&gt;\n   &lt;arg name=\"use_object_filter\" default=\"true\" description=\"use object filter\"/&gt;\ndiff --git a/perception/tensorrt_yolox/launch/yolox.launch.xml b/perception/tensorrt_yolox/launch/yolox.launch.xml\nindex b697b1f50..b9cb53102 100644\n--- a/perception/tensorrt_yolox/launch/yolox.launch.xml\n+++ b/perception/tensorrt_yolox/launch/yolox.launch.xml\n@@ -1,7 +1,7 @@\n &lt;?xml version=\"1.0\"?&gt;\n &lt;launch&gt;\n   &lt;arg name=\"input/image\" default=\"/sensing/camera/camera0/image_rect_color\"/&gt;\n-  &lt;arg name=\"output/objects\" default=\"/perception/object_recognition/detection/rois0\"/&gt;\n+  &lt;arg name=\"output/objects_yolox\" default=\"/perception/object_recognition/detection/rois0\"/&gt;\n   &lt;arg name=\"model_name\" default=\"yolox-tiny\"/&gt;\n   &lt;arg name=\"model_path\" default=\"$(find-pkg-share tensorrt_yolox)/data\"/&gt;\n   &lt;arg name=\"score_threshold\" default=\"0.35\"/&gt;\n@@ -16,7 +16,7 @@\n\n   &lt;node pkg=\"tensorrt_yolox\" exec=\"tensorrt_yolox_node_exe\" name=\"tensorrt_yolox\" output=\"screen\"&gt;\n     &lt;remap from=\"~/in/image\" to=\"$(var input/image)\"/&gt;\n-    &lt;remap from=\"~/out/objects\" to=\"$(var output/objects)\"/&gt;\n+    &lt;remap from=\"~/out/objects\" to=\"$(var output/objects_yolox)\"/&gt;\n     &lt;param name=\"score_threshold\" value=\"$(var score_threshold)\"/&gt;\n     &lt;param name=\"nms_threshold\" value=\"$(var nms_threshold)\"/&gt;\n     &lt;param name=\"model_path\" value=\"$(var model_path)/$(var model_name).onnx\"/&gt;\n</code></pre>"},{"location":"use_case/perception_2d/#evaluation-method","title":"Evaluation method","text":"<p>The perception_2d evaluation is executed by launching the <code>perception_2d.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>perception_2d_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and outputs camera, and the perception module performs recognition.</li> <li>The evaluation node subscribes to <code>/perception/object_recognition/detection{/detected}/rois{camera_no}</code> and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/perception_2d/#evaluation-results","title":"Evaluation results","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/perception_2d/#perception-normal","title":"Perception Normal","text":"<p>When the following conditions are satisfied by executing the evaluation function of perception_eval</p> <ol> <li>frame_result.pass_fail_result contains at least one object (<code>tp_object_results ! = [] and fp_object_results ! = [] and fn_objects ! = []</code>)</li> <li>no object fail (<code>frame_result.pass_fail_result.get_fail_object_num() == 0</code>)</li> </ol>"},{"location":"use_case/perception_2d/#perception-error","title":"Perception Error","text":"<p>The perception evaluation output is marked as <code>Error</code> when condition for <code>Normal</code> is not met.</p>"},{"location":"use_case/perception_2d/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/object_recognition/detection/rois{camera_no} tier4_perception_msgs/msg/DetectedObjectsWithFeature /perception/object_recognition/detection/tracked/rois{camera_no} tier4_perception_msgs/msg/DetectedObjectsWithFeature <p>Published topics:</p> Topic name Data type - -"},{"location":"use_case/perception_2d/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false / true (default value is false. Specify by <code>LaunchSensing</code> key for each t4_dataset in the scenario)</li> <li>perception_mode: camera_lidar_fusion</li> </ul> <p>NOTE: The <code>tf</code> in the bag is used to align the localization during annotation and simulation. Therefore, localization is invalid.</p>"},{"location":"use_case/perception_2d/#dependent-libraries","title":"Dependent libraries","text":"<p>The perception evaluation step bases on the perception_eval library.</p>"},{"location":"use_case/perception_2d/#division-of-roles-of-driving_log_replayer-with-dependent-libraries","title":"Division of roles of driving_log_replayer with dependent libraries","text":"<p><code>driving_log_replayer</code> package is in charge of the connection with ROS. The actual perception evaluation is conducted in perception_eval library. The perception_eval is a ROS-independent library, it cannot receive ROS objects. Also, ROS timestamps use nanoseconds while the <code>t4_dataset</code> format is based on milliseconds (because it uses <code>nuScenes</code>), so the values must be properly converted before using the library's functions.</p> <p><code>driving_log_replayer</code> subscribes the topic output from the perception module of Autoware, converts it to the data format defined in perception_eval, and passes it on. It is also responsible for publishing and visualizing the evaluation results from perception_eval on proper ROS topic.</p> <p>perception_eval is in charge of the part that compares the detection results passed from <code>driving_log_replayer</code> with ground truth data, calculates the index, and outputs the results.</p>"},{"location":"use_case/perception_2d/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/perception_2d/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Must contain the required topics in <code>t4_dataset</code> format.</p> <p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs and Cameras are used in a real-world vehicle configuration.</p> <p>/sensing/lidar/concatenated/pointcloud is used if the scenario LaunchSensing: false.</p> <p>If there is more than one CAMERA, include all on-board camera_info and image_rect_color_compressed.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/perception_2d/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/perception_2d/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/perception_2d/#scenario-format","title":"Scenario Format","text":"<p>There are two types of evaluation: use case evaluation and database evaluation. Use case evaluation is performed on a single dataset, while database evaluation uses multiple datasets and takes the average of the results for each dataset.</p> <p>In the database evaluation, the <code>vehicle_id</code> should be able to be set for each data set, since the calibration values may change. Also, it is necessary to set whether or not to activate the sensing module.</p> <p>See sample.</p>"},{"location":"use_case/perception_2d/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>The evaluation results by perception_eval under the conditions specified in the scenario are output for each frame. Only the final line has a different format from the other lines since the final metrics are calculated after all data has been flushed.</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Format of each frame:</p> <pre><code>{\n  \"Frame\": {\n    \"CameraType\": \"Evaluated camera\",\n    \"FrameName\": \"Frame number of t4_dataset used for evaluation\",\n    \"FrameSkip\": \"Number of times that an object was requested to be evaluated but the evaluation was skipped because there was no ground truth in the dataset within 75msec\",\n    \"PassFail\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TP\": \"Number of TPs\",\n        \"FP\": \"Number of FPs\",\n        \"FN\": \"Number of FNs\"\n      }\n    }\n  }\n}\n</code></pre> <p>Metrics Data Format:</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"TP rate for all labels\",\n          \"label0\": \"TP rate of label0\",\n          \"label1\": \"TP rate of label1\"\n        },\n        \"FP\": {\n          \"ALL\": \"FP rate for all labels\",\n          \"label0\": \"FP rate of label0\",\n          \"label1\": \"FP rate of label1\"\n        },\n        \"FN\": {\n          \"ALL\": \"FN rate for all labels\",\n          \"label0\": \"FN rate of label0\",\n          \"label1\": \"FN rate of label1\"\n        },\n        \"TN\": {\n          \"ALL\": \"TN rate for all labels\",\n          \"label0\": \"TN rate of label0\",\n          \"label1\": \"TN rate of label1\"\n        },\n        \"AP(Center Distance)\": {\n          \"ALL\": \"AP(Center Distance) rate for all labels\",\n          \"label0\": \"AP(Center Distance) rate of label0\",\n          \"label1\": \"AP(Center Distance) rate of label1\"\n        },\n        \"APH(Center Distance)\": {\n          \"ALL\": \"APH(Center Distance) rate for all labels\",\n          \"label0\": \"APH(Center Distance) rate of label0\",\n          \"label1\": \"APH(Center Distance) rate of label1\"\n        },\n        \"AP(IoU 2D)\": {\n          \"ALL\": \"AP(IoU 2D) rate for all labels\",\n          \"label0\": \"AP(IoU 2D) rate of label0\",\n          \"label1\": \"AP(IoU 2D) rate of label1\"\n        },\n        \"APH(IoU 2D)\": {\n          \"ALL\": \"APH(IoU 2D) rate for all labels\",\n          \"label0\": \"APH(IoU 2D) rate of label0\",\n          \"label1\": \"APH(IoU 2D) rate of label1\"\n        }\n      },\n      \"ConfusionMatrix\": {\n        \"label0(GroundTruth)\": {\n          \"label0(Prediction)\": \"value\",\n          \"label1(Prediction)\": \"value\"\n        },\n        \"label1(GroundTruth)\": {\n          \"label0(Prediction)\": \"value\",\n          \"label1(Prediction)\": \"value\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/perception_2d/#pickle-file","title":"pickle file","text":"<p>In database evaluation, it is necessary to replay multiple rosbags, but due to the ROS specification, it is impossible to use multiple bags in a single launch. Since one rosbag, i.e., one <code>t4_dataset</code>, requires one launch, it is necessary to execute as many launches as the number of datasets contained in the database evaluation.</p> <p>Since database evaluation cannot be done in a single launch, perception outputs a file <code>scene_result.pkl</code> in addition to <code>result.jsonl</code> file. A pickle file is a python object saved as a file, PerceptionEvaluationManager.frame_results of perception_eval. The dataset evaluation can be performed by reading all the objects recorded in the pickle file and outputting the index of the dataset's average.</p>"},{"location":"use_case/perception_2d/#result-file-of-database-evaluation","title":"Result file of database evaluation","text":"<p>In the case of a database evaluation with multiple datasets in the scenario, a file named <code>database_result.json</code> is output to the results directory.</p> <p>The format is the same as the Metrics Data Format.</p>"},{"location":"use_case/performance_diag/","title":"Evaluate diagnostics","text":"<p>Evaluate whether Autoware's diagnostics functionality behaves as expected.</p> <p>The following subjects of evaluation are currently supported:</p> <ul> <li>visibility: function to determine if visibility is impaired by fog, rain, etc.</li> <li>blockage: function to determine if leaves or other objects are attached to LiDAR and obstructing the measurement.</li> </ul>"},{"location":"use_case/performance_diag/#evaluation-method","title":"Evaluation Method","text":"<p>The diagnostics evaluation is executed by launching the <code>performance_diag.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>performance_diag_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command.</li> <li>Autoware receives sensor data output from the input rosbag and outputs the<code>/diagnostics</code> topic.</li> <li>The evaluation node subscribes to <code>/diagnostics</code> topic, and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/performance_diag/#visibility-evaluation","title":"visibility evaluation","text":"<p>The evaluation process confirms that more than a specified rate of ERRORs for limited visibility are generated for rosbag input data obtained under rainy conditions (naturally or artificially generated). Also, using data obtained during sunny weather, it is confirmed that ERRORs are never generated.</p> <p>The <code>status.name</code> in <code>/diagnostics</code> corresponding to <code>dual_return_filter: /sensing/lidar/.*: visibility_validation</code> is used for judgment.</p>"},{"location":"use_case/performance_diag/#blockage-evaluation","title":"blockage evaluation","text":"<p>For blockage evaluation, acquire data with LiDAR intentionally covered with a material that will not pass the laser beam (for example box). The evaluation confirms that ERROR for blockage is output more than a certain rate for the considered situation. The node will also confirm that no ERROR is generated for not covered LiDAR.</p> <p>The <code>status.name</code> in <code>/diagnostics</code> corresponding to <code>blockage_return_diag: /sensing/lidar/.*: blockage_validation</code> is used for judgment.</p>"},{"location":"use_case/performance_diag/#evaluation-result","title":"Evaluation Result","text":"<p>For each LiDAR diagnostic subscription, the evaluation judgment will be published on the topics described below:</p> <p>Each output of the evaluation can be considered a success or a failure depending on what you want to evaluate. You can change this by describing the type in the scenario.</p> <ul> <li>If the scenario type is TP (true positive), it succeeds if the <code>Diag</code> state is ERROR.</li> <li>If the scenario type is FP (false positive), it succeeds if the <code>Diag</code> state is not ERROR.</li> <li>If the scenario type is null, the test is omitted.</li> </ul>"},{"location":"use_case/performance_diag/#tp-normal","title":"TP Normal","text":"<p>If the scenario type is TP and the level in the diagnostic information is ERROR</p>"},{"location":"use_case/performance_diag/#tp-error","title":"TP Error","text":"<p>If the scenario type is TP and the level in the diagnostic information is not ERROR.</p>"},{"location":"use_case/performance_diag/#fp-normal","title":"FP Normal","text":"<p>If the scenario type is FP and the level in the diagnostic information is not ERROR.</p>"},{"location":"use_case/performance_diag/#fp-error","title":"FP Error","text":"<p>If the scenario type is FP and the level in the diagnostic information is ERROR.</p>"},{"location":"use_case/performance_diag/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/obstacle_segmentation/pointcloud sensor_msgs::msg::PointCloud2 /diagnostics diagnostic_msgs::msg::DiagnosticArray /tf tf2_msgs/msg/TFMessage <p>Published topics:</p> Topic name Data type /driving_log_replayer/visibility/value example_interfaces::msg::Float64 /driving_log_replayer/visibility/level example_interfaces::msg::Byte /driving_log_replayer/blockage/{lidar_name}/ground/ratio example_interfaces::msg::Float64 /driving_log_replayer/blockage/{lidar_name}/sky/ratio example_interfaces::msg::Float64 /driving_log_replayer/blockage/{lidar_name}/level example_interfaces::msg::Byte <p>{lidar_name} contains the name of the mounted lidar.</p>"},{"location":"use_case/performance_diag/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /api/localization/initialize InitializeLocalization"},{"location":"use_case/performance_diag/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>planning: false</li> <li>control: false</li> <li>localization: false / true (default value is false. Specify in scenario)</li> </ul>"},{"location":"use_case/performance_diag/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/performance_diag/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs are used in a real-world vehicle configuration.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport <p>NOTE: If localization is false (false by default), /tf is required.</p>"},{"location":"use_case/performance_diag/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/performance_diag/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/performance_diag/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/performance_diag/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>In <code>performance_diag</code> evaluation scenario visibility and blockage are evaluated. The <code>Result</code> is <code>true</code> if both visibility and blockage evaluation steps have passed. Otherwise, the <code>Result</code> is <code>false</code>.</p> <p>The result format is shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Visibility Result example:</p> <pre><code>{\n  \"Visibility\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Invalid\" },\n    \"Info\": {\n      \"Level\": \"diag\u306e\u30ec\u30d9\u30eb\",\n      \"Visibility\": \"visibility\u306e\u5024\"\n    }\n  }\n}\n</code></pre> <p>Blockage Result example:</p> <pre><code>{\n  \"Blockage\": {\n    \"name of LiDAR1\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"Level\": \"Level of diag\",\n        \"GroundBlockageRatio\": \"Ground blockage ratio\",\n        \"GroundBlockageCount\": \"Ground blockage count. Reference\",\n        \"SkyBlockageRatio\": \"Sky blockage ratio\",\n        \"SkyBlockageCount\": \"Sky blockage count. Reference\"\n      }\n    },\n    \"name of LiDAR2\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"Level\": \"Level of diag\",\n        \"GroundBlockageRatio\": \"Ground blockage ratio\",\n        \"GroundBlockageCount\": \"Ground blockage count. Reference\",\n        \"SkyBlockageRatio\": \"Sky blockage ratio\",\n        \"SkyBlockageCount\": \"Sky blockage count. Reference\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/traffic_light/","title":"Evaluate perception(traffic light)","text":"<p>The performance of Autoware's recognition function (perception) is evaluated by calculating mAP (mean Average Precision) and other indices from the recognition results.</p> <p>Run the perception module and pass the output perception topic to the evaluation library for evaluation.</p> <p>Currently, only the evaluation of <code>classification2d</code> is supported.</p>"},{"location":"use_case/traffic_light/#preparation","title":"Preparation","text":"<p>In perception evaluation, machine-learning pre-trained models are used. If the model is not prepared in advance, Autoware will not output recognition results. If no evaluation results are produced, check to see if this has been done correctly.</p>"},{"location":"use_case/traffic_light/#downloading-model-files","title":"Downloading Model Files","text":"<p>Models are downloaded during Autoware setup. The method of downloading models depends on the version of Autoware you are using, so check which method is used. The following patterns exist.</p>"},{"location":"use_case/traffic_light/#download-with-ansible","title":"Download with ansible","text":"<p>When you run the ansible setup script, you will see <code>Download artifacts? [y/N]</code>, type <code>y</code> and press enter (Autoware foundation's main branch use this method) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"use_case/traffic_light/#automatically-downloaded-when-the-package-is-built","title":"Automatically downloaded when the package is built","text":"<p>If you are using a slightly older Autoware.universe, this is the one to use, until the commit hash of <code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>. traffic_light_classifier/CMakeList.txt</p>"},{"location":"use_case/traffic_light/#conversion-of-model-files","title":"Conversion of model files","text":"<p>The downloaded onnx file is not to be used as-is, but to be converted to a TensorRT engine file for use. A conversion command is available, so source the autoware workspace and execute the command.</p> <p>Let's assume that autoware is installed in <code>$HOME/autoware</code>.</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch traffic_light_classifier traffic_light_classifier.launch.xml use_gpu:=true  build_only:=true\nros2 launch traffic_light_fine_detector traffic_light_fine_detector.launch.xml build_only:=true\n</code></pre> <p>When the conversion command finishes, the engine file is output. The output destination changes according to the model download method, so check that the output is in the appropriate directory.</p>"},{"location":"use_case/traffic_light/#download-with-ansible_1","title":"Download with ansible","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware_data/traffic_light_classifier/traffic_light_classifier_mobilenetv2_batch_6.fp16-batch6.engine\n$HOME/autoware_data/traffic_light_fine_detector/tlr_yolox_s_batch_6.fp16-batch6.engine\n</code></pre>"},{"location":"use_case/traffic_light/#automatic-download-at-package-build-time","title":"Automatic download at package build time","text":"<p>The following file is output.</p> <pre><code>$HOME/autoware/install/traffic_light_classifier/share/traffic_light_classifier/data/traffic_light_classifier_mobilenetv2_batch_6.fp16-batch6.engine\n$HOME/autoware/install/traffic_light_fine_detector/share/traffic_light_fine_detector/data/tlr_yolox_s_batch_6.fp16-batch6.engine\n</code></pre>"},{"location":"use_case/traffic_light/#for-evaluation-on-a-single-pc-rewrite-parameters-in-the-launch-file","title":"(For evaluation on a single PC) rewrite parameters in the launch file","text":"<p>set the value of <code>traffic_light_recognition/fusion_only</code> <code>true</code> in the file <code>autoware.universe/launch/tier4_perception_launch/launch/perception.launch.xml</code> https://github.com/autowarefoundation/autoware.universe/blob/main/launch/tier4_perception_launch/launch/perception.launch.xml#L79</p> <p>In the main branch of Autoware Foundation's Autoware, it is set to <code>false</code>, but in the case of Autoware used in actual vehicles, it may be set to <code>true</code>. Because <code>true</code> is a setting that recognition results are sent from another computer, when evaluating with a single PC, it should be set back to <code>false</code> before execution.</p>"},{"location":"use_case/traffic_light/#evaluation-method","title":"Evaluation method","text":"<p>The traffic_light evaluation is executed by launching the <code>traffic_light.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>traffic_light_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data output from input rosbag and outputs camera, and the perception module performs recognition.</li> <li>The evaluation node subscribes to <code>/perception/traffic_light_recognition/traffic_signals</code> and evaluates data. The result is dumped into a file.</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/traffic_light/#evaluation-results","title":"Evaluation results","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/traffic_light/#perception-normal","title":"Perception Normal","text":"<p>When the following conditions are satisfied by executing the evaluation function of perception_eval</p> <ol> <li>frame_result.pass_fail_result contains at least one object (<code>tp_object_results ! = [] and fp_object_results ! = [] and fn_objects ! = []</code>)</li> <li>no object fail (<code>frame_result.pass_fail_result.get_fail_object_num() == 0</code>)</li> </ol>"},{"location":"use_case/traffic_light/#perception-error","title":"Perception Error","text":"<p>The perception evaluation output is marked as <code>Error</code> when condition for <code>Normal</code> is not met.</p>"},{"location":"use_case/traffic_light/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /perception/traffic_light_recognition/traffic_signals tier4_perception_msgs/msg/TrafficSignalArray <p>Published topics:</p> Topic name Data type - -"},{"location":"use_case/traffic_light/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false / true (default value is false. Specify by <code>LaunchSensing</code> key for each t4_dataset in the scenario)</li> <li>perception_mode: camera_lidar_fusion</li> </ul> <p>NOTE: The <code>tf</code> in the bag is used to align the localization during annotation and simulation. Therefore, localization is invalid.</p>"},{"location":"use_case/traffic_light/#dependent-libraries","title":"Dependent libraries","text":"<p>The perception evaluation step bases on the perception_eval library.</p>"},{"location":"use_case/traffic_light/#division-of-roles-of-driving_log_replayer-with-dependent-libraries","title":"Division of roles of driving_log_replayer with dependent libraries","text":"<p><code>driving_log_replayer</code> package is in charge of the connection with ROS. The actual perception evaluation is conducted in perception_eval library. The perception_eval is a ROS-independent library, it cannot receive ROS objects. Also, ROS timestamps use nanoseconds while the <code>t4_dataset</code> format is based on milliseconds (because it uses <code>nuScenes</code>), so the values must be properly converted before using the library's functions.</p> <p><code>driving_log_replayer</code> subscribes the topic output from the perception module of Autoware, converts it to the data format defined in perception_eval, and passes it on. It is also responsible for publishing and visualizing the evaluation results from perception_eval on proper ROS topic.</p> <p>perception_eval is in charge of the part that compares the detection results passed from <code>driving_log_replayer</code> with ground truth data, calculates the index, and outputs the results.</p>"},{"location":"use_case/traffic_light/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/traffic_light/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>Must contain the required topics in <code>t4_dataset</code> format.</p> <p>The vehicle's ECU CAN and sensors data topics are required for the evaluation to be run correctly. The following example shows the topic list available in evaluation input rosbag when multiple LiDARs and Cameras are used in a real-world vehicle configuration.</p> <p>/sensing/lidar/concatenated/pointcloud is used if the scenario LaunchSensing: false.</p> <p>If there is more than one CAMERA, include all on-board camera_info and image_rect_color_compressed.</p> Topic name Data type /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>The vehicle topics can be included instead of CAN.</p> Topic name Data type /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/traffic_light/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must not be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/traffic_light/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/traffic_light/#scenario-format","title":"Scenario Format","text":"<p>There are two types of evaluation: use case evaluation and database evaluation. Use case evaluation is performed on a single dataset, while database evaluation uses multiple datasets and takes the average of the results for each dataset.</p> <p>In the database evaluation, the <code>vehicle_id</code> should be able to be set for each data set, since the calibration values may change. Also, it is necessary to set whether or not to activate the sensing module.</p> <p>See sample.</p>"},{"location":"use_case/traffic_light/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>The evaluation results by perception_eval under the conditions specified in the scenario are output for each frame. Only the final line has a different format from the other lines since the final metrics are calculated after all data has been flushed.</p> <p>The format of each frame and the metrics format are shown below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Format of each frame:</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"Frame number of t4_dataset used for evaluation\",\n    \"FrameSkip\": \"Number of times that an object was requested to be evaluated but the evaluation was skipped because there was no ground truth in the dataset within 75msec\",\n    \"PassFail\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TP\": \"Number of TPs\",\n        \"FP\": \"Number of FPs\",\n        \"FN\": \"Number of FNs\"\n      }\n    }\n  }\n}\n</code></pre> <p>Metrics Data Format:</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"TP rate for all labels\",\n          \"label0\": \"TP rate of label0\",\n          \"label1\": \"TP rate of label1\"\n        },\n        \"FP\": {\n          \"ALL\": \"FP rate for all labels\",\n          \"label0\": \"FP rate of label0\",\n          \"label1\": \"FP rate of label1\"\n        },\n        \"FN\": {\n          \"ALL\": \"FN rate for all labels\",\n          \"label0\": \"FN rate of label0\",\n          \"label1\": \"FN rate of label1\"\n        },\n        \"TN\": {\n          \"ALL\": \"TN rate for all labels\",\n          \"label0\": \"TN rate of label0\",\n          \"label1\": \"TN rate of label1\"\n        },\n        \"Accuracy\": {\n          \"ALL\": \"Accuracy for all labels\",\n          \"label0\": \"Accuracy of label0\",\n          \"label1\": \"Accuracy of label1\"\n        },\n        \"Precision\": {\n          \"ALL\": \"Precision for all labels\",\n          \"label0\": \"Precision of label0\",\n          \"label1\": \"Precision of label1\"\n        },\n        \"Recall\": {\n          \"ALL\": \"Recall for all labels\",\n          \"label0\": \"Recall of label0\",\n          \"label1\": \"Recall of label1\"\n        },\n        \"F1score\": {\n          \"ALL\": \"F1score for all labels\",\n          \"label0\": \"F1score of label0\",\n          \"label1\": \"F1score of label1\"\n        }\n      },\n      \"ConfusionMatrix\": {\n        \"label0(GroundTruth)\": {\n          \"label0(Prediction)\": \"value\",\n          \"label1(Prediction)\": \"value\"\n        },\n        \"label1(GroundTruth)\": {\n          \"label0(Prediction)\": \"value\",\n          \"label1(Prediction)\": \"value\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"use_case/traffic_light/#pickle-file","title":"pickle file","text":"<p>In database evaluation, it is necessary to replay multiple rosbags, but due to the ROS specification, it is impossible to use multiple bags in a single launch. Since one rosbag, i.e., one <code>t4_dataset</code>, requires one launch, it is necessary to execute as many launches as the number of datasets contained in the database evaluation.</p> <p>Since database evaluation cannot be done in a single launch, perception outputs a file <code>scene_result.pkl</code> in addition to <code>result.jsonl</code> file. A pickle file is a python object saved as a file, PerceptionEvaluationManager.frame_results of perception_eval. The dataset evaluation can be performed by reading all the objects recorded in the pickle file and outputting the index of the dataset's average.</p>"},{"location":"use_case/traffic_light/#result-file-of-database-evaluation","title":"Result file of database evaluation","text":"<p>In the case of a database evaluation with multiple datasets in the scenario, a file named <code>database_result.json</code> is output to the results directory.</p> <p>The format is the same as the Metrics Data Format.</p>"},{"location":"use_case/yabloc/","title":"Evaluate YabLoc estimation","text":"<p>Evaluate whether Autoware's YabLoc, a camera based pcd-less localization, is working stably.</p>"},{"location":"use_case/yabloc/#evaluation-method","title":"Evaluation method","text":"<p>The localization's evaluation is executed by launching the <code>yabloc.launch.py</code> file. Launching the file executes the following steps:</p> <ol> <li>Execute launch of evaluation node (<code>yabloc_evaluator_node</code>), <code>logging_simulator.launch</code> file and <code>ros2 bag play</code> command</li> <li>Autoware receives sensor data input from prepared rosbag and performs localization estimation</li> <li>Evaluation node subscribes to Autoware's output topics, determines whether the outputs meet the criteria, and outputs the results</li> <li>When the playback of the rosbag is finished, Autoware's launch is automatically terminated, and the evaluation is completed.</li> </ol>"},{"location":"use_case/yabloc/#availability-of-yabloc","title":"Availability of YabLoc","text":"<p>We use the output from <code>yabloc_monitor</code> via <code>/diagnostics</code> to evaluate whether YabLoc is available.</p> <ul> <li><code>/diagnostics</code></li> </ul>"},{"location":"use_case/yabloc/#evaluation-result","title":"Evaluation Result","text":"<p>The results are calculated for each subscription. The format and available states are described below.</p>"},{"location":"use_case/yabloc/#yabloc-availability-normal","title":"YabLoc Availability Normal","text":"<p>Information related to the monitored topic is extracted from <code>/diagnostics</code> which Component State Monitor outputs. If the most recent information is \"OK\", it is considered as pass.</p>"},{"location":"use_case/yabloc/#yabloc-availability-error","title":"YabLoc Availability Error","text":"<p>The YabLoc availability evaluation output is marked as <code>Error</code> when conditions for <code>YabLoc Availability Normal</code> are not met.</p>"},{"location":"use_case/yabloc/#topic-name-and-data-type-used-by-evaluation-node","title":"Topic name and data type used by evaluation node","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"use_case/yabloc/#service-name-and-data-type-used-by-the-evaluation-node","title":"Service name and data type used by the evaluation node","text":"Service name Data type /api/localization/initialize InitializeLocalization"},{"location":"use_case/yabloc/#arguments-passed-to-logging_simulatorlaunch","title":"Arguments passed to logging_simulator.launch","text":"<p>To make Autoware processing less resource-consuming, modules that are not relevant to evaluation are disabled by passing the <code>false</code> parameter as a launch argument. The following parameters are set to <code>false</code>:</p> <ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"use_case/yabloc/#about-simulation","title":"About simulation","text":"<p>State the information required to run the simulation.</p>"},{"location":"use_case/yabloc/#topic-to-be-included-in-the-input-rosbag","title":"Topic to be included in the input rosbag","text":"<p>The following example shows the topic list available in evaluation input rosbag.</p> Topic name Data type /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"use_case/yabloc/#topics-that-must-not-be-included-in-the-input-rosbag","title":"Topics that must NOT be included in the input rosbag","text":"Topic name Data type /clock rosgraph_msgs/msg/Clock <p>The clock is output by the --clock option of ros2 bag play, so if it is recorded in the bag itself, it is output twice, so it is not included in the bag.</p>"},{"location":"use_case/yabloc/#about-evaluation","title":"About Evaluation","text":"<p>State the information necessary for the evaluation.</p>"},{"location":"use_case/yabloc/#scenario-format","title":"Scenario Format","text":"<p>See sample.</p>"},{"location":"use_case/yabloc/#evaluation-result-format","title":"Evaluation Result Format","text":"<p>See sample.</p> <p>Examples of each evaluation are described below. NOTE: common part of the result file format, which has already been explained, is omitted.</p> <p>Availability Result example:</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"ja/","title":"Driving Log Replayer \u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<p>\u30da\u30fc\u30b8\u30c8\u30c3\u30d7\u306e \"\u6587 A\" \u30a2\u30a4\u30b3\u30f3\u304b\u3089\u8a00\u8a9e\u306e\u5207\u308a\u66ff\u3048\u304c\u53ef\u80fd\u3067\u3059\u3002</p> <p>\u3053\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u306f\u73fe\u5728\u30e1\u30f3\u30c6\u30ca\u30f3\u30b9\u30e2\u30fc\u30c9\u3067\u3059\u3002 \u30d0\u30b0\u4fee\u6b63\u306e\u307f\u3067\u3001\u65b0\u3057\u3044\u6a5f\u80fd\u306f\u8ffd\u52a0\u3055\u308c\u307e\u305b\u3093\u3002 \u4ee5\u4e0b\u306ev2\u3092\u3054\u5229\u7528\u304f\u3060\u3055\u3044\u3002</p> <p>https://github.com/tier4/driving_log_replayer_v2</p>"},{"location":"ja/#driving-log-replayer_1","title":"Driving Log Replayer \u306b\u3064\u3044\u3066","text":"<p>Driving Log Replayer \u306f\u3001\u904e\u53bb\u306b\u8a18\u9332\u3055\u308c\u305f\u5165\u529b\u30c7\u30fc\u30bf\u3092\u3082\u3068\u306b Autoware.Universe \u306e\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b ROS 2 \u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u3059\u3002 \u30b7\u30b9\u30c6\u30e0\u904b\u7528\u306e\u524d\u63d0\u6761\u4ef6\u3092\u5b9a\u7fa9\u3057\u3001\u305d\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u307e\u3059\u3002</p>"},{"location":"ja/analyzer/","title":"Driving Log Replayer Analyzer","text":"<p>Driving Log Replayer \u3067\u884c\u3063\u305f\u30c6\u30b9\u30c8\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u3092\u5206\u6790\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\u3002</p>"},{"location":"ja/analyzer/#_1","title":"\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u6210","text":"<p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u6210\u3092\u53d6\u308b\u3002</p> <pre><code>driving_log_replayer_analyzer\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 __main__.py      # CLI\u306e\u30a8\u30f3\u30c8\u30ea\u30fc\u30dd\u30a4\u30f3\u30c8\n\u251c\u2500\u2500 analysis         # CLI\u306e\u89e3\u6790\u30b3\u30de\u30f3\u30c9\n\u251c\u2500\u2500 config           # \u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3068\u8a2d\u5b9a\u3092\u8aad\u307f\u8fbc\u3080\u30e2\u30b8\u30e5\u30fc\u30eb\n\u251c\u2500\u2500 data             # jsonl\u304b\u3089\u30c7\u30fc\u30bf\u3092\u8aad\u307f\u8fbc\u3080\u30e2\u30b8\u30e5\u30fc\u30eb\n\u2514\u2500\u2500 plot             # \u30c7\u30fc\u30bf\u3092\u63cf\u753b\u3059\u308b\u30e2\u30b8\u30e5\u30fc\u30eb\n</code></pre> <p>ROS \u306b\u4f9d\u5b58\u3057\u306a\u3044\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u306f\u3042\u308b\u304c\u3001ROS \u306e\u30ce\u30fc\u30c9\u306b\u3082\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u3057\u3066 import \u3055\u308c\u308b\u306e\u3067\u3001ROS \u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u3057\u3066\u3082\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b\u3002</p> <p>\u30e2\u30b8\u30e5\u30fc\u30eb\u306e\u5f79\u5272\u3092\u56f3\u306b\u793a\u3059\u3002</p> <p></p>"},{"location":"ja/analyzer/#_2","title":"\u6ce8\u610f","text":"<p>\u73fe\u72b6\u3067\u306f obstacle_segmentation \u306e result.jsonl \u306e\u5206\u6790\u306e\u307f\u53ef\u80fd \u5fc5\u8981\u306b\u5fdc\u3058\u3066\u3001\u5404 use case \u306b\u5bfe\u5fdc\u3057\u305f\u5206\u6790\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8ffd\u52a0\u3059\u308b\u3002 analysis, config, data \u306b use_case_name.py \u30d5\u30a1\u30a4\u30eb\u3092\u8ffd\u52a0\u3059\u308b\u3002</p>"},{"location":"ja/analyzer/#_3","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u65b9\u6cd5","text":"<ul> <li>driving_log_replayer_cli \u3068\u4e00\u7dd2\u306b\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b</li> <li>driving_log_replayer \u3068\u4e00\u7dd2\u306b ros \u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3068\u3057\u3066\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3055\u308c\u308b</li> </ul>"},{"location":"ja/analyzer/#_4","title":"\u4f7f\u3044\u65b9","text":"<pre><code>dlr-analyzer analysis ${use-case-name} ${result.jsonl_path} [-c ${config_path}]\n</code></pre>"},{"location":"ja/overview/command/","title":"\u30b3\u30de\u30f3\u30c9","text":"<p>driving_log_replayer_cli \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3068\u3001\u30bf\u30fc\u30df\u30ca\u30eb\u3067 <code>dlr</code> \u3068\u3044\u3046\u30b3\u30de\u30f3\u30c9\u304c\u5b9f\u884c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u308a\u307e\u3059\u3002 <code>dlr</code> \u30b3\u30de\u30f3\u30c9\u306f\u3001\u30b5\u30d6\u30b3\u30de\u30f3\u30c9\u3092\u6301\u3063\u3066\u3044\u307e\u3059\u3002 \u5404\u30b3\u30de\u30f3\u30c9\u306b\u5fc5\u8981\u306a\u5f15\u6570\u306f <code>--help</code> \u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u6307\u5b9a\u3059\u308b\u3068\u8868\u793a\u3067\u304d\u308b\u307e\u3059\u3002</p> <pre><code># driving_log_replayer top level help\ndlr --help\n\n# show version\ndlr --version\n\n# show subcommand help\ndlr subcommand --help\n\n# show subsubcommand help\ndlr subcommand subsubcommand --help\n</code></pre>"},{"location":"ja/overview/command/#cli","title":"cli \u30b5\u30d6\u30b3\u30de\u30f3\u30c9","text":"<p>\u30b5\u30d6\u30b3\u30de\u30f3\u30c9\u3068\u3057\u3066\u4ee5\u4e0b\u304c\u5b58\u5728\u3059\u308b</p> <ul> <li>configure</li> <li>simulation</li> </ul>"},{"location":"ja/overview/command/#dlr-configure","title":"dlr configure","text":"<p>\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb <code>.driving_log_replayer.config.toml</code> \u3092\u64cd\u4f5c\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3002</p> <pre><code># -p\u3067\u6307\u5b9a\u3057\u305fprofile\u540d\u306bdata_directory\u3001output_directory\u3001autoware_path\u3092\u8a2d\u5b9a\u3059\u308b\u3002\n# -p\u3092\u7701\u7565\u3057\u305f\u5834\u5408\u306fprofile\u540d\u306bdefault\u304c\u6307\u5b9a\u3055\u308c\u308b\ndlr configure register -d ${data_directory} -o ${output_directory} -a ${autoware_path} [-p ${profile}]\n</code></pre>"},{"location":"ja/overview/command/#dlr-simulation","title":"dlr simulation","text":"<p>simulation \u3092\u5b9f\u884c\u3059\u308b\u30b3\u30de\u30f3\u30c9</p> <pre><code># simulation \u5b9f\u884c\ndlr simulation run -p ${profile}\n\n# \u7d50\u679c\u306e\u78ba\u8a8d\u3001output_directory\u4ee5\u4e0b\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u306e\u30b5\u30de\u30ea\u30fc\u3092\u8868\u793a\u3059\u308b\ndlr simulation show-result ${output_directory}\n\n# \u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u305b\u305a\u306b\u3001\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u5f97\u308b\u305f\u3081\u306b\u5b9f\u884c\u3059\u308b\u4e88\u884c\u6f14\u7fd2\u30e2\u30fc\u30c9\n# bag, map, sensor_model, vehicle_model [, vehicle_id] \u3092\u5f15\u6570\u3067\u6307\u5b9a\u3059\u308b\ndlr simulation dry-run -p ${profile} -u ${use_case} -l sensor_model:=${sensor_model} -l vehicle_model:=${vehicle_model} -l map_path:=${map_path} -l input_bag:=${bag_path} [-l vehicle_id:=${vehicle_id}]\n\n# \u30b3\u30de\u30f3\u30c9\u4f8b\n# -p\u306e\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u3001bag\u3068result.jsonl\u306e\u51fa\u529b\u5148\u3092\u6c7a\u3081\u308b\u305f\u3081\u306b\u4f7f\u308f\u308c\u308b\u3002\u7701\u7565\u3059\u308b\u3068default\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u306eoutput_directory\u306b\u51fa\u529b\u3055\u308c\u308b\u3002\n# \u73fe\u6642\u70b9\u3067\u306fuse_case\u306fannotationless_perception\u306e\u307f\u306a\u306e\u3067-u\u3092\u7701\u7565\u3059\u308b\u3068\u81ea\u52d5\u3067anontationless_perception\u306b\u306a\u308b\ndlr simulation dry-run -l input_bag:=$HOME/dlr_data/auto/annotationless/sample/input_bag -l sensor_model:=sample_sensor_kit -l vehicle_model:=sample_vehicle -l map_path:=$HOME/map/sample_map\n</code></pre>"},{"location":"ja/overview/command/#dlr-simulation-run-launch-argument-option","title":"dlr simulation run launch argument option","text":"<p>driving_log_replayer\u306ecli\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u304b\u3089sensor_model\u306a\u3069launch\u306b\u5fc5\u8981\u306a\u5f15\u6570\u3092\u8aad\u307f\u53d6\u3063\u3066\u3001launch\u30b3\u30de\u30f3\u30c9\u3092\u751f\u6210\u3059\u308b\u3002 \u4e00\u65b9\u3067\u3001bag\u306e\u518d\u751f\u901f\u5ea6\u306a\u3069\u3001\u5b9f\u884c\u6642\u306b\u5909\u66f4\u3057\u305f\u3044launch\u306e\u5f15\u6570\u306b\u95a2\u3057\u3066\u306f\u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u6e21\u3059\u3053\u3068\u3067\u6307\u5b9a\u53ef\u80fd\u3067\u3042\u308b\u3002 \u5f15\u6570\u3092\u30ab\u30f3\u30de\u3067\u533a\u5207\u308a\u3067\u4e26\u3079\u308b\u3053\u3068\u3067\u8907\u6570\u306e\u5f15\u6570\u3092\u6307\u5b9a\u53ef\u80fd\u3067\u3042\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u4f8b\u3092\u793a\u3059\u3002</p> <pre><code># bag\u306e\u518d\u751f\u901f\u5ea6\u3001\u3059\u306a\u308f\u3061\u3001simulation\u6642\u9593\u30920.5\u500d\u901f\u306b\u3059\u308b\ndlr simulation run -p default -l play_rate:=0.5\n\n# bag\u306e\u518d\u751f\u901f\u5ea6\u30920.5\u500d\u901f\u3001\u304b\u3064\u3001input_pointcloud\u3092 /sensing/lidar/concatenated/pointcloud\u306b\u3059\u308b\ndlr simulation run -p default -l play_rate:=0.5 -l input_pointcloud:=/sensing/lidar/concatenated/pointcloud\n\n# perception_mode\u3092camera_lidar_fusion\u306b\u3059\u308b\ndlr simulation run -p default -l perception_mode:=camera_lidar_fusion\n</code></pre> <p>\u6307\u5b9a\u53ef\u80fd\u306a\u5f15\u6570\u306f\u3001ros2 launch\u306e-s\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u4f7f\u3046\u3053\u3068\u3067\u8868\u793a\u3067\u304d\u308b\u3002</p> <pre><code># \u276f ros2 launch driving_log_replayer ${use_case}.launch.py -s\n\u276f ros2 launch driving_log_replayer localization.launch.py -s\nArguments (pass arguments as '&lt;name&gt;:=&lt;value&gt;'):\n\n    'with_autoware':\n        Whether to launch autoware or not\n        (default: 'true')\n\n    'scenario_path':\n        scenario path\n...\n</code></pre> <p>\u305f\u3060\u3057\u3001launch\u306e\u5f15\u6570\u3068\u3057\u3066\u8868\u793a\u3055\u308c\u3066\u3044\u3066\u3082\u3001localization\u306e\u8a55\u4fa1\u3067localization:=false\u3068\u3044\u3063\u305f\u77db\u76fe\u3057\u305f\u8a2d\u5b9a\u304c\u51fa\u6765\u306a\u3044\u3088\u3046\u306b\u3001driving_log_replayer\u5074\u3067\u56fa\u5b9a\u3055\u308c\u3066\u3044\u308b\u5f15\u6570\u3082\u3042\u308b\u3002 \u56fa\u5b9a\u3057\u3066\u3044\u308b\u5f15\u6570\u306f\u6307\u5b9a\u3057\u3066\u3082\u7121\u8996\u3055\u308c\u308b\u3002\u56fa\u5b9a\u3055\u308c\u3066\u3044\u308b\u5f15\u6570\u306f\u3001\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u3092\u53c2\u7167\u3002</p> <pre><code>driving_log_replayer/driving_log_replayer/launch_common.py get_autoware_launch\u95a2\u6570\ndriving_log_replayer/launch/${use_case}.launch.py get_autoware_launch\u306e\u5f15\u6570\n</code></pre>"},{"location":"ja/overview/command/#simulation","title":"simulation\u5b9f\u884c\u3067\u4f5c\u6210\u3055\u308c\u308b\u30d5\u30a1\u30a4\u30eb","text":"<p>simulation run\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3068\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u306e\u51fa\u529b\u5148\u30d5\u30a9\u30eb\u30c0\u306b\u5b9f\u884c\u6642\u9593\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u304c\u4f5c\u6210\u3055\u308c\u3001\u305d\u306e\u4e0b\u306b\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002 \u51fa\u529b\u30d5\u30a1\u30a4\u30eb\u306e\u4f8b\u3092\u4ee5\u4e0b\u306b\u793a\u3059\u3002</p> <pre><code># t4_dataset\u3092\u4f7f\u7528\u3057\u306a\u3044\u5834\u5408\noutput_direcotry\n\u2514\u2500\u2500 YYYY-mmDD-HHMMSS               // \u5b9f\u884c\u6642\u523b\n    \u2514\u2500\u2500 TC01                       // \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u540d\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 console.log           // \u30bf\u30fc\u30df\u30ca\u30eb\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u30ed\u30b0\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 result.jsonl          // \u5909\u63db\u5143\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 result_bag            // record\u3057\u305fbag\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 metadata.yaml\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 result_bag_0.db3\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 run.bash              // \u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u30b3\u30de\u30f3\u30c9\n    \u2514\u2500\u2500 TC02\n...\n</code></pre> <pre><code>output_direcotry\n\u2514\u2500\u2500 YYYY-mmDD-HHMMSS                         // \u5b9f\u884c\u6642\u523b\n    \u2514\u2500\u2500 TC01                                 // \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u540d\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 console.log                     // \u30bf\u30fc\u30df\u30ca\u30eb\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u30ed\u30b0\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 run.bash                        // \u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u30b3\u30de\u30f3\u30c9\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 DATASET01\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 perception_eval_log        // perception_eval\u306e\u30ed\u30b0\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 ...\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 result.jsonl               // \u5909\u63db\u5143\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 result_archive             // json\u4ee5\u5916\u306e\u8a55\u4fa1\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 scene_result.pkl      // perception_eval\u3067\u8a55\u4fa1\u3057\u305fframe_results\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30d5\u30a1\u30a4\u30eb\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 result_bag                 // record\u3057\u305fbag\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0     \u251c\u2500\u2500 metadata.yaml\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0     \u2514\u2500\u2500 result_bag_0.db3\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 DATASET02\n...\n</code></pre>"},{"location":"ja/overview/command/#wasim-driving_log_replayer","title":"wasim \u306b\u3088\u308b driving_log_replayer \u5b9f\u884c","text":"<p>TIER IV \u304c\u63d0\u4f9b\u3057\u3066\u3044\u308bAutoware Evaluator\u3078 \u30a2\u30af\u30bb\u30b9\u6a29\u304c\u3042\u308b\u5834\u5408\u306fwasim\u3092\u5229\u7528\u3059\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u3002</p> <p>\u4f7f\u3044\u65b9\u306f\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u30b5\u30a4\u30c8\u3092\u53c2\u7167\u3002</p> <p>wasim \u306f Autoware Evaluator \u304b\u3089\u30b7\u30ca\u30ea\u30aa\u3092\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u3066\u5b9f\u884c\u3059\u308b\u306e\u3067\u3001\u30af\u30e9\u30a6\u30c9\u74b0\u5883\u306b\u767b\u9332\u6e08\u307f\u306e\u30b7\u30ca\u30ea\u30aa\u3057\u304b\u5b9f\u884c\u51fa\u6765\u306a\u3044\u3002 \u30af\u30e9\u30a6\u30c9\u306b\u767b\u9332\u3057\u3066\u306a\u3044\u30b7\u30ca\u30ea\u30aa\u306f driving_log_replayer_cli \u3092\u4f7f\u7528\u3059\u308b\u3002</p>"},{"location":"ja/overview/","title":"\u6982\u8981","text":"<p>Driving Log Replayer \u306f\u3001log(rosbag2)\u3092\u7528\u3044\u3066 Autoware \u306e open loop simulation \u3092\u5b9f\u884c\u3057\u3001Autoware \u304c\u51fa\u529b\u3059\u308b\u30c8\u30d4\u30c3\u30af\u3092\u8a55\u4fa1\u3059\u308b\u30d1\u30c3\u30b1\u30fc\u30b8\u3067\u3059\u3002 Sensing, Localization, Perception \u306e\u6027\u80fd\u78ba\u8a8d\u3068\u3001\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306e\u30ea\u30b0\u30ec\u30c3\u30b7\u30e7\u30f3\u30c6\u30b9\u30c8\u306b\u4f7f\u7528\u3057\u307e\u3059\u3002</p>"},{"location":"ja/overview/#_2","title":"\u95a2\u9023\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8","text":"<ol> <li>AutowareDocumentation</li> <li>WebAutoDocumentation</li> </ol>"},{"location":"ja/overview/#_3","title":"\u95a2\u9023\u30ea\u30dd\u30b8\u30c8\u30ea","text":"<ol> <li>ros2bag_extensions</li> <li>perception_eval</li> <li>perception_dataset</li> </ol>"},{"location":"ja/overview/#_4","title":"\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3","text":"<p>Driving Log Replayer \u306f\u3001Autoware \u306e\u8a55\u4fa1\u30ce\u30fc\u30c9\u3092 Autoware \u306e\u6a19\u6e96\u6a5f\u80fd\u306b\u4ed8\u52a0\u3057\u305f\u69cb\u6210\u3068\u306a\u3063\u3066\u3044\u308b\u3002 \u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u56f3\u3092\u4ee5\u4e0b\u306b\u793a\u3059\u3002</p> <p></p>"},{"location":"ja/overview/#_5","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u69cb\u6210","text":"<p>Driving Log Replayer \u306e\u8a55\u4fa1\u30ce\u30fc\u30c9\u306f\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306b\u52d5\u4f5c\u3057\u307e\u3059\u3002</p> <ul> <li>\u8a55\u4fa1\u306e\u6761\u4ef6\u304c\u8a18\u8f09\u3055\u308c\u305f\u30b7\u30ca\u30ea\u30aa\u3092\u30d1\u30c3\u30b1\u30fc\u30b8\u304c\u8aad\u307f\u53d6\u308b</li> <li>autoware \u3092\u8d77\u52d5\u3059\u308b</li> <li>\u8a55\u4fa1\u7d50\u679c\u3092 jsonl \u30d5\u30a1\u30a4\u30eb\u5f62\u5f0f\u3067\u51fa\u529b\u3059\u308b</li> </ul> <p>\u30ce\u30fc\u30c9\u306e\u52d5\u4f5c\u306e\u8a73\u7d30\u3092\u4e0b\u56f3\u306b\u793a\u3059\u3002</p> <p></p>"},{"location":"ja/overview/#_6","title":"\u5229\u7528\u30d5\u30ed\u30fc","text":"<ol> <li>\u8a55\u4fa1\u7528\u306e rosbag \u3092\u5b9f\u8eca\u3067\u53d6\u5f97\u3059\u308b</li> <li>\u53d6\u5f97\u3057\u305f rosbag \u3092\u5fc5\u8981\u306a\u6642\u9593\u3001topic \u3060\u3051\u6b8b\u308b\u3088\u3046\u306b\u30d5\u30a3\u30eb\u30bf\u3059\u308b<ul> <li>\u30d5\u30a3\u30eb\u30bf\u51e6\u7406\u306b\u306f TIER IV \u3067\u958b\u767a\u3057\u305f ros2bag_extensions \u3092\u4f7f\u7528\u3059\u308b</li> <li>\u30d5\u30a3\u30eb\u30bf\u3067\u3069\u306etopic\u3092\u6b8b\u3059\u304b\u306f\u3001docs/use_case/\u306e\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u53c2\u7167</li> </ul> </li> <li>\u30b7\u30ca\u30ea\u30aa\u3092\u4f5c\u6210\u3059\u308b<ol> <li>sample folder \u5185\u306b\u30b7\u30ca\u30ea\u30aa\u306e\u4f8b\u3042\u308a</li> <li>\u8a18\u8ff0\u5185\u5bb9\u306f\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u5b9a\u7fa9\u3092\u53c2\u7167</li> </ol> </li> <li>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u304c obstacle_segmentation, perception, perception_2d, traffic_light \u306e\u5834\u5408\u3001t4_dataset \u3078\u306e\u5909\u63db\u306b\u5bfe\u5fdc\u3057\u305f\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c4\u30fc\u30eb\u3067\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u65bd\u3059\u308b\u3002<ol> <li>Deepen.AI\u304c\u5229\u7528\u53ef\u80fd</li> <li>perception_dataset\u306b\u5909\u63db\u6a5f\u80fd\u3092\u8ffd\u52a0\u3059\u308c\u3070\u4ed6\u306e\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c4\u30fc\u30eb\u3082\u4f7f\u7528\u53ef\u80fd\u306b\u306a\u308b</li> </ol> </li> <li>\u8a55\u4fa1\u3092\u5b9f\u884c\u3059\u308b\u3002</li> </ol>"},{"location":"ja/overview/setup/","title":"\u8a2d\u5b9a","text":"<p>driving_log_replayer \u3092\u5229\u7528\u3059\u308b\u306e\u306b\u5fc5\u8981\u306a\u8a2d\u5b9a\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/overview/setup/#cli","title":"cli \u306e\u8a2d\u5b9a","text":"<p>driving_log_replayer_cli \u3067\u306f\u3001cli \u306b\u6e21\u3059\u5f15\u6570\u3092\u5c11\u306a\u304f\u3059\u308b\u305f\u3081\u306b\u5f15\u6570\u306b\u6307\u5b9a\u3059\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u8f09\u3057\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u8aad\u307f\u8fbc\u3080\u5f62\u5f0f\u3092\u53d6\u308b\u3002</p> <p>\u3088\u3063\u3066 cli \u3092\u4f7f\u3046\u524d\u306b\u4ee5\u4e0b\u306e\u5f62\u5f0f\u3067$HOME/.driving_log_replayer.config.toml \u30d5\u30a1\u30a4\u30eb\u3092\u4f5c\u6210\u3057\u3066\u304a\u304f\u3002 \u624b\u52d5\u3067\u4f5c\u6210\u3001\u3082\u3057\u304f\u306f dlr configuration \u30b3\u30de\u30f3\u30c9\u3067\u4f5c\u6210\u3059\u308b\u3002</p> <pre><code># \u624b\u52d5\u3067\u4f5c\u6210\nnano $HOME/.driving_log_replayer.config.toml\n\n# cli\u3067\u4f5c\u6210\ndlr configuration register -d ${data_directory} -o ${output_directory} -a ${autoware_path} [-p ${profile}]\n</code></pre> <p>profile \u306f\u6700\u4f4e 1 \u3064\u5fc5\u8981\u3067\u30011 \u3064\u306f <code>default</code> \u3068\u3044\u3046\u540d\u524d\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>\u4ee5\u964d\u3067\u8aac\u660e\u3059\u308b\u30b3\u30de\u30f3\u30c9\u3067-p ${profile}\u3067 profile \u540d\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u306b\u6307\u5b9a\u3057\u305f\u8a2d\u5b9a\u304c\u8aad\u307f\u8fbc\u307e\u308c\u308b\u3002 \u8907\u6570\u306e autoware \u3092\u5207\u308a\u66ff\u3048\u3066\u5229\u7528\u3059\u308b\u3053\u3068\u304c\u51fa\u6765\u3001\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3092\u4f55\u3082\u6307\u5b9a\u3057\u306a\u3044\u5834\u5408\u306f default \u304c\u4f7f\u7528\u3055\u308c\u308b\u3002</p> <pre><code>[profile_name]\ndata_directory = \"\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u5165\u529b\u306b\u4f7f\u3046\u30c7\u30fc\u30bf\u30d5\u30a9\u30eb\u30c0\u306e\u30d1\u30b9\"\noutput_directory = \"\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u30d5\u30a9\u30eb\u30c0\u306e\u30d1\u30b9\"\nautoware_path = \"autoware\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306e\u30d1\u30b9\"\n</code></pre> <p>\u8a2d\u5b9a\u4f8b</p> <pre><code># default\u306f\u5fc5\u305a\u5fc5\u8981\u3001profile\u540d\u3092\u7701\u7565\u3057\u305f\u3068\u304d\u306b\u9078\u629e\u3055\u308c\u308b\n[default]\ndata_directory = \"$HOME/driving_log_replayer_data/default\"\noutput_directory = \"$HOME/driving_log_replayer_output/default\"\nautoware_path = \"$HOME/autoware\"\n\n[localization]\ndata_directory = \"$HOME/driving_log_replayer_data/localization\"\noutput_directory = \"$HOME/driving_log_replayer_output/localization\"\nautoware_path = \"$HOME/autoware\"\n\n[yabloc]\ndata_directory = \"$HOME/driving_log_replayer_data/yabloc\"\noutput_directory = \"$HOME/driving_log_replayer_output/yabloc\"\nautoware_path = \"$HOME/autoware\"\n\n[ar_tag_based_localizer]\ndata_directory = \"$HOME/driving_log_replayer_data/ar_tag_based_localizer\"\noutput_directory = \"$HOME/driving_log_replayer_output/ar_tag_based_localizer\"\nautoware_path = \"$HOME/autoware\"\n\n[obstacle_segmentation]\ndata_directory = \"$HOME/driving_log_replayer_data/obstacle_segmentation\"\noutput_directory = \"$HOME/driving_log_replayer_output/obstacle_segmentation\"\nautoware_path = \"$HOME/autoware\"\n\n[perception]\ndata_directory = \"$HOME/driving_log_replayer_data/perception\"\noutput_directory = \"$HOME/driving_log_replayer_output/perception\"\nautoware_path = \"$HOME/autoware\"\n</code></pre>"},{"location":"ja/overview/setup/#_2","title":"\u30d5\u30a9\u30eb\u30c0\u69cb\u6210\u3001\u30d5\u30a1\u30a4\u30eb\u547d\u540d\u898f\u5247","text":"<p>driving_log_replayer \u304c\u671f\u5f85\u3059\u308b\u30d5\u30a9\u30eb\u30c0\u69cb\u6210\u3001\u30d5\u30a1\u30a4\u30eb\u547d\u540d\u898f\u5247\u306b\u3064\u3044\u3066\u89e3\u8aac\u3059\u308b\u3002</p> <p>driving_log_replayer \u3067\u306f\u3001\u30d5\u30a9\u30eb\u30c0\u69cb\u6210\u3001\u30d5\u30a1\u30a4\u30eb\u540d\u306a\u3069\u3092\u56fa\u5b9a\u306b\u3059\u308b\u3053\u3068\u3067\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3059\u308b\u30d1\u30b9\u3084\u3001\u30b3\u30de\u30f3\u30c9\u306b\u6e21\u3059\u5f15\u6570\u3092\u5c11\u306a\u304f\u3057\u3066\u3044\u308b\u3002 \u307e\u305f\u3001<code>data_directory</code> \u306b\u8907\u6570\u306e\u30d5\u30a9\u30eb\u30c0\u3092\u7f6e\u304f\u3053\u3068\u3067\u3001\u8907\u6570\u306e\u30c6\u30b9\u30c8\u3092\u9023\u7d9a\u3067\u5b9f\u884c\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3002</p>"},{"location":"ja/overview/setup/#_3","title":"\u30c7\u30fc\u30bf\u30d5\u30a9\u30eb\u30c0","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u7528\u3059\u308b\u30ea\u30bd\u30fc\u30b9\u3092\u4fdd\u5b58\u3057\u3066\u304a\u304f\u30d5\u30a9\u30eb\u30c0\u3002</p> <p>\u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u6bce\u306b\u3001\u30b7\u30ca\u30ea\u30aa\u3068\u3001bag\u3001dataset \u3092\u914d\u7f6e\u3059\u308b\u3002</p>"},{"location":"ja/overview/setup/#t4_dataset","title":"t4_dataset\u3092\u4f7f\u7528\u3057\u306a\u3044\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u30c7\u30fc\u30bf\u30d5\u30a9\u30eb\u30c0\u69cb\u6210","text":"<pre><code>profile_data_directory                // .driving_log_replayer.config \u306e profile \u6bce\u306edata_directory\n\u2502\n\u251c\u2500\u2500 TC001                          // \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u30c7\u30a3\u30ec\u30af\u30c8\u30ea \u4efb\u610f\u306e\u540d\u79f0\u3092\u3064\u3051\u3066\u3088\u3044\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 scenario.yaml             // \u30b7\u30ca\u30ea\u30aa\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 input_bag                 // \u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u304c\u53ce\u9332\u3055\u308c\u305f\u5165\u529b\u7528\u306ebag\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input_bag_0.db3       // bag\u306e\u30d0\u30a4\u30ca\u30ea\u30d5\u30a1\u30a4\u30eb\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 metadata.yaml         // bag\u306emetadata\n\u2502\n\u251c\u2500\u2500 TC002                           // \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u30c7\u30a3\u30ec\u30af\u30c8\u30ea S001\u3068\u69cb\u6210\u306f\u540c\u3058\n...\n</code></pre>"},{"location":"ja/overview/setup/#t4_dataset_1","title":"t4_dataset\u3092\u4f7f\u7528\u3059\u308b\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u30c7\u30fc\u30bf\u30d5\u30a9\u30eb\u30c0\u69cb\u6210","text":"<pre><code>profile_data_directory                 // .driving_log_replayer.config \u306e data_directory\n\u2502\n\u251c\u2500\u2500 TC001                           // \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u30c7\u30a3\u30ec\u30af\u30c8\u30ea \u4efb\u610f\u306e\u540d\u79f0\u3092\u3064\u3051\u3066\u3088\u3044\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 scenario.yaml              // \u30b7\u30ca\u30ea\u30aa\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 t4_dataset\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 T4D001                 // t4_dataset\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3001sensing\u306e\u5834\u5408\u306f1\u500b\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 annotation\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 LIDAR_CONCAT\n\u2502\u00a0\u00a0     \u2502\u00a0\u00a0 \u2514\u2500\u2500 input_bag\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 T4D002                 // t4_dataset\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3001perception\u306e\u5834\u5408\u306f\u8907\u6570\u500b\u6301\u3066\u308b\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 annotation\n\u2502\u00a0\u00a0         \u251c\u2500\u2500 data\n\u2502\u00a0\u00a0         \u2502\u00a0\u00a0 \u2514\u2500\u2500 LIDAR_CONCAT\n\u2502\u00a0\u00a0         \u2514\u2500\u2500 input_bag\n\u2502          ...\n\u2502\n\u251c\u2500\u2500 TC002                           // \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u30c7\u30a3\u30ec\u30af\u30c8\u30ea S001\u3068\u69cb\u6210\u306f\u540c\u3058\n...\n</code></pre>"},{"location":"ja/overview/setup/#profile","title":"profile\u3067\u5171\u901a\u306e\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u3092\u4f7f\u3044\u307e\u308f\u3059\u5834\u5408","text":"<p>\u540c\u3058\u5730\u56f3\u3001\u8eca\u4e21\u3001\u30bb\u30f3\u30b5\u30fc\u69cb\u6210\u3067\u53d6\u5f97\u3057\u305fbag\u30d5\u30a1\u30a4\u30eb\u3092\u4e00\u3064\u306e\u5171\u901a\u30b7\u30ca\u30ea\u30aa\u3067\u8a55\u4fa1\u3057\u305f\u3044\u5834\u5408\u306b\u4f7f\u7528\u3059\u308b\u3002 annotationless_perception\u3067\u95be\u5024\u3092\u6c7a\u5b9a\u3059\u308b\u305f\u3081\u306b\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u6c42\u3081\u308b\u3060\u3051\u306e\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3092\u5b9f\u884c\u3057\u305f\u3044\u5834\u5408\u306b\u5229\u7528\u3067\u304d\u308b\u3002</p> <p>\u4f8b\u3048\u3070\u3001\u4ee5\u4e0b\u306e\u5834\u5408\u306f\u3001TC001\u306fbase_scenario.yaml\u3067\u8a55\u4fa1\u3055\u308c\u3066\u3001TC002\u306f\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3042\u308bscenario.yaml\u304c\u4f7f\u308f\u308c\u308b</p> <pre><code>profile_data_directory                // .driving_log_replayer.config \u306e data_directory\n\u251c\u2500\u2500 base_scenario.yaml\u3000\u3000\u3000\u3000\u3000\u3000 // \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3057\u306a\u3044\u3068\u304d\u306b\u4f7f\u308f\u308c\u308b\u5171\u901a\u30b7\u30ca\u30ea\u30aa\n\u2502\n\u251c\u2500\u2500 TC001                          // \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u30c7\u30a3\u30ec\u30af\u30c8\u30ea \u4efb\u610f\u306e\u540d\u79f0\u3092\u3064\u3051\u3066\u3088\u3044\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 input_bag                 // \u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u304c\u53ce\u9332\u3055\u308c\u305f\u5165\u529b\u7528\u306ebag\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input_bag_0.db3       // bag\u306e\u30d0\u30a4\u30ca\u30ea\u30d5\u30a1\u30a4\u30eb\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 metadata.yaml         // bag\u306emetadata\n\u2502\n\u251c\u2500\u2500 TC002                          // \u30c6\u30b9\u30c8\u30b1\u30fc\u30b9\u30c7\u30a3\u30ec\u30af\u30c8\u30ea \u4efb\u610f\u306e\u540d\u79f0\u3092\u3064\u3051\u3066\u3088\u3044\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 scenario.yaml             // \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u5185\u306e\u30b7\u30ca\u30ea\u30aa\u30d5\u30a1\u30a4\u30eb\u304c\u4f7f\u7528\u3055\u308c\u308b\u3002base_scenario.yaml\u306f\u7121\u8996\u3055\u308c\u308b\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 input_bag                 // \u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u304c\u53ce\u9332\u3055\u308c\u305f\u5165\u529b\u7528\u306ebag\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 input_bag_0.db3       // bag\u306e\u30d0\u30a4\u30ca\u30ea\u30d5\u30a1\u30a4\u30eb\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 metadata.yaml         // bag\u306emetadata\n...\n</code></pre>"},{"location":"ja/overview/setup/#_4","title":"\u30de\u30c3\u30d7\u30d5\u30a9\u30eb\u30c0","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u3067\u4f7f\u7528\u3059\u308b\u5730\u56f3\u3092\u4fdd\u5b58\u3057\u3066\u304a\u304f\u30d5\u30a9\u30eb\u30c0\u3002</p> <pre><code>autoware_map\n\u2502\n\u251c\u2500\u2500 LocalMapPath1            // \u30b7\u30ca\u30ea\u30aa\u306eLocalMapPath\u3067\u6307\u5b9a\u3059\u308b\u30d1\u30b9\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 lanelet2_map.osm    // lanelet\u30d5\u30a1\u30a4\u30eb\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 pointcloud_map.pcd  // pcd\u30d5\u30a1\u30a4\u30eb\n\u2502\n\u251c\u2500\u2500 LocalMapPath2            // \u30b7\u30ca\u30ea\u30aa\u306eLocalMapPath\u3067\u6307\u5b9a\u3059\u308b\u30d1\u30b9\n...\n</code></pre>"},{"location":"ja/quick_start/annotationless_perception/","title":"Annotationless\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1","text":""},{"location":"ja/quick_start/annotationless_perception/#_1","title":"\u6e96\u5099","text":"<ol> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30b7\u30ca\u30ea\u30aa\u306e\u30b3\u30d4\u30fc</p> <pre><code>mkdir -p ~/driving_log_replayer_data/annotationless_perception/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/annotationless_perception/scenario.yaml ~/driving_log_replayer_data/annotationless_perception/sample\n</code></pre> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30b3\u30d4\u30fc</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_dataset/input_bag ~/driving_log_replayer_data/annotationless_perception/sample\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/annotationless_perception/#_2","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<ol> <li> <p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u884c</p> <pre><code>dlr simulation run -p annotationless_perception -l play_rate:=0.5\n</code></pre> </li> <li> <p>\u7d50\u679c\u306e\u78ba\u8a8d</p> <p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7d50\u679c\u304c\u30bf\u30fc\u30df\u30ca\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002</p> <pre><code>scenario: sample\n--------------------------------------------------\nTestResult: Passed\nPassed:\nCAR (Success)\nBUS (Success)\nPEDESTRIAN (Success)\nBICYCLE (Success)\nMOTORCYCLE (Success)\nTRAILER (Success)\nUNKNOWN (Success)\nTRUCK (Success)\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/ar_tag_based_localizer/","title":"ArTagBasedLocalizer\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u6a5f\u80fd\u306e\u8a55\u4fa1","text":""},{"location":"ja/quick_start/ar_tag_based_localizer/#_1","title":"\u6e96\u5099","text":"<ol> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30b7\u30ca\u30ea\u30aa\u306e\u30b3\u30d4\u30fc</p> <pre><code>mkdir -p ~/driving_log_replayer_data/ar_tag_based_localizer/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/ar_tag_based_localizer/scenario.yaml ~/driving_log_replayer_data/ar_tag_based_localizer/sample\n</code></pre> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306ebag\u3068\u5730\u56f3\u306e\u30b3\u30d4\u30fc</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_bag/ar_tag_based_localizer/input_bag ~/driving_log_replayer_data/ar_tag_based_localizer/sample\ncp -r ~/driving_log_replayer_data/sample_bag/ar_tag_based_localizer/map ~/driving_log_replayer_data/ar_tag_based_localizer/sample\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/ar_tag_based_localizer/#_2","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<ol> <li> <p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u884c</p> <pre><code>dlr simulation run -p ar_tag_based_localizer -l play_rate:=0.5\n</code></pre> </li> <li> <p>\u7d50\u679c\u306e\u78ba\u8a8d</p> <p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7d50\u679c\u304c\u30bf\u30fc\u30df\u30ca\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002</p> <pre><code>test case 1 / 1 : use case: sample\n--------------------------------------------------\nTestResult: Passed\nPassed: ArTagBasedLocalizer Availability (Success): Detected 1 AR tags\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/eagleye/","title":"Eagleye\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u6a5f\u80fd\u306e\u8a55\u4fa1","text":""},{"location":"ja/quick_start/eagleye/#_1","title":"\u6e96\u5099","text":"<ol> <li> <p>\u30b7\u30ca\u30ea\u30aa\u3092\u30b3\u30d4\u30fc\u3059\u308b</p> <pre><code>mkdir -p ~/driving_log_replayer_data/eagleye/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/eagleye/scenario.yaml ~/driving_log_replayer_data/eagleye/sample\n</code></pre> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306ebag\u3092\u30b3\u30d4\u30fc</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_bag/eagleye/input_bag ~/driving_log_replayer_data/eagleye/sample\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/eagleye/#_2","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<ol> <li> <p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u884c</p> <pre><code>dlr simulation run -p eagleye -l play_rate:=0.5\n</code></pre> </li> <li> <p>\u7d50\u679c\u306e\u78ba\u8a8d</p> <p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7d50\u679c\u304c\u30bf\u30fc\u30df\u30ca\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002</p> <pre><code>test case 1 / 1 : use case: sample\n--------------------------------------------------\nTestResult: Passed\nPassed: Eagleye Availability (Passed): OK\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/installation/","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb","text":"<p>AWF Autoware Core/Universe\u3092<code>driving_log_replayer</code>\u3068\u4e00\u7dd2\u306b\u30d3\u30eb\u30c9\u3059\u308b\u65b9\u6cd5\u3092\u89e3\u8aac\u3057\u307e\u3059\u3002</p>"},{"location":"ja/quick_start/installation/#_2","title":"\u30d3\u30eb\u30c9\u65b9\u6cd5","text":"<ol> <li> <p>Autoware workspace \u306b\u79fb\u52d5\u3059\u308b:</p> <pre><code>cd autoware\n</code></pre> </li> <li> <p>\u4f9d\u5b58\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u8ffd\u52a0\u3059\u308b:</p> <pre><code>nano simulator.repos\n# \u4ee5\u4e0b\u306e\u5185\u5bb9\u3092\u8ffd\u52a0\u3059\u308b\n</code></pre> <pre><code>  simulator/perception_eval:\n    type: git\n    url: https://github.com/tier4/autoware_perception_evaluation.git\n    version: main\n  simulator/driving_log_replayer:\n    type: git\n    url: https://github.com/tier4/driving_log_replayer.git\n    version: main\n  simulator/vendor/ros2_numpy:\n    type: git\n    url: https://github.com/Box-Robotics/ros2_numpy.git\n    version: humble\n  simulator/vendor/ros2bag_extensions:\n    type: git\n    url: https://github.com/tier4/ros2bag_extensions.git\n    version: main\n</code></pre> </li> <li> <p>simulator \u306e\u4f9d\u5b58\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u30a4\u30f3\u30dd\u30fc\u30c8\u3059\u308b:</p> <pre><code>vcs import src &lt; simulator.repos\n</code></pre> </li> <li> <p>\u4f9d\u5b58\u89e3\u6c7a\u306e\u305f\u3081\u306b rosdep \u3092\u66f4\u65b0\u3059\u308b:</p> <pre><code>rosdep update\n</code></pre> </li> <li> <p>rosdep \u3067\u4f9d\u5b58\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b:</p> <pre><code>rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n</code></pre> </li> <li> <p>\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092\u30d3\u30eb\u30c9\u3059\u308b:</p> <pre><code>colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE=Release\n</code></pre> </li> <li> <p>driving_log_replayer_cli \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b:</p> <pre><code>pipx install git+https://github.com/tier4/driving_log_replayer.git\n</code></pre> </li> <li> <p>shell\u306e\u88dc\u5b8c\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b:</p> <pre><code># bash\n_DLR_COMPLETE=bash_source dlr &gt; $HOME/.dlr-complete.bash\n_DLR_COMPLETE=bash_source dlr &gt; $HOME/.dlr-analyzer-complete.bash\n\necho \"source $HOME/.dlr-complete.bash\" &gt;&gt; ~/.bashrc\necho \"source $HOME/.dlr-analyzer-complete.bash\" &gt;&gt; ~/.bashrc\n</code></pre> <pre><code># fish\n_DLR_COMPLETE=fish_source dlr &gt; $HOME/.config/fish/completions/dlr.fish\n_DLR_ANALYZER_COMPLETE=fish_source dlr-analyzer &gt; $HOME/.config/fish/completions/dlr-analyzer.fish\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/localization/","title":"NDT\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u6a5f\u80fd\u306e\u8a55\u4fa1","text":""},{"location":"ja/quick_start/localization/#_1","title":"\u6e96\u5099","text":"<ol> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30b7\u30ca\u30ea\u30aa\u306e\u30b3\u30d4\u30fc</p> <pre><code>mkdir -p ~/driving_log_replayer_data/localization/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/localization/scenario.yaml ~/driving_log_replayer_data/localization/sample\n</code></pre> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30b3\u30d4\u30fc</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_dataset/input_bag ~/driving_log_replayer_data/localization/sample\n</code></pre> </li> <li> <p>\u5165\u529b\u306e bag \u30d5\u30a1\u30a4\u30eb\u306e\u30d5\u30a3\u30eb\u30bf\u3068\u30b9\u30e9\u30a4\u30b9\u51e6\u7406</p> <pre><code>source ~/autoware/install/setup.bash\ncd ~/driving_log_replayer_data/localization/sample\nros2 bag filter input_bag -o filtered_bag -x \"/localization/.*\" \"/sensing/lidar/concatenated/pointcloud\" \"/tf\"\nros2 bag slice filtered_bag -o sliced_bag -b 1649138880 -e 1649138910\nrm -rf input_bag\nrm -rf filtered_bag\nmv sliced_bag input_bag\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/localization/#_2","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<ol> <li> <p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u884c</p> <pre><code>dlr simulation run -p localization  -l play_rate:=0.5\n</code></pre> <p></p> </li> <li> <p>\u7d50\u679c\u306e\u78ba\u8a8d</p> <p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7d50\u679c\u304c\u30bf\u30fc\u30df\u30ca\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002  PC \u306e\u6027\u80fd\u3084 CPU \u306e\u8ca0\u8377\u72b6\u6cc1\u306b\u3088\u3063\u3066\u30c6\u30b9\u30c8\u56de\u6570\u304c\u82e5\u5e72\u7570\u306a\u308b\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u591a\u5c11\u306e\u5dee\u306f\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002</p> <pre><code> test case 1 / 1 : use case: sample\n --------------------------------------------------\n TestResult: Passed\n Passed: Convergence (Passed): 281 / 281 -&gt; 100.00%, Reliability (Passed): NVTL Sequential NG Count: 0 (Total Test: 283, Average: 2.476907772225963, StdDev: 0.042055602266257264), NDT Availability (Passed): NDT available\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/obstacle_segmentation/","title":"Obstacle Segmentation \u306e\u8a55\u4fa1","text":""},{"location":"ja/quick_start/obstacle_segmentation/#_1","title":"\u6e96\u5099","text":"<ol> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30b7\u30ca\u30ea\u30aa\u306e\u30b3\u30d4\u30fc</p> <pre><code>mkdir -p ~/driving_log_replayer_data/obstacle_segmentation/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/obstacle_segmentation/scenario.yaml ~/driving_log_replayer_data/obstacle_segmentation/sample\n</code></pre> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30b3\u30d4\u30fc</p> <pre><code>mkdir -p ~/driving_log_replayer_data/obstacle_segmentation/sample/t4_dataset\ncp -r ~/driving_log_replayer_data/sample_dataset ~/driving_log_replayer_data/obstacle_segmentation/sample/t4_dataset\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/obstacle_segmentation/#_2","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<ol> <li> <p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u884c</p> <pre><code>dlr simulation run -p obstacle_segmentation  -l play_rate:=0.5\n</code></pre> <p></p> </li> <li> <p>\u7d50\u679c\u306e\u78ba\u8a8d</p> <p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7d50\u679c\u304c\u30bf\u30fc\u30df\u30ca\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002  PC \u306e\u6027\u80fd\u3084 CPU \u306e\u8ca0\u8377\u72b6\u6cc1\u306b\u3088\u3063\u3066\u30c6\u30b9\u30c8\u56de\u6570\u304c\u82e5\u5e72\u7570\u306a\u308b\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u591a\u5c11\u306e\u5dee\u306f\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002</p> <pre><code> test case 1 / 1 : use case: sample_dataset\n --------------------------------------------------\n TestResult: Failed\n Detection Failed: detection: 557 / 681 -&gt; 81.79% detection_warn: 0 non_detection: 681 / 681 -&gt; 100.00%\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/perception/","title":"\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1","text":""},{"location":"ja/quick_start/perception/#_2","title":"\u6e96\u5099","text":"<ol> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30b7\u30ca\u30ea\u30aa\u306e\u30b3\u30d4\u30fc</p> <pre><code>mkdir -p ~/driving_log_replayer_data/perception/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/perception/scenario.yaml ~/driving_log_replayer_data/perception/sample\n</code></pre> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u30b3\u30d4\u30fc</p> <pre><code>mkdir -p ~/driving_log_replayer_data/perception/sample/t4_dataset\ncp -r ~/driving_log_replayer_data/sample_dataset ~/driving_log_replayer_data/perception/sample/t4_dataset\n</code></pre> </li> <li> <p>\u6a5f\u68b0\u5b66\u7fd2\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u306e\u5909\u63db\u3092\u884c\u3046</p> <pre><code>source ~/autoware/install/setup\nros2 launch autoware_launch logging_simulator.launch.xml map_path:=$HOME/autoware_map/sample-map-planning vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit\n# ~/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data\u306b\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u3067\u304d\u308b\u307e\u3067\u5f85\u3064\n# - pts_backbone_neck_head_centerpoint_tiny.engine\n# - pts_voxel_encoder_centerpoint_tiny.engine\n# \u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u305f\u3089Ctrl+C\u3067launch\u3092\u6b62\u3081\u308b\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/perception/#_3","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<ol> <li> <p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u884c</p> <pre><code>dlr simulation run -p perception  -l play_rate:=0.5\n</code></pre> <p></p> </li> <li> <p>\u7d50\u679c\u306e\u78ba\u8a8d</p> <p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7d50\u679c\u304c\u30bf\u30fc\u30df\u30ca\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002  PC \u306e\u6027\u80fd\u3084 CPU \u306e\u8ca0\u8377\u72b6\u6cc1\u306b\u3088\u3063\u3066\u30c6\u30b9\u30c8\u56de\u6570\u304c\u82e5\u5e72\u7570\u306a\u308b\u3053\u3068\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u591a\u5c11\u306e\u5dee\u306f\u554f\u984c\u3042\u308a\u307e\u305b\u3093\u3002</p> <pre><code>scenario: sample_dataset\n--------------------------------------------------\nTestResult: Passed\nPassed: criteria0 (Success): 215 / 215 -&gt; 100.00%, Passed: NotTested\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/setup/","title":"\u8a2d\u5b9a","text":"<p>Note</p> <p>Driving Log Replayer\u3092\u5b9f\u884c\u3059\u308b\u306b\u306f\u3001Autoware\u306e\u30d3\u30eb\u30c9\u3068\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u306b\u52a0\u3048\u3066\u3001Driving Log Replayer\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb \u304c\u5b8c\u4e86\u3057\u3066\u3044\u308b\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</p> <p>Sample map: Copyright 2020 TIER IV, Inc.</p> <p>Sample Dataset: Copyright 2022 TIER IV, Inc.</p>"},{"location":"ja/quick_start/setup/#_2","title":"\u30ea\u30bd\u30fc\u30b9\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7","text":"<ol> <li> <p>\u5730\u56f3\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3068\u89e3\u51cd</p> <pre><code># annotationless_perception, localization, obstacle_segmentation, perception\nmkdir -p ~/autoware_map\ngdown -O ~/autoware_map/sample-map-planning.zip 'https://docs.google.com/uc?export=download&amp;id=1499_nsbUbIeturZaDj7jhUownh5fvXHd'\nunzip -d ~/autoware_map ~/autoware_map/sample-map-planning.zip\n\n# yabloc, eagleye\nwget -O ~/autoware_map/nishishinjuku_autoware_map.zip https://github.com/tier4/AWSIM/releases/download/v1.1.0/nishishinjuku_autoware_map.zip\nunzip -d ~/autoware_map ~/autoware_map/nishishinjuku_autoware_map.zip\n</code></pre> <p>\u30d6\u30e9\u30a6\u30b6\u304b\u3089\u624b\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3053\u3068\u3082\u53ef\u80fd\u3067\u3059\u3002  sample-map-planning nishishinjuku_autoware_map</p> </li> <li> <p>\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u30c0\u30a6\u30ed\u30fc\u30c9\u3068\u89e3\u51cd</p> <pre><code># annotationless_perception, localization, obstacle_segmentation, perception\nmkdir -p ~/driving_log_replayer_data\ngdown -O ~/driving_log_replayer_data/sample_dataset_v2.tar.zst 'https://docs.google.com/uc?export=download&amp;id=1iCoykBBETI_rGfKEFYYb7LFydF-RJVkC'\ntar -I zstd -xvf ~/driving_log_replayer_data/sample_dataset_v2.tar.zst -C ~/driving_log_replayer_data/\n\n# yabloc, eagleye, artag\ngdown -O ~/driving_log_replayer_data/sample_bag.tar.zst 'https://docs.google.com/uc?export=download&amp;id=17ppdMKi4IC8J_2-_9nyYv-LAfW0M1re5'\ntar -I zstd -xvf ~/driving_log_replayer_data/sample_bag.tar.zst -C ~/driving_log_replayer_data/\n</code></pre> <p>\u30d6\u30e9\u30a6\u30b6\u304b\u3089\u624b\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3059\u308b\u3053\u3068\u3082\u53ef\u80fd\u3067\u3059\u3002  \u30c7\u30fc\u30bf\u30bb\u30c3\u30c8 bag</p> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u8a2d\u5b9a\u3092\u30b3\u30d4\u30fc\u3059\u308b</p> <pre><code># assuming that autoware is placed under ~/autoware directory\ncp ~/autoware/src/simulator/driving_log_replayer/sample/.driving_log_replayer.config.toml ~/\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/yabloc/","title":"YabLoc\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u6a5f\u80fd\u306e\u8a55\u4fa1","text":""},{"location":"ja/quick_start/yabloc/#_1","title":"\u6e96\u5099","text":"<ol> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306e\u30b7\u30ca\u30ea\u30aa\u306e\u30b3\u30d4\u30fc</p> <pre><code>mkdir -p ~/driving_log_replayer_data/yabloc/sample\ncp -r ~/autoware/src/simulator/driving_log_replayer/sample/yabloc/scenario.yaml ~/driving_log_replayer_data/yabloc/sample\n</code></pre> </li> <li> <p>\u30b5\u30f3\u30d7\u30eb\u306ebag\u3092\u30b3\u30d4\u30fc</p> <pre><code>cp -r ~/driving_log_replayer_data/sample_bag/yabloc/input_bag ~/driving_log_replayer_data/yabloc/sample\n</code></pre> </li> </ol>"},{"location":"ja/quick_start/yabloc/#_2","title":"\u5b9f\u884c\u65b9\u6cd5","text":"<ol> <li> <p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u5b9f\u884c</p> <pre><code>dlr simulation run -p yabloc -l play_rate:=0.5\n</code></pre> </li> <li> <p>\u7d50\u679c\u306e\u78ba\u8a8d</p> <p>\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u7d50\u679c\u304c\u30bf\u30fc\u30df\u30ca\u30eb\u306b\u8868\u793a\u3055\u308c\u307e\u3059\u3002</p> <pre><code>test case 1 / 1 : use case: sample\n--------------------------------------------------\nTestResult: Passed\nPassed: YabLoc Availability (Passed): OK\n</code></pre> </li> </ol>"},{"location":"ja/result_format/","title":"Driving Log Replayer \u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>1 \u884c\u6bce\u306b json \u5f62\u5f0f\u306e\u6587\u5b57\u5217\u304c\u5165\u3063\u3066\u3044\u308b jsonl \u5f62\u5f0f\u3068\u306a\u3063\u3066\u3044\u308b\u3002</p>"},{"location":"ja/result_format/#_1","title":"\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u5404\u884c\u4ee5\u4e0b\u306e\u5f62\u5f0f\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u51fa\u529b\u3055\u308c\u308b\u3002 \u5b9f\u969b\u306b\u306f\u4e00\u884c\u306e\u6587\u5b57\u5217\u3060\u304c\u307f\u3084\u3059\u3055\u306e\u305f\u3081\u306b\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3057\u3066\u3044\u308b\u3002</p> <pre><code>{\n  \"Result\": {\n    \"Success\": \"true or false\",\n    \"Summary\": \"\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u306e\u8981\u7d04\"\n  },\n  \"Stamp\": {\n    \"System\": \"PC\u306e\u6642\u523b\",\n    \"ROS\": \"\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u6642\u523b\"\n  },\n  \"Frame\": {\n    \"Ego\": { \"TransformStamped\": \"map\u304b\u3089base_link\u3078\u306etransform_stamped\" },\n    \"\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u6bce\u306b\u69cb\u6210\u304c\u7570\u306a\u308b\": \"...\"\n  }\n}\n</code></pre> <p>\u7d50\u679c\u51fa\u529b\u306f\u4ee5\u4e0b\u306e\u5c5e\u6027\u304b\u3089\u69cb\u6210\u3055\u308c\u308b\u3002</p> <ul> <li>Result: \u5b9f\u884c\u3057\u305f\u30b7\u30ca\u30ea\u30aa\u306e\u8a55\u4fa1\u7d50\u679c</li> <li>Stamp: \u8a55\u4fa1\u3057\u305f\u6642\u523b</li> <li>Frame: \u53d7\u3051\u53d6\u3063\u305f frame(topic) 1 \u56de\u5206\u306e\u8a55\u4fa1\u7d50\u679c\u3068\u3001\u5224\u5b9a\u306b\u4f7f\u7528\u3057\u305f\u5024\u306a\u3069\u306e\u4ed8\u5c5e\u60c5\u5831</li> </ul> <p>Frame \u306e\u8a73\u7d30\u306b\u3064\u3044\u3066\u306f\u3001\u5404\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u8a55\u4fa1\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u53c2\u7167\u3002</p>"},{"location":"ja/result_format/#_2","title":"\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u306e\u5206\u6790","text":"<p>vscode\u306eJSONL Converter\u3092\u7528\u3044\u308b\u3068\u30dc\u30bf\u30f3\u3092\u62bc\u3059\u3060\u3051\u3067\u5bb9\u6613\u306bjsonl &lt;-&gt; json\u306e\u5909\u63db\u304c\u3067\u304d\u308b</p> <p>https://marketplace.visualstudio.com/items?itemName=F-loat.jsonl-converter</p> <p>python \u3092\u7528\u3044\u308b\u5834\u5408\u306f\u3001pandas.read_json \u3067 lines=True \u3068\u3059\u308b\u3068 jsonl \u3092\u8aad\u307f\u8fbc\u3080\u3053\u3068\u304c\u3067\u304d\u308b</p>"},{"location":"ja/scenario_format/","title":"Driving Log Replayer \u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u5b9a\u7fa9","text":"<p>driving_log_replayer \u3067\u7528\u3044\u308b\u30b7\u30ca\u30ea\u30aa\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u3064\u3044\u3066\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/scenario_format/#_1","title":"\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306b\u95a2\u3059\u308b\u6ce8\u610f\u4e8b\u9805","text":"<ul> <li>\u30ad\u30fc\u306f CamelCase \u306b\u3066\u5b9a\u7fa9\u3059\u308b\u3002</li> <li>\u5ea7\u6a19\u7cfb\u306b\u95a2\u3057\u3066\u306f\u3001 <code>map</code> \u5ea7\u6a19\u7cfb\u3092\u4f7f\u7528\u3059\u308b</li> <li>\u5358\u4f4d\u7cfb\u306b\u95a2\u3057\u3066\u306f\u3001\u7279\u306b\u6307\u5b9a\u304c\u306a\u3051\u308c\u3070\u4ee5\u4e0b\u3092\u4f7f\u7528\u3059\u308b\u3002</li> </ul> <pre><code>\u8ddd\u96e2: m\n\u901f\u5ea6: m/s\n\u52a0\u901f\u5ea6: m/s^2\n\u6642\u9593: s\n</code></pre>"},{"location":"ja/scenario_format/#_2","title":"\u30b5\u30f3\u30d7\u30eb","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306e\u30b5\u30f3\u30d7\u30eb\u3092sample \u30d5\u30a9\u30eb\u30c0\u306b\u7f6e\u3044\u3066\u3044\u308b\u3002</p>"},{"location":"ja/scenario_format/#_3","title":"\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u57fa\u672c\u69cb\u9020\u306f\u4ee5\u4e0b\u306e\u901a\u308a\u3002\u5404\u30ad\u30fc\u306e\u8a73\u7d30\u306f\u4ee5\u4e0b\u3067\u8a18\u8ff0\u3059\u308b\u3002</p>"},{"location":"ja/scenario_format/#2xx","title":"2.x.x \u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p><code>localization</code>\u3001 <code>performance_diag</code>\u3001 <code>yabloc</code>\u3001 <code>eagleye</code>\u3001 <code>ar_tag_based_localizer</code>\u3067\u4f7f\u7528\u3059\u308b\u3002</p> <pre><code>ScenarioFormatVersion: 2.x.x\nScenarioName: String\nScenarioDescription: String\nSensorModel: String\nVehicleModel: String\nVehicleId: String\nLocalMapPath: String\nEvaluation:\n  UseCaseName: String\n  UseCaseFormatVersion: String\n  Conditions: Dictionary # refer use case\n</code></pre>"},{"location":"ja/scenario_format/#3xx","title":"3.x.x \u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p><code>perception</code> \u3068 <code>obstacle_segmentation</code> \u3067\u4f7f\u7528\u3059\u308b\u3002</p> <p>\u6ce8\u610f: VehicleId \u3068 LocalMapPath \u304c t4_dataset \u306e id \u6bce\u306b\u8a2d\u5b9a\u3059\u308b\u3088\u3046\u306b\u5909\u66f4\u3055\u308c\u3066\u3044\u308b\u3002</p> <pre><code>ScenarioFormatVersion: 3.x.x\nScenarioName: String\nScenarioDescription: String\nSensorModel: String\nVehicleModel: String\nEvaluation:\n  UseCaseName: String\n  UseCaseFormatVersion: String\n  Datasets:\n    - DatasetName:\n        VehicleId: String\n        LocalMapPath: String\n  Conditions: Dictionary # refer use case\n</code></pre>"},{"location":"ja/scenario_format/#scenarioformatversion","title":"ScenarioFormatVersion","text":"<p>\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u3092\u8a18\u8ff0\u3059\u308b\u3002\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u7528\u3044\u308b\u3002</p> <p><code>localization</code> \u3068 <code>performance_diag</code> \u3068 <code>yabloc</code> \u3068 <code>eagleye</code> \u3068 <code>ar_tag_based_localizer</code> \u306f 2.x.x \u7cfb\u3092\u4f7f\u7528\u3059\u308b\u30022.x.x \u306e\u6700\u65b0\u30d0\u30fc\u30b8\u30e7\u30f3\u306f 2.2.0 <code>perception</code> \u3068 <code>obstacle_segmentation</code> \u306f 3.x.x \u7cfb\u3092\u4f7f\u7528\u3059\u308b\u30023.x.x \u306e\u6700\u65b0\u30d0\u30fc\u30b8\u30e7\u30f3\u306f 3.0.0</p> <p>\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u66f4\u65b0\u306e\u5ea6\u306b\u30de\u30a4\u30ca\u30fc\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u66f4\u65b0\u3059\u308b\u3002</p>"},{"location":"ja/scenario_format/#scenarioname","title":"ScenarioName","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306e\u540d\u524d\u3092\u8a18\u8ff0\u3059\u308b\u3002Autoware Evaluator \u4e0a\u3067\u30b7\u30ca\u30ea\u30aa\u306e\u8868\u793a\u540d\u3068\u3057\u3066\u4f7f\u7528\u3055\u308c\u308b\u3002</p>"},{"location":"ja/scenario_format/#scenariodescription","title":"ScenarioDescription","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306e\u8aac\u660e\u3092\u8a18\u8ff0\u3059\u308b\u3002Autoware Evaluator \u4e0a\u3067\u30b7\u30ca\u30ea\u30aa\u306e\u8aac\u660e\u3068\u3057\u3066\u4f7f\u7528\u3055\u308c\u308b\u3002</p>"},{"location":"ja/scenario_format/#sensormodel","title":"SensorModel","text":"<p>autoware_launch/launch/logging_simulator.launch.xml \u306e\u5f15\u6570\u306e sensor_model \u3092\u6307\u5b9a\u3059\u308b</p>"},{"location":"ja/scenario_format/#vehiclemodel","title":"VehicleModel","text":"<p>autoware_launch/launch/logging_simulator.launch.xml \u306e\u5f15\u6570\u306e vehicle_model \u3092\u6307\u5b9a\u3059\u308b</p>"},{"location":"ja/scenario_format/#vehicleid","title":"VehicleId","text":"<p>autoware_launch/launch/logging_simulator.launch.xml \u306e\u5f15\u6570\u306e vehicle_id \u3092\u6307\u5b9a\u3059\u308b\u3002</p> <p>\u8eca\u4e21 ID \u304c\u4e0d\u660e\u306a\u5834\u5408\u306f\u3001<code>default</code> \u3092\u8a2d\u5b9a\u3059\u308b\u3002</p>"},{"location":"ja/scenario_format/#localmappath","title":"LocalMapPath","text":"<p>\u30ed\u30fc\u30ab\u30eb\u74b0\u5883\u3067\u4f7f\u7528\u3059\u308b\u5730\u56f3\u306e\u30d5\u30a9\u30eb\u30c0\u306e\u30d1\u30b9\u3092\u8a18\u8ff0\u3059\u308b\u3002</p> <p><code>$HOME</code>\u306e\u3088\u3046\u306a\u74b0\u5883\u5909\u6570\u3092\u4f7f\u7528\u3059\u308b\u3053\u3068\u304c\u51fa\u6765\u308b\u3002</p>"},{"location":"ja/scenario_format/#evaluation","title":"Evaluation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u306e\u8a55\u4fa1\u6761\u4ef6\u3092\u5b9a\u7fa9\u3059\u308b\u3002</p>"},{"location":"ja/scenario_format/#usecasename","title":"UseCaseName","text":"<p>\u8a55\u4fa1\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u6307\u5b9a\u3059\u308b\u3002</p> <p>\u3053\u3053\u3067\u6307\u5b9a\u3055\u308c\u305f\u540d\u524d\u3068\u540c\u3058\u540d\u524d\u306e launch \u30d5\u30a1\u30a4\u30eb\u3092\u547c\u3073\u51fa\u3059\u3053\u3068\u3067\u8a55\u4fa1\u304c\u5b9f\u884c\u3055\u308c\u308b\u3002 driving_log_replayer/launch \u306b\u6307\u5b9a\u3057\u305f\u540d\u79f0\u3068\u540c\u3058\u540d\u79f0\u306e launch.py \u30d5\u30a1\u30a4\u30eb\u304c\u5b58\u5728\u3057\u3066\u3044\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p>"},{"location":"ja/scenario_format/#usecaseformatversion","title":"UseCaseFormatVersion","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u60c5\u5831\u3092\u8a18\u8ff0\u3059\u308b\u3002\u30bb\u30de\u30f3\u30c6\u30a3\u30c3\u30af\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u7528\u3044\u308b\u3002 \u30e1\u30b8\u30e3\u30fc\u30d0\u30fc\u30b8\u30e7\u30f3\u304c 1 \u306b\u306a\u308b\u307e\u3067\u306f\u3001\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u306e\u66f4\u65b0\u306e\u5ea6\u306b\u30de\u30a4\u30ca\u30fc\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u66f4\u65b0\u3059\u308b\u3002\u521d\u671f\u30d0\u30fc\u30b8\u30e7\u30f3\u306f 0.1.0\u3002</p>"},{"location":"ja/scenario_format/#conditions","title":"Conditions","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u6bce\u306b\u8a2d\u5b9a\u3067\u304d\u308b\u6761\u4ef6\u3092\u6307\u5b9a\u3059\u308b\u3002</p> <p>\u6307\u5b9a\u53ef\u80fd\u306a\u6761\u4ef6\u306f\u5404\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u3092\u53c2\u7167\u3002</p>"},{"location":"ja/trouble_shooting/","title":"\u30c8\u30e9\u30d6\u30eb\u30b7\u30e5\u30fc\u30c6\u30a3\u30f3\u30b0","text":"<p>\u671f\u5f85\u901a\u308a\u306b\u52d5\u304b\u306a\u3044\u5834\u5408\u306b\u78ba\u8a8d\u3059\u308b</p>"},{"location":"ja/trouble_shooting/#autoware","title":"Autoware\u304c\u8d77\u52d5\u3057\u306a\u3044","text":""},{"location":"ja/trouble_shooting/#1","title":"\u539f\u56e01","text":"<p>\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305fsensor_model\u3001vehicle_model\u3001vehicle_id\u304c\u5229\u7528\u3059\u308bAutoware\u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u306b\u542b\u307e\u308c\u3066\u3044\u306a\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#1_1","title":"\u4f8b1","text":"<pre><code>\u276f dlr simulation run -p localization\n[INFO] [launch]: All log files can be found below /home/hyt/.ros/log/2024-06-07-12-37-19-365597-dpc2405001-1360746\n[INFO] [launch]: Default logging verbosity is set to INFO\n1717731451.040883 [77]       ros2: determined eno1 (udp/10.0.55.137) as highest quality interface, selected for automatic interface.\n[ERROR] [launch]: Caught exception in launch (see debug for traceback): executed command failed. Command: xacro /home/hyt/ros_ws/pilot-auto/install/tier4_vehicle_launch/share/tier4_vehicle_launch/urdf/vehicle.xacro vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit config_dir:=/home/hyt/ros_ws/pilot-auto/install/individual_params/share/individual_params/config/default/sample_sensor_kit\nCaptured stderr output: error: package not found: \"package 'sample_sensor_kit_description' not found, searching: ...\n...\n</code></pre>"},{"location":"ja/trouble_shooting/#1_2","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401","text":"<p>\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u3067\u6307\u5b9a\u3057\u3066\u3044\u308bautoware_path\u306b\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u3001sensor_model\u3001vehicle_model\u3001vehicle_id\u304c\u5b58\u5728\u3059\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/trouble_shooting/#2","title":"\u539f\u56e02","text":"<p>cli\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304cdriving_log_replayer\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3068\u4e00\u81f4\u3057\u3066\u3044\u306a\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#2_1","title":"\u4f8b2","text":"<pre><code>\u276f dlr simulation run -p yabloc -l play_rate:=0.5\nUsage: dlr simulation run [OPTIONS]\nTry 'dlr simulation run -h' for help.\n\nError: No such option: -l\n</code></pre>"},{"location":"ja/trouble_shooting/#2_2","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62402","text":"<p>install\u3055\u308c\u3066\u3044\u308bdriving_log_replayer\u306epackage.xml\u306eversion\u30bf\u30b0\u306e\u5024\u3068\u3001cli\u304c\u51fa\u529b\u3059\u308bversion\u304c\u4e00\u81f4\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p> <pre><code>\u276f dlr --version\n1.18.0\n</code></pre>"},{"location":"ja/trouble_shooting/#autoware_1","title":"Autoware\u8d77\u52d5\u5f8c\u3059\u3050\u306b\u7d42\u4e86\u3057\u3066\u3057\u307e\u3046","text":""},{"location":"ja/trouble_shooting/#_2","title":"\u539f\u56e0","text":"<p>\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u304c\u4e0d\u6b63</p>"},{"location":"ja/trouble_shooting/#_3","title":"\u4f8b","text":"<p>\u30b3\u30f3\u30bd\u30fc\u30eb\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u51fa\u529b\u3055\u308c\u308b\u3002 \u307e\u305f\u3001\u540c\u69d8\u306e\u5185\u5bb9\u304cresult.jsonl\u306b\u51fa\u529b\u3055\u308c\u308b</p> <pre><code>[localization_evaluator_node.py-55] [ERROR] [1717734608.157798307] [driving_log_replayer.localization_evaluator]: An error occurred while loading the scenario. 1 validation error for LocalizationScenario\n[localization_evaluator_node.py-55] Evaluation.UseCaseFormatVersion\n[localization_evaluator_node.py-55]   Input should be '1.2.0' or '1.3.0' [type=literal_error, input_value='1.0.0', input_type=str]\n[localization_evaluator_node.py-55]     For further information visit https://errors.pydantic.dev/2.7/v/literal_error\n\nscenario: direct\n--------------------------------------------------\nTestResult: Failed\nScenarioFormatError\n--------------------------------------------------\n</code></pre> <pre><code>{\"Condition\":{}}\n{\"Result\":{\"Success\":false,\"Summary\":\"NoData\"},\"Stamp\":{\"System\":1717734608.157981},\"Frame\":{}}\n{\"Result\":{\"Success\":false,\"Summary\":\"ScenarioFormatError\"},\"Stamp\":{\"System\":0},\"Frame\":{\"ErrorMsg\":\"1 validation error for LocalizationScenario\\nEvaluation.UseCaseFormatVersion\\n  Input should be '1.2.0' or '1.3.0' [type=literal_error, input_value='1.0.0', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.7/v/literal_error\"}}\n</code></pre>"},{"location":"ja/trouble_shooting/#_4","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u6240","text":"<p>result.jsonl\u306b\u4f55\u304c\u554f\u984c\u304b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u6307\u793a\u901a\u308a\u6cbb\u3059\u3002 \u4f8b\u3060\u3068\u3001UseCaseFormatVersion\u306f1.2.0\u304b1.3.0\u3067\u3042\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u306b\u30011.0.0\u306a\u306e\u3067\u5229\u7528\u3067\u304d\u306a\u3044\u3002 \u53e4\u3044\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u5229\u7528\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u30ea\u30dd\u30b8\u30c8\u30ea\u306esample\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u3042\u308b\u30b7\u30ca\u30ea\u30aa\u3092\u53c2\u8003\u306b\u4fee\u6b63\u3059\u308b\u3002</p>"},{"location":"ja/trouble_shooting/#nodata","title":"\u8a55\u4fa1\u7d50\u679c\u304cNoData\u3068\u306a\u308b","text":""},{"location":"ja/trouble_shooting/#1_3","title":"\u539f\u56e01","text":"<p>Autoware\u304b\u3089\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u306a\u3044</p>"},{"location":"ja/trouble_shooting/#1-1","title":"\u4f8b1-1","text":"<p>\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u3092\u51fa\u529b\u3059\u308b\u30ce\u30fc\u30c9\u304claunch\u304b\u3089\u8d77\u52d5\u3055\u308c\u3066\u3044\u306a\u3044 launch\u30d5\u30a1\u30a4\u30eb\u306etrue/false\u306e\u5024\u306e\u8a2d\u5b9a\u9593\u9055\u3044</p>"},{"location":"ja/trouble_shooting/#1-1_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401-1","text":"<p>\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u3092\u30c9\u30ad\u30e5\u30e1\u30f3\u30c8\u304b\u3089\u63a2\u3057\u3066\u3001topic info\u3057\u3066publisher\u304c\u5b58\u5728\u3059\u308b\u304b\u78ba\u8a8d\u3059\u308b Publisher count: 0\u306e\u5834\u5408\u306f\u3001\u305d\u3082\u305d\u3082\u8d77\u52d5\u3067\u304d\u3066\u306a\u3044\u53ef\u80fd\u6027\u304c\u9ad8\u3044\u3002</p> <pre><code>\u276f ros2 topic info /perception/traffic_light_recognition/traffic_signals -v\nType: autoware_auto_perception_msgs/msg/TrafficSignalArray\n\nPublisher count: 1 &lt;- 0\u3058\u3083\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\n\nNode name: crosswalk_traffic_light_estimator\nNode namespace: /perception/traffic_light_recognition\nTopic type: autoware_auto_perception_msgs/msg/TrafficSignalArray\nEndpoint type: PUBLISHER\nGID: 01.10.d8.43.57.21.7c.2d.98.25.db.df.00.00.46.03.00.00.00.00.00.00.00.00\nQoS profile:\n  Reliability: RELIABLE\n  History (Depth): KEEP_LAST (1)\n  Durability: VOLATILE\n  Lifespan: Infinite\n  Deadline: Infinite\n  Liveliness: AUTOMATIC\n  Liveliness lease duration: Infinite\n</code></pre>"},{"location":"ja/trouble_shooting/#1-2","title":"\u4f8b1-2","text":"<p>\u30ce\u30fc\u30c9\u304claunch\u3067\u8d77\u52d5\u306f\u3057\u3066\u3044\u308b\u304c\u3001\u8d77\u52d5\u5f8c\u3059\u3050\u306b\u6b7b\u3093\u3067\u3044\u308b</p>"},{"location":"ja/trouble_shooting/#1-2_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401-2","text":"<p>\u8d77\u52d5\u3057\u305f\u30bf\u30fc\u30df\u30ca\u30eb\u3001\u307e\u305f\u306f\u3001console.log\u3092ERROR\u3067\u691c\u7d22\u3059\u308b\u3002</p> <p>\u4ee5\u4e0b\u306f\u3001\u70b9\u7fa4\u304c\u4e00\u5207\u51fa\u306a\u304b\u3063\u305f\u30b1\u30fc\u30b9\u306e\u30ed\u30b0\u3067\u3042\u308b\u3002 ERROR\u3067\u691c\u7d22\u3059\u308b\u3068pointcloud_preprocessor\u304c\u6b7b\u3093\u3067\u3044\u308b\u3053\u3068\u304c\u308f\u304b\u308b\u3002 topic\u3092\u51fa\u529b\u3059\u308bcomponent_container\u304c\u30a8\u30e9\u30fc\u3092\u5410\u3044\u3066\u306a\u3044\u304b\u78ba\u8a8d\u3059\u308b\u3002</p> <pre><code>[ERROR] [component_container_mt-18]: process has died [pid 95, exit code -6, cmd '/opt/ros/galactic/lib/rclcpp_components/component_container_mt --ros-args -r __node:=pointcloud_preprocessor_container -r __ns:=/sensing/lidar/pointcloud_preprocessor --params-file /tmp/launch_params_rh_9gxcs'].\n</code></pre>"},{"location":"ja/trouble_shooting/#1-3","title":"\u4f8b1-3","text":"<p>cuda, cuDNN, TensorRT\u306e\u4e0d\u6574\u5408\u304c\u767a\u751f\u3057\u3066\u7d50\u679c\u3068\u3057\u3066\u3001perception\u306e\u8a8d\u8b58\u7d50\u679c\u304c\u51fa\u3066\u3053\u306a\u3044\u3002 apt upgrade\u3067nvidia driver\u304c\u66f4\u65b0\u3055\u308c\u305f\u3068\u304d\u306b\u767a\u751f\u3059\u308b\u3053\u3068\u304c\u3042\u308b\u3002</p> <pre><code>hyt@dpc1909014-2204:~/ros_ws/awf$ ros2 launch lidar_centerpoint lidar_centerpoint.launch.xml model_name:=centerpoint_tiny model_path:=/home/hyt/autoware_data/lidar_centerpoint model_param_path:=$(ros2 pkg prefix lidar_centerpoint --share)/config/centerpoint_tiny.param.yaml build_only:=true\n[INFO] [launch]: All log files can be found below /home/hyt/.ros/log/2024-01-22-14-36-04-069409-dpc1909014-2204-3835027\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [lidar_centerpoint_node-1]: process started with pid [3835028]\n[lidar_centerpoint_node-1] 1705901764.307868 [77] lidar_cent: determined enp4s0 (udp/10.0.53.59) as highest quality interface, selected for automatic interface.\n[lidar_centerpoint_node-1] terminate called after throwing an instance of 'thrust::system::system_error'\n[lidar_centerpoint_node-1]   what():  This program was not compiled for SM 75\n[lidar_centerpoint_node-1] : cudaErrorInvalidDevice: invalid device ordinal\n[ERROR] [lidar_centerpoint_node-1]: process has died [pid 3835028, exit code -6, cmd '/home/hyt/ros_ws/awf/install/lidar_centerpoint/lib/lidar_centerpoint/lidar_centerpoint_node --ros-args -r __node:=lidar_centerpoint --params-file /tmp/launch_params_60_o26mq --params-file /tmp/launch_params_79jodq9o --params-file /tmp/launch_params_spwl7uq2 --params-file /tmp/launch_params_ur_yt_y2 --params-file /tmp/launch_params_iqs0hf9o --params-file /tmp/launch_params_t6bo4aow --params-file /tmp/launch_params_ufdn98_7 --params-file /tmp/launch_params_7m7aj130 --params-file /tmp/launch_params_yr4emr64 --params-file /tmp/launch_params_u4_e0ngh --params-file /home/hyt/ros_ws/awf/install/lidar_centerpoint/share/lidar_centerpoint/config/centerpoint_tiny.param.yaml --params-file /home/hyt/ros_ws/awf/install/lidar_centerpoint/share/lidar_centerpoint/config/detection_class_remapper.param.yaml -r ~/input/pointcloud:=/sensing/lidar/pointcloud -r ~/output/objects:=objects'].\n</code></pre>"},{"location":"ja/trouble_shooting/#1-3_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401-3","text":"<p>cudaErrorInvalidDevice: invalid device ordinal\u304c\u51fa\u3066\u306a\u3044\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u51fa\u3066\u3044\u305f\u3089\u3001nvidia-driver, cuda, cuDNN, TensorRT\u3092\u518d\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3059\u308b\u3002</p> <pre><code>sudo apt-mark unhold cuda-*\nsudo apt-mark unhold nvidia-*\nsudo apt-mark unhold libcudnn*\nsudo apt-mark unhold libnv*\n\nsudo apt purge cuda-*\nsudo apt purge nvidia-*\nsudo apt purge libcudnn*\nsudo apt purge libnv*\n\n# install nvidia driver and run Autoware's setup-dev-env.sh\n</code></pre>"},{"location":"ja/trouble_shooting/#2_3","title":"\u539f\u56e02","text":"<p>Autoware\u304b\u3089\u8a55\u4fa1\u5bfe\u8c61\u306etopic\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304c\u30ce\u30fc\u30c9\u304csubscribe\u3067\u304d\u306a\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#2-1","title":"\u4f8b2-1","text":"<p>QoS\u306e\u4e0d\u4e00\u81f4\u3067\u53d6\u5f97\u3067\u304d\u3066\u3044\u306a\u3044</p> <pre><code>[component_container_mt-13] [WARN 1633081042.510824100] [localization.util.random_downsample_filter]: New subscription discovered on topic '/localization/util/downsample/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n[component_container_mt-19] [WARN 1633081042.593132498] [sensing.lidar.occupancy_grid_map_outlier_filter]: New subscription discovered on topic '/sensing/lidar/no_ground/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n[component_container_mt-19] [WARN 1633081042.597116410] [sensing.lidar.concatenate_data]: New subscription discovered on topic '/sensing/lidar/concatenated/pointcloud', requesting incompatible QoS. No messages will be sent to it. Last incompatible policy: RELIABILITY_QOS_POLICY\n</code></pre>"},{"location":"ja/trouble_shooting/#2-1_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62402-1","text":"<p>\u8d77\u52d5\u3057\u305f\u30bf\u30fc\u30df\u30ca\u30eb\u3082\u3057\u304f\u306f\u3001console.log\u3092QoS\u3067\u691c\u7d22\u3059\u308b\u3002</p> <p>Autoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3068driving_log_replayer\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u5bfe\u5fdc\u3057\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 Autoware Foundation\u306emain\u3068driving_log_replayer\u306emain\u3092\u4f7f\u7528\u3057\u3066\u3001\u3053\u306e\u554f\u984c\u304c\u767a\u751f\u3057\u3066\u3044\u308b\u5834\u5408\u3001github\u306eissue\u3067\u5831\u544a\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#2-2","title":"\u4f8b2-2","text":"<p>\u30e1\u30c3\u30bb\u30fc\u30b8\u578b\u306e\u4e0d\u4e00\u81f4\u3067\u53d6\u5f97\u3067\u304d\u3066\u3044\u306a\u3044\u3002 Autoware\u304c\u51fa\u529b\u3059\u308b\u578b\u304cdriving_log_replayer\u304c\u671f\u5f85\u3057\u3066\u3044\u308b\u578b\u3068\u7570\u306a\u3063\u3066\u3044\u308b\u305f\u3081\u306b\u767a\u751f\u3059\u308b\u3002</p> <p>2024\u5e746\u6708\u306bautoware_auto_msg\u304b\u3089autoware_msg\u306b\u5909\u66f4\u3055\u308c\u305f\u3002\u3053\u308c\u306b\u3088\u3063\u3066\u3001autoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3068driving_log_replayer\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u304c\u5bfe\u5fdc\u3057\u3066\u3044\u306a\u3044\u3068\u3053\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u3067\u308b\u3002</p> <pre><code>[ros2-67] [ERROR] [1717610261.542314281] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610261.721551659] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610261.903905941] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.084860123] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.263855979] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n[ros2-67] [ERROR] [1717610262.442275790] [ROSBAG2_TRANSPORT]: Topic '/perception/object_recognition/tracking/objects' has more than one type associated. Only topics with one type are supported\n</code></pre>"},{"location":"ja/trouble_shooting/#2-2_1","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62402-2","text":"<p>\u5927\u304d\u306a\u6a5f\u80fd\u5909\u66f4\u304c\u3042\u308b\u5834\u5408\u3001driving_log_replayer\u306eReleaseNotes.md\u306bAutoware\u306e\u5fc5\u8981\u306a\u6a5f\u80fd(PR\u756a\u53f7\u7b49)\u304c\u8a18\u8f09\u3057\u3066\u3042\u308b\u3002 \u5229\u7528\u3059\u308bAutoware\u306b\u5fc5\u8981\u306a\u6a5f\u80fd\u304c\u5165\u3063\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p> <p>Autoware Foundation\u306emain\u3068driving_log_replayer\u306emain\u3092\u4f7f\u7528\u3057\u3066\u3001\u3053\u306e\u554f\u984c\u304c\u767a\u751f\u3057\u3066\u3044\u308b\u5834\u5408\u3001github\u306eissue\u3067\u5831\u544a\u3057\u3066\u304f\u3060\u3055\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#_5","title":"\u8a55\u4fa1\u6570\u304c\u7570\u5e38\u306b\u5c11\u306a\u3044","text":""},{"location":"ja/trouble_shooting/#1_4","title":"\u539f\u56e01","text":"<p>PC\u306e\u6027\u80fd\u4e0d\u8db3\u3067Autoware\u304c\u6240\u5b9a\u306e\u5468\u671f(\u70b9\u7fa4\u306a\u308910Hz)\u3067topic\u3092publish\u51fa\u6765\u3066\u3044\u306a\u3044\u3002</p>"},{"location":"ja/trouble_shooting/#1_5","title":"\u4f8b1","text":"<pre><code>\u276f ros2 topic hz /perception/obstacle_segmentation/pointcloud\n1718083964.779455 [77]       ros2: determined eno1 (udp/10.0.55.137) as highest quality interface, selected for automatic interface.\naverage rate: 5.619\n min: 0.109s max: 0.207s std dev: 0.03246s window: 7\naverage rate: 5.333\n min: 0.109s max: 0.214s std dev: 0.02783s window: 12\n</code></pre>"},{"location":"ja/trouble_shooting/#1_6","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62401","text":"<p>\u5bfe\u8c61\u306etopic\u304c\u671f\u5f85\u901a\u308a\u306e\u5468\u671f\u3067\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304bros2 topic hz\u3067\u78ba\u8a8d\u3059\u308b\u3002 play_rate\u304c0.5\u3067\u3042\u308c\u307010*0.5=5\u3067\u6b63\u5e38\u3067\u3042\u308b\u3053\u3068\u306b\u6ce8\u610f\u3002</p> <p>\u51fa\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u3001dlr simulation run \u306eplay_rate\u5f15\u6570\u3092\u4f4e\u304f\u3059\u308b</p> <pre><code>dlr simulation run -p perception -l play_rate:=0.2\n</code></pre>"},{"location":"ja/trouble_shooting/#2_4","title":"\u539f\u56e02","text":"<p>topic\u304csimulation\u958b\u59cb\u6642\u70b9\u3067\u306f\u51fa\u3066\u3053\u305a\u306b\u3001simulation\u306e\u7d42\u308f\u308a\u9803\u306b\u3088\u3046\u3084\u304f\u51fa\u3066\u304f\u308b\u3002 \u4e8b\u524d\u306bml model\u3092engine\u306b\u5909\u63db\u3057\u3066\u3044\u306a\u3044\u5834\u5408\u3001simulation\u5b9f\u884c\u6642\u306bengine\u5909\u63db\u304c\u59cb\u307e\u308a\u3001engine\u5909\u63db\u304c\u7d42\u308f\u3063\u305f\u3042\u3068\u306btopic\u304c\u51fa\u3066\u304f\u308b\u3002</p>"},{"location":"ja/trouble_shooting/#2_5","title":"\u4f8b2","text":"<pre><code>[component_container_mt-52] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +894, GPU +174, now: CPU 1009, GPU 852 (MiB)\n[component_container_mt-52] [I] [TRT] ----------------------------------------------------------------\n[component_container_mt-52] [I] [TRT] Input filename:   /home/autoware/autoware_data/traffic_light_classifier/traffic_light_classifier_mobilenetv2_batch_6.onnx\n[component_container_mt-52] [I] [TRT] ONNX IR version:  0.0.8\n[component_container_mt-52] [I] [TRT] Opset version:    11\n[component_container_mt-52] [I] [TRT] Producer name:    pytorch\n[component_container_mt-52] [I] [TRT] Producer version: 1.13.1\n[component_container_mt-52] [I] [TRT] Domain:\n[component_container_mt-52] [I] [TRT] Model version:    0\n[component_container_mt-52] [I] [TRT] Doc string:\n[component_container_mt-52] [I] [TRT] ----------------------------------------------------------------\n[component_container_mt-52] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 116, GPU 678 (MiB)\n\n[component_container_mt-52] [I] [TRT] Applying optimizations and building TRT CUDA engine. Please wait for a few minutes...\n</code></pre>"},{"location":"ja/trouble_shooting/#2_6","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u62402","text":"<p>\u5b9f\u884c\u3057\u305f\u30bf\u30fc\u30df\u30ca\u30eb\u307e\u305f\u306fconsole.log\u306b\u4f8b\u306b\u793a\u3057\u305f\u3088\u3046\u306a\u30ed\u30b0\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u51fa\u3066\u3044\u308b\u5834\u5408\u306f\u3001driving_Log_replayer\u3067\u8a55\u4fa1\u3092\u884c\u3046\u524d\u306b\u4e8b\u524d\u306bonnx\u304b\u3089engine\u306e\u5909\u63db\u3092\u884c\u3046\u3002</p> <p>logging_simulator.launch.xml\u3092perception:=true\u3067\u8d77\u52d5\u3057\u3066\u3057\u3070\u3089\u304f\u653e\u7f6e\u3059\u308b\u3002 \u307e\u305f\u306f\u3001\u30e2\u30c7\u30eb\u3060\u3051\u30d3\u30eb\u30c9\u3059\u308blaunch\u3092\u8d77\u52d5\u3059\u308b\u3002</p> <pre><code># \u8d77\u52d5\u3057\u3066\u3057\u3070\u3089\u304f\u653e\u7f6e\u3059\u308b\nros2 launch autoware_launch logging_simulator.launch.xml map_path:=$HOME/autoware_map/sample-map-planning vehicle_model:=sample_vehicle sensor_model:=sample_sensor_kit\n\n# lidar_centerpoint \u3092 build_only\u3067launch\u3092\u8d77\u52d5\nros2 launch lidar_centerpoint lidar_centerpoint.launch.xml model_name:=centerpoint_tiny model_path:=$HOME/autoware_data/lidar_centerpoint model_param_path:=$(ros2 pkg prefix lidar_centerpoint --share)/config/centerpoint_tiny.param.yaml build_only:=true\n</code></pre>"},{"location":"ja/trouble_shooting/#_6","title":"\u7d42\u4e86\u3057\u306a\u3044\u3001\u9014\u4e2d\u3067\u7d42\u4e86\u3059\u308b","text":""},{"location":"ja/trouble_shooting/#_7","title":"\u539f\u56e0","text":"<p>\u610f\u56f3\u3057\u306a\u3044\u5165\u529b\u30c7\u30fc\u30bf\u306a\u3069\u306b\u3088\u308a\u4f8b\u5916\u304c\u767a\u751f\u3057\u3066\u3001\u30ce\u30fc\u30c9\u304c\u6b62\u307e\u308b\u3002\u307e\u305f\u306f\u7d42\u4e86\u3059\u308b\u3002</p>"},{"location":"ja/trouble_shooting/#_8","title":"\u4f8b","text":"<p>perception\u306eobject\u306e\u4e2d\u8eab\u304c\u60f3\u5b9a\u3057\u305f\u901a\u308a\u306b\u306a\u3063\u3066\u304a\u3089\u305a\u306b\u4f8b\u5916\u304c\u51fa\u529b\u3055\u308c\u305f\u3002</p> <pre><code>[perception_evaluator_node.py-115] [ERROR] [1711460672.978143229] [driving_log_replayer.perception_evaluator]: Unexpected footprint length: len(perception_object.shape.footprint.points)=2\n[perception_evaluator_node.py-115] Exception in thread Thread-2 (run_func):\n[perception_evaluator_node.py-115] Traceback (most recent call last):\n[perception_evaluator_node.py-115]   File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n[perception_evaluator_node.py-115]     self.run()\n[perception_evaluator_node.py-115]   File \"/usr/lib/python3.10/threading.py\", line 953, in run\n[perception_evaluator_node.py-115]     self._target(*self._args, **self._kwargs)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/lib/python3.10/site-packages/tf2_ros/transform_listener.py\", line 95, in run_func\n[perception_evaluator_node.py-115]     self.executor.spin()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 294, in spin\n[perception_evaluator_node.py-115]     self.spin_once()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 739, in spin_once\n[perception_evaluator_node.py-115]     self._spin_once_impl(timeout_sec)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 728, in _spin_once_impl\n[perception_evaluator_node.py-115]     handler, entity, node = self.wait_for_ready_callbacks(timeout_sec=timeout_sec)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 711, in wait_for_ready_callbacks\n[perception_evaluator_node.py-115]     return next(self._cb_iter)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/executors.py\", line 612, in _wait_for_ready_callbacks\n[perception_evaluator_node.py-115]     raise ExternalShutdownException()\n[perception_evaluator_node.py-115] rclpy.executors.ExternalShutdownException\n[ros2-117] [INFO] [1711460673.168213400] [rosbag2_recorder]: Subscribed to topic '/driving_log_replayer/marker/results'\n[ros2-117] [INFO] [1711460673.174638594] [rosbag2_recorder]: Subscribed to topic '/driving_log_replayer/marker/ground_truth'\n[simple_object_merger_node-69] [INFO] [1711460673.191825620] [sensing.radar.simple_object_merger]: waiting for object msg...\n[perception_evaluator_node.py-115] Traceback (most recent call last):\n[perception_evaluator_node.py-115]   File \"/home/autoware/autoware.proj/install/driving_log_replayer/lib/driving_log_replayer/perception_evaluator_node.py\", line 336, in &lt;module&gt;\n[perception_evaluator_node.py-115]     main()\n[perception_evaluator_node.py-115]   File \"/home/autoware/autoware.proj/install/driving_log_replayer/local/lib/python3.10/dist-packages/driving_log_replayer/evaluator.py\", line 448, in wrapper\n[perception_evaluator_node.py-115]     rclpy.shutdown()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/__init__.py\", line 126, in shutdown\n[perception_evaluator_node.py-115]     _shutdown(context=context)\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/utilities.py\", line 58, in shutdown\n[perception_evaluator_node.py-115]     return context.shutdown()\n[perception_evaluator_node.py-115]   File \"/opt/ros/humble/local/lib/python3.10/dist-packages/rclpy/context.py\", line 100, in shutdown\n[perception_evaluator_node.py-115]     raise RuntimeError('Context must be initialized before it can be shutdown')\n[perception_evaluator_node.py-115] RuntimeError: Context must be initialized before it can be shutdown\n[perception_evaluator_node.py-115] The following exception was never retrieved: Expected BOUNDING_BOX, but got polygon, which should have footprint.\n</code></pre>"},{"location":"ja/trouble_shooting/#_9","title":"\u4fee\u6b63\u65b9\u6cd5\u3001\u78ba\u8a8d\u7b87\u6240","text":"<p>\u8d77\u52d5\u3057\u305f\u30bf\u30fc\u30df\u30ca\u30eb\u304b\u3001console.log\u3092evaluator\u306e\u6587\u5b57\u5217\u3067\u691c\u7d22\u3057\u3066\u3001\u4f8b\u306e\u3088\u3046\u306b\u4f8b\u5916\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u306a\u3044\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/","title":"Annotationless\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1","text":"<p>perception_online_evaluator\u3092\u5229\u7528\u3057\u3066\u3001Autoware\u306e\u8a8d\u8b58\u6a5f\u80fd(perception)\u3092\u3001\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u306a\u3057\u3067\u8a55\u4fa1\u3059\u308b\u3002</p> <p>\u4ee5\u4e0b\u306ePR\u306e\u6a5f\u80fd\u3092\u6301\u3064Autoware\u304c\u5fc5\u8981\u3002 https://github.com/autowarefoundation/autoware.universe/pull/6556</p>"},{"location":"ja/use_case/annotationless_perception/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>annotationless_perception.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>annotationless_perception_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u8a8d\u8b58\u3092\u884c\u3046</li> <li>perception_online_evaluator \u304c <code>/perception/perception_online_evaluator/metrics</code>\u306b\u8a3a\u65ad\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/annotationless_perception/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>perception_online_evaluator\u304c\u51fa\u529b\u3059\u308btopic\u306f\u4ee5\u4e0b\u306e\u30b5\u30f3\u30d7\u30eb\u306e\u3088\u3046\u306a\u5f62\u5f0f\u3068\u306a\u3063\u3066\u3044\u308b\u3002 topic\u30b5\u30f3\u30d7\u30eb</p> <p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u8a8d\u8b58\u30af\u30e9\u30b9\u6bce\u306b\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u5168\u3066\u306e\u30af\u30e9\u30b9\u3067\u6b63\u5e38\u3068\u306a\u3063\u305f\u5834\u5408\u3001\u30c6\u30b9\u30c8\u306f\u6b63\u5e38\u3068\u306a\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#_3","title":"\u6b63\u5e38","text":"<p>\u5224\u5b9a\u306b\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u307e\u305f\u306flaunch\u306e\u5f15\u6570\u3067\u6307\u5b9a\u3055\u308c\u305f\u4ee5\u4e0b\u306e2\u3064\u306e\u5024\u3092\u5229\u7528\u3059\u308b\u3002</p> <ul> <li>\u95be\u5024</li> <li>\u5408\u683c\u7bc4\u56f2(\u95be\u5024\u3092\u88dc\u6b63\u3059\u308b\u4fc2\u6570)</li> </ul> <p><code>/perception/perception_online_evaluator/metrics</code> \u306estatus.name\u6bce\u306b\u4ee5\u4e0b\u306e\u30eb\u30fc\u30eb\u306b\u5f93\u3044\u6210\u5426\u306e\u5224\u5b9a\u304c\u884c\u308f\u308c\u308b\u3002 \u95be\u5024\u304c\u8a2d\u5b9a\u3055\u308c\u3066\u306a\u3044\u9805\u76ee(min, max, mean)\u306b\u95a2\u3057\u3066\u306f\u5e38\u306b\u6b63\u5e38\u3068\u5224\u5b9a\u3055\u308c\u308b\u3002\u6307\u5b9a\u304c\u3042\u308b\u3082\u306e\u306e\u307f\u304c\u8a55\u4fa1\u5bfe\u8c61\u306b\u306a\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#min","title":"min","text":"<p>\u95be\u5024\u00d7\u4e0b\u9650\u5024\u3000\uff1c\uff1d\u3000min\u306e\u6700\u5c0f\u5024\u3000\uff1c\uff1d\u3000\u95be\u5024\u00d7\u4e0a\u9650\u5024\u3067\u3042\u308c\u3070\u6b63\u5e38\u3068\u3059\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#max","title":"max","text":"<p>\u95be\u5024\u00d7\u4e0b\u9650\u5024\u3000\uff1c\uff1d\u3000max\u306e\u6700\u5927\u5024\u3000\uff1c\uff1d\u3000\u95be\u5024\u00d7\u4e0a\u9650\u5024\u3067\u3042\u308c\u3070\u6b63\u5e38\u3068\u3059\u308b\u3002</p> <p>\u4e0b\u9650\u5024\u306f0.0\u306b\u3059\u308b\u3053\u3068\u3092\u63a8\u5968</p>"},{"location":"ja/use_case/annotationless_perception/#mean","title":"mean","text":"<p>\u95be\u5024\u00d7\u4e0b\u9650\u5024\u3000\uff1c\uff1d\u3000mean\u306e\u5e73\u5747\u5024\u3000\uff1c\uff1d\u3000\u95be\u5024\u00d7\u4e0a\u9650\u5024\u3067\u3042\u308c\u3070\u6b63\u5e38\u3068\u3059\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#metric_value","title":"metric_value","text":"<p>\u95be\u5024\u00d7\u4e0b\u9650\u5024\u3000\uff1c\uff1d\u3000metric_value\u306e\u5024\u3000\uff1c\uff1d\u3000\u95be\u5024\u00d7\u4e0a\u9650\u5024\u3067\u3042\u308c\u3070\u6b63\u5e38\u3068\u3059\u308b\u3002</p> <p>metric_value\u306f\u73fe\u5728\u306e\u5024\u3060\u3051\u3067\u5224\u5b9a\u3055\u308c\u3001min, max, mean\u306emetrics\u306e\u5024\u3092\u66f4\u65b0\u3057\u306a\u3044\u3002</p> <p>\u30a4\u30e1\u30fc\u30b8\u56f3\u3092\u4ee5\u4e0b\u306b\u793a\u3059 </p>"},{"location":"ja/use_case/annotationless_perception/#_4","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u3068\u304d</p>"},{"location":"ja/use_case/annotationless_perception/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /perception/perception_online_evaluator/metrics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/annotationless_perception/#_5","title":"\u6761\u4ef6\u3092\u6307\u5b9a\u3059\u308b\u65b9\u6cd5","text":"<p>\u6761\u4ef6\u306f\u4ee5\u4e0b\u306e2\u901a\u308a\u306e\u65b9\u6cd5\u3067\u4e0e\u3048\u308b\u3053\u3068\u304c\u3067\u304d\u308b</p>"},{"location":"ja/use_case/annotationless_perception/#_6","title":"\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3059\u308b","text":"<pre><code>Evaluation:\n  UseCaseName: annotationless_perception\n  UseCaseFormatVersion: 0.3.0\n  Conditions:\n    ClassConditions:\n      # \u30af\u30e9\u30b9\u6bce\u306e\u6761\u4ef6\u3092\u8a18\u8ff0\u3059\u308b\u3002\u6761\u4ef6\u3092\u8a2d\u5b9a\u304c\u306a\u3044\u30af\u30e9\u30b9\u304c\u51fa\u529b\u3055\u308c\u305f\u5834\u5408\u306f\u30e1\u30c8\u30ea\u30af\u30b9\u3060\u3051\u8a08\u7b97\u3055\u308c\u308b\u3002\u8a55\u4fa1\u306b\u306f\u5f71\u97ff\u3057\u306a\u3044\n      # \u30b5\u30f3\u30d7\u30eb\u30c7\u30fc\u30bf\u3067\u306fTRUCK\u306eclass\u3082\u51fa\u529b\u3055\u308c\u308b\u304c\u6761\u4ef6\u3092\u8a18\u8ff0\u3057\u3066\u306a\u3044\u306e\u3067\u3001TRUCK\u306f\u5fc5\u305aSuccess\u306b\u306a\u308b\n      # result.jsonl\u304b\u3089\u6761\u4ef6\u6307\u5b9a\u3092\u884c\u3046\u5834\u5408\u3001\u3053\u3053\u306b\u8a18\u8ff0\u304c\u3042\u308b\u30ad\u30fc\u306e\u307f\u66f4\u65b0\u3055\u308c\u308b\u3002\n      # result.jsonl\u306bTRUCK\u306e\u30e1\u30c8\u30ea\u30af\u30b9\u304c\u51fa\u3066\u3044\u3066\u3082\u3001\u3053\u306e\u4f8b\u3067\u306fTRUCK\u306e\u30ad\u30fc\u3092\u6307\u5b9a\u3057\u3066\u3044\u306a\u3044\u306e\u3067\u8a55\u4fa1\u6761\u4ef6\u306b\u306f\u8ffd\u52a0\u3055\u308c\u306a\u3044\u3002\n      CAR: # classification key\n        Threshold:\n          # \u8a18\u8ff0\u306e\u306a\u3044\u30ad\u30fc\u306b\u3064\u3044\u3066\u306f\u8a55\u4fa1\u3055\u308c\u306a\u3044\uff08\u5fc5\u305a\u6210\u529f\u306b\u306a\u308b\uff09\n          lateral_deviation: { max: 0.4, mean: 0.019 }\n          yaw_deviation: { max: 3.1411, mean: 0.05 }\n          predicted_path_deviation_5.00: { max: 16.464, mean: 1.8 }\n          total_objects_count_r60.00_h10.00: { metric_value: 10 }\n        PassRange:\n          min: 0.0-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          max: 0.0-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          mean: 0.5-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          metric_value: 0.9-1.1\n      BUS: # classification key\n        Threshold:\n          # Only lateral_deviation is evaluated.\n          yaw_rate: { max: 0.05 } # Only max is evaluated.\n        PassRange:\n          min: 0.0-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          max: 0.0-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          mean: 0.5-2.0 # lower[&lt;=1.0]-upper[&gt;=1.0]\n          metric_value: 0.9-1.1\n</code></pre>"},{"location":"ja/use_case/annotationless_perception/#launch","title":"launch\u5f15\u6570\u3067\u6307\u5b9a\u3059\u308b","text":"<p>\u3053\u3061\u3089\u306e\u65b9\u6cd5\u3092\u30e1\u30a4\u30f3\u306b\u4f7f\u3046\u60f3\u5b9a\u3002</p> <p>\u904e\u53bb\u306e\u30c6\u30b9\u30c8\u3067\u51fa\u529b\u3055\u308c\u305fresult.jsonl\u306e\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u3092\u6307\u5b9a\u3059\u308b\u3068\u3001\u904e\u53bb\u306e\u30c6\u30b9\u30c8\u306e\u30e1\u30c8\u30ea\u30af\u30b9\u5024\u3092\u95be\u5024\u3068\u3057\u3066\u5229\u7528\u3059\u308b\u3002 \u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8f09\u306e\u3042\u308b\u95be\u5024\u3060\u3051result.jsonl\u304b\u3089\u5024\u304c\u66f4\u65b0\u3055\u308c\u308b\u3002</p> <p>\u307e\u305f\u5408\u683c\u7bc4\u56f2\u3082\u5f15\u6570\u3067\u6307\u5b9a\u53ef\u80fd\u3002</p> <p>\u5229\u7528\u30a4\u30e1\u30fc\u30b8\u3092\u4ee5\u4e0b\u306b\u793a\u3059\u3002</p> <p></p>"},{"location":"ja/use_case/annotationless_perception/#autoware-evaluator","title":"Autoware Evaluator","text":"<p>.webauto-ci.yml\u306esimulator\u306e\u8a2d\u5b9a\u3067parameters\u306b\u8ffd\u52a0\u3059\u308b\u3002</p> <pre><code>simulations:\n  - name: annotationless_perception\n    type: annotationless_perception\n    simulator:\n      deployment:\n        type: container\n        artifact: main\n      runtime:\n        type: simulator/standard1/amd64/medium\n      parameters:\n        annotationless_threshold_file: ${previous_test_result.jsonl_path}\n        annotationless_pass_range:\n          KEY1: VALUE1\n          KEY2: VALUE2\n</code></pre>"},{"location":"ja/use_case/annotationless_perception/#_7","title":"\u30b7\u30ca\u30ea\u30aa\u306e\u6761\u4ef6\u3092\u66f4\u65b0\u3059\u308b\u65b9\u6cd5","text":"<p>driving-log-replayer-cli\u3067\u306f\u30d7\u30ed\u30d5\u30a1\u30a4\u30eb\u306edata_directory\u914d\u4e0b\u306b\u5b58\u5728\u3059\u308b\u8907\u6570\u306e\u30b7\u30ca\u30ea\u30aa\u3092\u9023\u7d9a\u3067\u5b9f\u884c\u3059\u308b\u6a5f\u80fd\u3092\u5099\u3048\u3066\u3044\u308b\u3002 \u4e00\u65b9\u3067\u3001\u8a55\u4fa1\u6761\u4ef6\u3092\u5f15\u6570\u3067\u4e0e\u3048\u308b\u5834\u5408\u3001\u8907\u6570\u306e\u30b7\u30ca\u30ea\u30aa\u306b\u5bfe\u3057\u3066\u540c\u3058\u5f15\u6570\u304c\u9069\u7528\u3055\u308c\u3066\u3057\u307e\u3044\u4e0d\u90fd\u5408\u304c\u3042\u308b\u3002</p> <p>driving-log-replayer-cli\u3092\u7528\u3044\u305f\u30ed\u30fc\u30ab\u30eb\u30c6\u30b9\u30c8\u306e\u5834\u5408\u306f\u3001\u5f15\u6570\u6307\u5b9a\u3067\u306f\u306a\u304f\u3001\u30b7\u30ca\u30ea\u30aa\u306e\u6761\u4ef6\u3092\u968f\u6642\u66f4\u65b0\u3057\u3066\u5229\u7528\u3067\u304d\u308b\u3088\u3046\u306b\u3001\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u30b3\u30de\u30f3\u30c9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002</p> <ul> <li>\u624b\u52d5\u3067\u30b7\u30ca\u30ea\u30aa\u306e\u6761\u4ef6\u3092\u66f4\u65b0\u3059\u308bupdate-condition\u30b3\u30de\u30f3\u30c9</li> <li>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u5f8c\u306b\u81ea\u52d5\u3067\u30b7\u30ca\u30ea\u30aa\u306e\u6761\u4ef6\u3092\u66f4\u65b0\u3059\u308brun\u306e-u\u306e\u30aa\u30d7\u30b7\u30e7\u30f3</li> </ul> <p>\u66f4\u65b0\u65b9\u6cd5\u306f\u4ee5\u4e0b\u306e2\u901a\u308a\u304c\u3042\u308b</p> <ul> <li>existing \u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u306e\u3042\u308b\u9805\u76ee\u306e\u307f\u66f4\u65b0</li> <li>all \u30e1\u30c8\u30ea\u30af\u30b9\u306b\u51fa\u3066\u3044\u308b\u5024\u3067\u5168\u3066\u66f4\u65b0</li> </ul> <pre><code># manual update\ndlr simulation update-condition -s ${scenario_path} -r ${result.jsonl_path} -u ${existing|all}\n\n# automatically update scenario after simulation run\ndlr simulation run -p annotationless_perception -u ${existing|all}\n</code></pre>"},{"location":"ja/use_case/annotationless_perception/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>perception: true</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false / true (\u30c7\u30d5\u30a9\u30eb\u30c8 false\u3001launch\u5f15\u6570\u3067\u4e0e\u3048\u308b)</li> </ul>"},{"location":"ja/use_case/annotationless_perception/#sensing","title":"sensing\u306e\u5f15\u6570\u6307\u5b9a\u65b9\u6cd5","text":""},{"location":"ja/use_case/annotationless_perception/#autoware-evaluator_1","title":"Autoware Evaluator","text":"<p>.webauto-ci.yml\u306esimulator\u306e\u8a2d\u5b9a\u3067parameters\u306b\u8ffd\u52a0\u3059\u308b\u3002</p> <pre><code>simulations:\n  - name: annotationless_perception\n    type: annotationless_perception\n    simulator:\n      deployment:\n        type: container\n        artifact: main\n      runtime:\n        type: simulator/standard1/amd64/medium\n      parameters:\n        sensing: \"true\"\n</code></pre>"},{"location":"ja/use_case/annotationless_perception/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /localization/kinematic_state nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_auto_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_auto_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_auto_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_auto_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_auto_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/annotationless_perception/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/annotationless_perception/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/annotationless_perception/#_8","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/annotationless_perception/#_9","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <pre><code>{\n  \"Frame\": {\n    \"Ego\": {},\n    \"OBJECT_CLASSIFICATION\": {\n      // \u8a8d\u8b58\u3057\u305f\u30af\u30e9\u30b9\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" }, // Total\u3068Frame\u306e\u7d50\u679c\u306f\u540c\u3058\u3002\u4ed6\u306e\u8a55\u4fa1\u3068\u30c7\u30fc\u30bf\u69cb\u9020\u3092\u540c\u3058\u306b\u3059\u308b\u305f\u3081\u306b\u540c\u3058\u5024\u3092\u51fa\u529b\u3057\u3066\u3044\u308b\n      \"Info\": {\n        \"name_min_max_mean\": { \"min\": \"\u6700\u5c0f\u5024\", \"max\": \"\u6700\u5927\u5024\", \"mean\": \"\u5e73\u5747\u5024\" },\n        \"name_metric_value\": { \"metric_value\": \"\u5024\"},\n        ...\n      },\n      \"Metrics\": {\n        \"name_min_max_mean\": {\n          \"min\": \"min\u306e\u6700\u5c0f\u5024\",\n          \"max\": \"max\u306e\u6700\u5927\u5024\",\n          \"mean\": \"mean\u306e\u5e73\u5747\u5024\"\n        },\n        ...\n      }\n    }\n  }\n}\n</code></pre> <p>\u9805\u76ee\u306e\u610f\u5473\u306f\u4ee5\u4e0b\u306e\u56f3\u3092\u53c2\u7167</p> <p></p> <p></p>"},{"location":"ja/use_case/ar_tag_based_localizer/","title":"ArTagBasedLocalizer\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1","text":"<p>Autoware \u306eArTagBasedLocalizer\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u304c\u5b89\u5b9a\u3057\u3066\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>ar_tag_based_localizer.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>ar_tag_based_localizer_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/ar_tag_based_localizer/#artagbasedlocalizer_1","title":"ArTagBasedLocalizer \u306e\u53ef\u7528\u6027","text":"<p>\u672c\u9805\u76ee\u3067\u306f\u3001ArTagBasedLocalizer\u306e\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u3001\u306a\u3093\u3089\u304b\u306e\u4e8b\u60c5\u3067\u30ce\u30fc\u30c9\u304c\u843d\u3061\u308b\u30b1\u30fc\u30b9\u3092\u691c\u77e5\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3059\u308b\u3002</p> <p>\u672c\u30c4\u30fc\u30eb\u306f\u3001\u4e0b\u8a18\u306e\u30c8\u30d4\u30c3\u30af\u3092\u76e3\u8996\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u305d\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b\u3002</p> <ul> <li>/diagnostics</li> </ul>"},{"location":"ja/use_case/ar_tag_based_localizer/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_3","title":"\u53ef\u7528\u6027\u6b63\u5e38","text":"<p>ArTagBasedLocalizer Monitor\u304c\u51fa\u529b\u3059\u308b <code>/diagnostics</code> \u306e\u4e2d\u304b\u3089\u3001\u76e3\u8996\u30c8\u30d4\u30c3\u30af\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3002 \u6700\u65b0\u306e\u60c5\u5831\u306b\u304a\u3051\u308b<code>Number of Detected AR Tags</code>\u304c0\u4ee5\u4e0a\u3067\u3042\u308b\u5834\u5408\u3001\u6b63\u5e38\u3067\u3042\u308b\u3068\u5224\u65ad\u3059\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_4","title":"\u53ef\u7528\u6027\u7570\u5e38","text":"<p>\u53ef\u7528\u6027\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/ar_tag_based_localizer/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /api/localization/initialize InitializeLocalization"},{"location":"ja/use_case/ar_tag_based_localizer/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"ja/use_case/ar_tag_based_localizer/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/ar_tag_based_localizer/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_5","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/ar_tag_based_localizer/#_6","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>Availability\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Availability \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"ja/use_case/eagleye/","title":"Eagleye\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1","text":"<p>Autoware \u306eEagleye\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u304c\u5b89\u5b9a\u3057\u3066\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>eagleye.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>eagleye_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/eagleye/#eagleye_1","title":"Eagleye \u306e\u53ef\u7528\u6027","text":"<p>\u672c\u9805\u76ee\u3067\u306f\u3001Eagleye\u306e\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u3001\u5177\u4f53\u7684\u306b\u306f\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3092\u691c\u77e5\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3059\u308b\u3002</p> <ul> <li>Runtime error\u7b49\u306b\u3088\u308a\u3001Heading\u306e\u63a8\u5b9a\u304c\u3046\u307e\u304f\u52d5\u4f5c\u3057\u3066\u3044\u306a\u3044</li> <li>\u521d\u671f\u4f4d\u7f6e\u63a8\u5b9a\u5468\u308a\u306e\u30a2\u30fc\u30ad\u30c6\u30af\u30c1\u30e3\u5909\u66f4\u304c\u4e0d\u5341\u5206\u3067\u3001\u305d\u3082\u305d\u3082Eagleye\u304c\u521d\u671f\u5316\u3055\u308c\u306a\u3044</li> </ul> <p>\u305d\u306e\u305f\u3081\u306b\u3001\u672c\u9805\u76ee\u3067\u306f\u4e0b\u8a18\u306e\u51fa\u529b\u304c\u5b9a\u671f\u7684\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>/localization/pose_twist_estimator/eagleye/enu_absolute_pos_interpolate</li> </ul> <p>\u3053\u308c\u306f\u3001Eagleye Monitor\u3068\u3044\u3046Autoware\u5185\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u9593\u63a5\u7684\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5b9f\u73fe\u3055\u308c\u308b\u3002\u672c\u30c4\u30fc\u30eb\u306f\u3001\u4e0b\u8a18\u306e\u30c8\u30d4\u30c3\u30af\u3092\u76e3\u8996\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u305d\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b\u3002</p> <ul> <li>/diagnostics</li> </ul>"},{"location":"ja/use_case/eagleye/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#_3","title":"\u53ef\u7528\u6027\u6b63\u5e38","text":"<p>Eagleye Monitor\u304c\u51fa\u529b\u3059\u308b <code>/diagnostics</code> \u306e\u4e2d\u304b\u3089\u3001\u76e3\u8996\u30c8\u30d4\u30c3\u30af\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3002 \u6700\u65b0\u306e\u60c5\u5831\u306b\u304a\u3051\u308bAvailability\u304c <code>OK</code> \u3067\u3042\u308b\u5834\u5408\u3001\u6b63\u5e38\u3067\u3042\u308b\u3068\u5224\u65ad\u3059\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#_4","title":"\u53ef\u7528\u6027\u7570\u5e38","text":"<p>\u53ef\u7528\u6027\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/eagleye/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/eagleye/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /api/localization/initialize InitializeLocalization"},{"location":"ja/use_case/eagleye/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"ja/use_case/eagleye/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/eagleye/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/eagleye/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/eagleye/#_5","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/eagleye/#_6","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>Availability\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Availability \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"ja/use_case/","title":"\u8a55\u4fa1\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9","text":"<p>driving_log_replayer \u3092\u7528\u3044\u3066\u3069\u306e\u3088\u3046\u306a\u8a55\u4fa1\u3092\u884c\u3048\u308b\u304b\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/#driving-log-replayer","title":"Driving Log Replayer \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u4e00\u89a7","text":"<ul> <li>Localization</li> <li>YabLoc</li> <li>Eagleye</li> <li>AR-Tag Based Localizer</li> <li>Obstacle Segmentation</li> <li>Perception</li> <li>Performance Diag</li> <li>Annotationless Perception</li> </ul>"},{"location":"ja/use_case/localization/","title":"NDT\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1","text":"<p>NDT\u306b\u3088\u308bAutoware\u306e\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u304c\u5b89\u5b9a\u3057\u3066\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>NDT\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1\u3067\u306f NDT \u306e\u4fe1\u983c\u5ea6\u3001\u53ce\u675f\u6027\u3001\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>localization.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>localization_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001NDT \u306e\u4fe1\u983c\u5ea6\u3001\u53ce\u675f\u6027\u3001\u53ef\u7528\u6027\u304c\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/localization/#ndt_1","title":"NDT \u306e\u4fe1\u983c\u5ea6","text":"<p>\u4ee5\u4e0b\u306e 2 \u3064\u306e topic \u306e\u3046\u3061\u3001\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f\u65b9\u3092\u7528\u3044\u3066\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>/localization/pose_estimator/transform_probability</li> <li>/localization/pose_estimator/nearest_voxel_transformation_likelihood</li> </ul>"},{"location":"ja/use_case/localization/#ndt_2","title":"NDT \u306e\u53ce\u675f\u6027","text":"<p>\u4ee5\u4e0b\u3092\u7528\u3044\u3066\u8a55\u4fa1\u3059\u308b</p> <ul> <li>/localization/pose_estimator/initial_to_result_relative_pose</li> </ul>"},{"location":"ja/use_case/localization/#ndt_3","title":"NDT \u306e\u53ef\u7528\u6027","text":"<p>\u672c\u9805\u76ee\u3067\u306f\u3001NDT\u306e\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u3001\u5177\u4f53\u7684\u306b\u306f\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3092\u691c\u77e5\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3059\u308b\u3002</p> <ul> <li>Runtime error\u7b49\u306b\u3088\u308a <code>pointcloud_preprocessor</code> \u304c\u843d\u3061\u3066\u3044\u308b\uff08\u3053\u308c\u306b\u3088\u308a\u3001 <code>ndt_scan_matcher</code> \u3078\u306eLiDAR\u30b9\u30ad\u30e3\u30f3\u304c\u9001\u4fe1\u3055\u308c\u306a\u304f\u306a\u308b\uff09</li> <li>Runtime error\u7b49\u306b\u3088\u308a <code>ndt_scan_matcher</code> \u304c\u843d\u3061\u3066\u3044\u308b</li> </ul> <p>\u305d\u306e\u305f\u3081\u306b\u3001\u672c\u9805\u76ee\u3067\u306f\u4e0b\u8a18\u306e\u51fa\u529b\u304c\u5b9a\u671f\u7684\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>/localization/pose_estimator/exe_time_ms</li> </ul> <p>\u3053\u308c\u306f\u3001Component State Monitor\u3068\u3044\u3046Autoware\u5185\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u9593\u63a5\u7684\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5b9f\u73fe\u3055\u308c\u308b\u3002\u672c\u30c4\u30fc\u30eb\u306f\u3001\u4e0b\u8a18\u306e\u30c8\u30d4\u30c3\u30af\u3092\u76e3\u8996\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u305d\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b\u3002</p> <ul> <li>/diagnostics</li> </ul> <p>\u306a\u304a\u3001NDT\u306e\u51fa\u529b\u30c8\u30d4\u30c3\u30af\u306e\u4e2d\u3067 <code>/localization/pose_estimator/exe_time_ms</code> \u304c\u9078\u3070\u308c\u305f\u306e\u306f\u3001\u300c\u30c8\u30d4\u30c3\u30af\u306b\u5b9a\u671f\u7684\u306b\u30e1\u30c3\u30bb\u30fc\u30b8\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u300d\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3053\u3068\u3067\u4e0a\u8a18\u306b\u8ff0\u3079\u305f\u5931\u6557\u3092\u5224\u5b9a\u3059\u308b\u3053\u3068\u304c\u3067\u304d\u308b\u304b\u3089\u3067\u3042\u308b\u3002\u4f8b\u3048\u3070 <code>/localization/pose_estimator/pose</code> \u306f\u4eca\u56de\u306e\u76e3\u8996\u30c8\u30d4\u30c3\u30af\u3068\u3057\u3066\u9069\u3055\u306a\u3044\u3002\u4f55\u6545\u306a\u3089\u3070\u3001\u540c\u30c8\u30d4\u30c3\u30af\u306fNVTL\u3084TP\u306a\u3069\u306e\u30b9\u30b3\u30a2\u304c\u4f4e\u3044\u5834\u5408\u3082\u51fa\u529b\u3055\u308c\u306a\u3044\u306e\u3067\u3001\u51fa\u529b\u3092\u76e3\u8996\u3059\u308b\u3060\u3051\u3067\u306f\u3001\u305d\u306e\u539f\u56e0\u304c\u4e0a\u8a18\u5931\u6557\u3067\u3042\u308b\u304b\u3068\u3046\u304b\u3092\u5224\u5b9a\u3059\u308b\u3053\u3068\u304c\u96e3\u3057\u3044\u304b\u3089\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_3","title":"\u4fe1\u983c\u5ea6\u6b63\u5e38","text":"<p>/localization/pose_estimator/transform_probability\u3001\u307e\u305f\u306f/localization/pose_estimator/nearest_voxel_transformation_likelihood \u306e data \u304c\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3057\u305f AllowableLikelihood \u4ee5\u4e0a\u306e\u5834\u5408</p>"},{"location":"ja/use_case/localization/#_4","title":"\u4fe1\u983c\u5ea6\u7570\u5e38","text":"<p>/localization/pose_estimator/transform_probability\u3001\u307e\u305f\u306f/localization/pose_estimator/nearest_voxel_transformation_likelihood \u306e data \u304c\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3057\u305f AllowableLikelihood \u672a\u6e80\u306e\u5834\u5408</p>"},{"location":"ja/use_case/localization/#_5","title":"\u53ce\u675f\u6b63\u5e38","text":"<p>\u4ee5\u4e0b\u306e 3 \u3064\u306e\u6761\u4ef6\u3092\u5168\u3066\u6e80\u305f\u3059\u5834\u5408</p> <ol> <li>/localization/pose_estimator/initial_to_result_relative_pose\u306e\u6a2a\u65b9\u5411\u8ddd\u96e2\u304c\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3057\u305f AllowableDistance \u4ee5\u4e0b</li> <li>/localization/pose_estimator/exe_time_ms \u304c\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3057\u305f AllowableExeTimeMs \u4ee5\u4e0b</li> <li>/localization/pose_estimator/iteration_num \u304c\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3057\u305f AllowableIterationNum \u4ee5\u4e0b</li> </ol> <p>\u30b9\u30c6\u30c3\u30d7 1 \u3067\u53d6\u5f97\u3057\u305f\u6a2a\u65b9\u5411\u8ddd\u96e2\u304c/driving_log_replayer/localization/lateral_distance \u3068\u3057\u3066 publish \u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_6","title":"\u53ce\u675f\u7570\u5e38","text":"<p>\u53ce\u675f\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/localization/#_7","title":"\u53ef\u7528\u6027\u6b63\u5e38","text":"<p>Component State Monitor\u304c\u51fa\u529b\u3059\u308b <code>/diagnostics</code> \u306e\u4e2d\u304b\u3089\u3001\u76e3\u8996\u30c8\u30d4\u30c3\u30af\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3002 \u6700\u65b0\u306e\u60c5\u5831\u306b\u304a\u3051\u308bStatus\u304c <code>Timeout</code> \u307e\u305f\u306f <code>NotReceived</code> \u4ee5\u5916\u306e\u5834\u5408\u3001\u6b63\u5e38\u3067\u3042\u308b\u3068\u5224\u65ad\u3059\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_8","title":"\u53ef\u7528\u6027\u7570\u5e38","text":"<p>\u53ef\u7528\u6027\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/localization/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /diagnostics diagnostic_msgs::msg::DiagnosticArray /localization/pose_estimator/transform_probability autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/nearest_voxel_transformation_likelihood autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/initial_to_result_relative_pose geometry_msgs::msg::PoseStamped /localization/pose_estimator/exe_time_ms autoware_internal_debug_msgs::msg::Float32Stamped /localization/pose_estimator/iteration_num autoware_internal_debug_msgs::msg::Int32Stamped /tf tf2_msgs/msg/TFMessage /localization/util/downsample/pointcloud sensor_msgs::msg::PointCloud2 /localization/pose_estimator/points_aligned sensor_msgs::msg::PointCloud2 <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /driving_log_replayer/localization/lateral_distance example_interfaces::msg::Float64"},{"location":"ja/use_case/localization/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /api/localization/initialize InitializeLocalization"},{"location":"ja/use_case/localization/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"ja/use_case/localization/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/localization/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/localization/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/localization/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/localization/#_9","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/localization/#_10","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>localization \u3067\u306f\u3001\u53ce\u675f\u6027\u3001\u4fe1\u983c\u5ea6\u3001\u53ef\u7528\u6027\u306e 3 \u3064\u3092\u8a55\u4fa1\u3057\u3066\u3044\u308b\u306e\u3067\u3001\u884c\u6bce\u306b\u53ce\u675f\u6027\u3001\u4fe1\u983c\u5ea6\u3001\u53ef\u7528\u6027\u306e\u3044\u305a\u308c\u304b\u306e\u7d50\u679c\u304c\u5165\u3063\u3066\u3044\u308b\u3002 Result \u306f\u53ce\u675f\u6027\u3001\u4fe1\u983c\u5ea6\u3001\u53ef\u7528\u6027\u306e\u3059\u3079\u3066\u3092\u30d1\u30b9\u3057\u3066\u3044\u308c\u3070 true \u3067\u305d\u308c\u4ee5\u5916\u306f false \u5931\u6557\u3068\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>\u53ce\u675f\u6027\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Convergence \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Convergence\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n    \"Info\": {\n      \"LateralDistance\": \"initial_to_result_relative_pose.pose.position.y\",\n      \"HorizontalDistance\": \"initial_to_result_relative_pose.pose.position\u306e\u6c34\u5e73\u8ddd\u96e2\u3002\u53c2\u8003\u5024\",\n      \"ExeTimeMs\": \"ndt\u306e\u8a08\u7b97\u306b\u304b\u304b\u3063\u305f\u6642\u9593\",\n      \"IterationNum\": \"ndt\u306e\u518d\u8a08\u7b97\u56de\u6570\"\n    }\n  }\n}\n</code></pre> <p>\u4fe1\u983c\u5ea6\u306e\u7d50\u679c(Frame \u306b Reliability \u306e\u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Reliability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n    \"Info\": {\n      \"Value\": {\n        \"stamp\": {\n          \"sec\": \"stamp\u306e\u79d2\",\n          \"nanosec\": \"stamp\u306enano\u79d2\"\n        },\n        \"data\": \"NVTL or TP\u306e\u5024\"\n      },\n      \"Reference\": {\n        \"stamp\": {\n          \"sec\": \"stamp\u306e\u79d2\",\n          \"nanosec\": \"stamp\u306enano\u79d2\"\n        },\n        \"data\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u306a\u304b\u3063\u305f\u5c24\u5ea6\u3002\u53c2\u8003\u5024\u3002Value\u304cNVTL\u306a\u3089TP\u304c\u5165\u308b\"\n      }\n    }\n  }\n}\n</code></pre> <p>\u53ef\u7528\u6027\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Availability \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"},{"location":"ja/use_case/obstacle_segmentation/","title":"\u70b9\u7fa4\u751f\u6210\u306e\u8a55\u4fa1","text":"<p>Autoware \u306e\u70b9\u7fa4\u51e6\u7406\u306e\u30d7\u30ed\u30bb\u30b9(sensing\u2192perception)\u304c\u52d5\u4f5c\u3057\u3066\u3001/perception/obstacle_segmentation/pointcloud \u304c\u610f\u56f3\u901a\u308a\u306b\u51fa\u529b\u3055\u308c\u308b\u304b\u3069\u3046\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>\u70b9\u7fa4\u304c\u610f\u56f3\u901a\u308a\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u306e\u5224\u5b9a\u306f\u3001t4_dataset \u3068\u70b9\u7fa4\u3092\u7528\u3044\u3066\u884c\u3046\u3002\u4ee5\u4e0b\u306e\u8a55\u4fa1\u3092\u540c\u6642\u306b\u884c\u3046\u3002</p> <ul> <li>\u4e8b\u524d\u306b\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u3057\u3066\u304a\u3044\u305f\u8eca\u4e21\u3084\u6b69\u884c\u8005\u306a\u3069\u304c\u691c\u77e5\u51fa\u6765\u3066\u3044\u308b\u304b\u306e\u8a55\u4fa1\uff08detection: \u691c\u77e5\uff09</li> <li>\u30ec\u30fc\u30f3\u3068\u30b7\u30ca\u30ea\u30aa\u3067\u5b9a\u7fa9\u3057\u305f\u81ea\u8eca\u4e21\u5468\u308a\u306e\u30dd\u30ea\u30b4\u30f3\u304c\u91cd\u306a\u308b\u30a8\u30ea\u30a2\u306b\u4f59\u5206\u306a\u70b9\u7fa4\u304c\u51fa\u3066\u3044\u306a\u3044\u304b\u306e\u8a55\u4fa1\uff08non_detection: \u975e\u691c\u77e5\uff09</li> </ul> <p>\u307e\u305f\u3001\u8a55\u4fa1\u6761\u4ef6\u306b null \u3092\u6307\u5b9a\u3059\u308c\u3070\u8a55\u4fa1\u3057\u306a\u3044\u3053\u3068\u3082\u53ef\u80fd\u3067\u3042\u308b\u3002\u3059\u306a\u308f\u3061\u4ee5\u4e0b\u306e 3 \u30e2\u30fc\u30c9\u3067\u8a55\u4fa1\u3092\u5b9f\u65bd\u3067\u304d\u308b\u3002</p> <ol> <li>detection \u3068 non_detection \u3092\u540c\u6642\u306b\u8a55\u4fa1\u3059\u308b</li> <li>detection \u3060\u3051\u8a55\u4fa1\u3059\u308b(NonDetection: null)</li> <li>non_detection \u3060\u3051\u8a55\u4fa1\u3059\u308b(Detection: null)</li> </ol> <p>\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c4\u30fc\u30eb\u306fDeepen\u304c\u63a8\u5968\u3067\u3042\u308b\u304c\u3001t4_dataset \u3078\u306e\u5909\u63db\u304c\u30b5\u30dd\u30fc\u30c8\u3055\u308c\u3066\u3044\u308b\u30c4\u30fc\u30eb\u3067\u3042\u308c\u3070\u3088\u3044\u3002 \u5909\u63db\u30c4\u30fc\u30eb\u3055\u3048\u4f5c\u6210\u3067\u304d\u308c\u3070\u8907\u6570\u306e\u30a2\u30ce\u30c6\u30fc\u30b7\u30e7\u30f3\u30c4\u30fc\u30eb\u3092\u5229\u7528\u3059\u308b\u3053\u3068\u304c\u53ef\u80fd\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_2","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>obstacle_segmentation.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>obstacle_segmentation_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001/perception/obstacle_segmentation/pointcloud \u3092\u51fa\u529b\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/perception/obstacle_segmentation/pointcloud \u3092 subscribe \u3057\u3066\u3001header \u306e\u6642\u523b\u3067\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306e polygon \u3092\u8a08\u7b97\u3059\u308b\u3002</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u70b9\u7fa4\u3068\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306epolygon\u3092perception_eval \u306b\u6e21\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/obstacle_segmentation/#polygon","title":"\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306epolygon\u306e\u8a08\u7b97\u65b9\u6cd5","text":"<p>\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u3067\u4e0e\u3048\u3089\u308c\u305fpolygon\u3068\u3001\u8d70\u884c\u8def(road_lanelet)\u306e\u91cd\u306a\u308a\u5408\u3063\u305f\u30a8\u30ea\u30a2\u3068\u3057\u3066\u7b97\u51fa\u3055\u308c\u308b\u3002 \u4ee5\u4e0b\u306e\u30b9\u30c6\u30c3\u30d7\u306b\u5f93\u3063\u3066\u8a08\u7b97\u3055\u308c\u308b\u3002</p> <ol> <li>pointcloud\u306eheader.stamp\u306e\u6642\u523b\u3067\u306emap_to_base_link\u306etransform\u3092\u53d6\u5f97\u3057\u3066\u3001polygon\u3092map\u5ea7\u6a19\u7cfb\u306b\u5909\u63db\u3059\u308b</li> <li>\u8eca\u4e21\u306e\u3044\u308bpoint\u304b\u3089\u3001search_range(\u4e0b\u56f3\u53c2\u7167)\u306e\u7bc4\u56f2\u306eroad_lanelet\u3092\u53d6\u5f97\u3059\u308b</li> <li>2\u3067\u53d6\u5f97\u3057\u305froad_lanelet\u3068polygon\u306eintersection\u3092\u53d6\u308b</li> <li>3\u3067\u53d6\u5f97\u3057\u305fpolygon\u306e\u914d\u5217\u3092base_link\u5ea7\u6a19\u7cfb\u3078\u623b\u3059(pointcloud\u3092\u30d5\u30a3\u30eb\u30bf\u3059\u308b\u305f\u3081\u306b\u5ea7\u6a19\u7cfb\u3092\u4e00\u81f4\u3055\u305b\u308b)</li> </ol> <p></p> <p>\u30b9\u30c6\u30c3\u30d72\u3067\u3001polygon\u304c\u5b58\u5728\u3057\u5f97\u308b\u7bc4\u56f2\u306elanelet\u306b\u7d5e\u308b\u3053\u3068\u3067\u3001\u30b9\u30c6\u30c3\u30d73\u3067\u7a7a\u306epolygon\u304c\u8fd4\u3063\u3066\u304f\u308b\u3068\u308f\u304b\u308a\u304d\u3063\u3066\u3044\u308blanelet\u3068\u306eintersection\u51e6\u7406\u3092\u7701\u3044\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_3","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_4","title":"\u691c\u77e5\u6b63\u5e38","text":"<p>\u4ee5\u4e0b\u306e\u6761\u4ef6\u3092\u3059\u3079\u3066\u6e80\u305f\u3059\u5834\u5408\u3001\u691c\u77e5\u6b63\u5e38\u3068\u306a\u308b\u3002</p> <ol> <li>\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f UUID \u3092\u6301\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u5185\u306b\u3001\u6307\u5b9a\u3057\u305f\u70b9\u6570\u4ee5\u4e0a\u306e\u70b9\u7fa4\uff08/perception/obstacle_segmentation/pointcloud\uff09\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068\u3002<ul> <li>\u8907\u6570\u306e UUID \u3092\u6307\u5b9a\u3057\u305f\u5834\u5408\u306f\u3001\u6307\u5b9a\u3057\u305f\u3059\u3079\u3066\u306e\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306b\u3064\u3044\u3066\u6761\u4ef6\u3092\u6e80\u305f\u3059\u5fc5\u8981\u304c\u3042\u308a\u307e\u3059\u3002</li> </ul> </li> <li>Autoware \u306e\u8a3a\u65ad\u6a5f\u80fd\u3067\u63d0\u4f9b\u3055\u308c\u308b\u70b9\u7fa4\u306e\u51fa\u529b\u30ec\u30fc\u30c8\u304c\u30a8\u30e9\u30fc\u72b6\u614b\u3067\u306a\u3044\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u3057\u304d\u3044\u5024\u306f 1.0Hz \u3067\u3059\u3002</li> </ol>"},{"location":"ja/use_case/obstacle_segmentation/#_5","title":"\u691c\u77e5\u8b66\u544a","text":"<p>\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3057\u305f UUID \u3092\u6301\u3064 bounding box \u306e visibility \u304c none(occlusion \u72b6\u614b)\u3067\u3042\u308a\u3001\u8a55\u4fa1\u51fa\u6765\u306a\u3044\u5834\u5408\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_6","title":"\u691c\u77e5\u7570\u5e38","text":"<p>\u691c\u77e5\u8b66\u544a\u3067\u3082\u3001\u691c\u77e5\u6b63\u5e38\u3067\u3082\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/obstacle_segmentation/#_7","title":"\u975e\u691c\u77e5\u6b63\u5e38","text":"<p>\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u70b9\u7fa4\u304c 1 \u70b9\u3082\u306a\u3044\u3053\u3068\u3002</p> <p>\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306f\u8a55\u4fa1\u65b9\u6cd5\u306e\u30b9\u30c6\u30c3\u30d7 3 \u3067\u8a08\u7b97\u3055\u308c\u308b\u9818\u57df\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_8","title":"\u975e\u691c\u77e5\u7570\u5e38","text":"<p>\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u70b9\u7fa4\u304c\u51fa\u3066\u3044\u308b\u3053\u3068\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/obstacle_segmentation/pointcloud sensor_msgs::msg::PointCloud2 /diagnostics diagnostic_msgs::msg::DiagnosticArray /tf tf2_msgs/msg/TFMessage /planning/scenario_planning/status/stop_reasons tier4_planning_msgs::msg::StopReasonArray /planning/scenario_planning/trajectory autoware_planning_msgs::msg::Trajectory <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /driving_log_replayer/marker/detection visualization_msgs::msg::MarkerArray /driving_log_replayer/marker/non_detection visualization_msgs::msg::MarkerArray /driving_log_replayer/pcd/detection sensor_msgs::msg::PointCloud2 /driving_log_replayer/pcd/non_detection sensor_msgs::msg::PointCloud2 /planning/mission_planning/goal geometry_msgs::msg::PoseStamped"},{"location":"ja/use_case/obstacle_segmentation/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3059\u308b\u3002</p> <ul> <li>localization: false</li> <li>control: false</li> </ul>"},{"location":"ja/use_case/obstacle_segmentation/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>t4_dataset \u3067\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068</p> <p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state Type: nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /localization/kinematic_state Type: nav_msgs/msg/Odometry /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/obstacle_segmentation/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/obstacle_segmentation/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/obstacle_segmentation/#_9","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/obstacle_segmentation/#_10","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>obstacle_segmentation \u3067\u306f\u3001\u691c\u77e5(Detection)\u3068\u975e\u691c\u77e5(NonDetection)\u306e 2 \u3064\u3092\u8a55\u4fa1\u3057\u3066\u3044\u308b\u3002 1 \u56de\u306e\u70b9\u7fa4\u306e callback \u3067\u540c\u6642\u306b\u8a55\u4fa1\u3057\u3066\u3044\u308b\u304c\u3001\u305d\u308c\u305e\u308c\u5225\u306b\u30ab\u30a6\u30f3\u30c8\u3057\u3066\u3044\u308b\u3002 Result \u306f\u691c\u77e5\u3068\u975e\u691c\u77e5\u4e21\u65b9\u306e\u30d1\u30b9\u3057\u3066\u3044\u308c\u3070 true \u3067\u305d\u308c\u4ee5\u5916\u306f false \u5931\u6557\u3068\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u305ft4_dataset\u306e\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\",\n    \"FrameSkip\": \"object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u8a55\u4fa1\u3092\u98db\u3070\u3055\u308c\u305f\u56de\u6570\",\n    \"StopReasons\": \"Planning module\u304c\u51fa\u529b\u3059\u308b\u505c\u6b62\u7406\u7531\u3002\u53c2\u8003\u5024\",\n    \"TopicRate\": \"\u70b9\u7fa4\u306e\u51fa\u529b\u30ec\u30fc\u30c8\u304c\u6b63\u5e38\u304b\u3069\u3046\u304b\u3092\u793a\u3059diag\u306e\u7d50\u679c\",\n    \"Detection\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, Warn or Invalid\" },\n      \"Info\": {\n        \"DetectionSuccess or DetectionFail or DetectionWarn\": {\n          \"Annotation\": {\n            \"Scale\": {\n              \"x\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306ex\u65b9\u5411\u306e\u9577\u3055\",\n              \"y\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306ey\u65b9\u5411\u306e\u9577\u3055\",\n              \"z\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306ez\u65b9\u5411\u306e\u9577\u3055\"\n            },\n            \"Position\": {\n              \"position\": {\n                \"x\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u4f4d\u7f6ex\",\n                \"y\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u4f4d\u7f6ey\",\n                \"z\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u4f4d\u7f6ez\"\n              },\n              \"orientation\": {\n                \"x\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u5411\u304dx\",\n                \"y\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u5411\u304dy\",\n                \"z\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u5411\u304dz\",\n                \"w\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306e\u5411\u304dw\"\n              }\n            },\n            \"UUID\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306eUUID\",\n            \"StampFloat\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u306eunix_time[us]\u306efloat\u306b\u3057\u305f\u3082\u306e\"\n          },\n          \"PointCloud\": {\n            \"NumPoints\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u5185\u306b\u542b\u307e\u308c\u308b\u70b9\u7fa4\u306e\u6570\",\n            \"Nearest\": \"\u30d0\u30a6\u30f3\u30c7\u30a3\u30f3\u30b0\u30dc\u30c3\u30af\u30b9\u5185\u3067base_link\u304b\u3089\u6700\u3082\u8fd1\u3044\u70b9\u306e[x,y,z]\u5ea7\u6a19\",\n            \"Stamp\": {\n              \"sec\": \"\u4f7f\u7528\u3057\u305f\u70b9\u7fa4\u306eheader.stamp\u306esec\",\n              \"nanosec\": \"\u4f7f\u7528\u3057\u305f\u70b9\u7fa4\u306eheader.stamp\u306enanosec\"\n            }\n          }\n        }\n      }\n    },\n    \"NonDetection\": {\n      \"Result\": \"Success, Fail, or Invalid\",\n      \"Info\": {\n        \"PointCloud\": {\n          \"NumPoints\": \"\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u51fa\u3066\u3044\u308b\u70b9\u7fa4\u306e\u6570\",\n          \"Distance\": {\n            \"0-1\": \"base_link\u304b\u30890-1m\u306e\u9593\u306e\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u51fa\u3066\u3044\u308b\u70b9\u7fa4\u6570\",\n            \"x-x+1\": \"\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u51fa\u3066\u3044\u308b\u70b9\u7fa4\u306e\u8ddd\u96e2\u6bce\u306e\u5206\u5e03\",\n            \"99-100\": \"base_link\u304b\u308999-100m\u306e\u9593\u306e\u975e\u691c\u77e5\u30a8\u30ea\u30a2\u306b\u51fa\u3066\u3044\u308b\u70b9\u7fa4\u6570\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/perception/","title":"\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1","text":"<p>Autoware \u306e\u8a8d\u8b58\u6a5f\u80fd(perception)\u306e\u8a8d\u8b58\u7d50\u679c\u304b\u3089 mAP(mean Average Precision)\u306a\u3069\u306e\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3066\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>perception \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3057\u3066\u51fa\u529b\u3055\u308c\u308b perception \u306e topic \u3092\u8a55\u4fa1\u7528\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u6e21\u3057\u3066\u8a55\u4fa1\u3092\u884c\u3046\u3002</p> <p>\u30b7\u30ca\u30ea\u30aa\u306b\u8a18\u8ff0\u3057\u305fperception_mode\u3067\u8d77\u52d5\u3055\u308c\u308b\u306e\u3067\u3001\u8a55\u4fa1\u5bfe\u8c61\u306e\u30bb\u30f3\u30b5\u30fc\u3092\u5909\u66f4\u3057\u305f\u3044\u5834\u5408\u306f\u30b7\u30ca\u30ea\u30aa\u3092\u5909\u66f4\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_2","title":"\u4e8b\u524d\u6e96\u5099","text":"<p>perception \u3067\u306f\u3001\u6a5f\u68b0\u5b66\u7fd2\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3002 \u30e2\u30c7\u30eb\u3092\u4e8b\u524d\u306b\u6e96\u5099\u3057\u3066\u3044\u306a\u3044\u3068Autoware\u304b\u3089\u8a8d\u8b58\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u306a\u3044\u3002 \u4f55\u3082\u8a55\u4fa1\u7d50\u679c\u304c\u51fa\u3066\u3053\u306a\u3044\u5834\u5408\u306f\u3001\u3053\u306e\u4f5c\u696d\u304c\u6b63\u3057\u304f\u51fa\u6765\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_3","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30e2\u30c7\u30eb\u306fAutoware\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6642\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306f\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b\u306bAutoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u306e\u3067\u3069\u3061\u3089\u306e\u624b\u6cd5\u304c\u4f7f\u308f\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u4ee5\u4e0b\u306e\u30d1\u30bf\u30fc\u30f3\u304c\u5b58\u5728\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#ansible","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30b9\u30af\u30ea\u30d7\u30c8\u5b9f\u884c\u6642\u306b<code>Download artifacts? [y/N]</code>\u3068\u51fa\u3066\u304f\u308b\u306e\u3067<code>y</code>\u3092\u5165\u529b\u3057\u3066\u30a8\u30f3\u30bf\u30fc\u3092\u62bc\u3059(Autoware foundation\u306emain\u3060\u3068\u3053\u3061\u3089) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"ja/use_case/perception/#_4","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u5c11\u3057\u53e4\u3044Autoware.universe\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3053\u3061\u3089\u3001<code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>\u306e\u30b3\u30df\u30c3\u30c8\u30cf\u30c3\u30b7\u30e5\u307e\u3067\u306f\u3053\u3061\u3089\u304c\u4f7f\u7528\u3055\u308c\u308b\u3002 lidar_centerpoint/CMakeList.txt</p>"},{"location":"ja/use_case/perception/#_5","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u63db","text":"<p>\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f onnx \u30d5\u30a1\u30a4\u30eb\u306f\u305d\u306e\u307e\u307e\u4f7f\u7528\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001TensorRT \u306e engine \u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u3066\u5229\u7528\u3059\u308b\u3002 \u5909\u63db\u7528\u306e\u30b3\u30de\u30f3\u30c9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001autoware \u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092 source \u3057\u3066\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002</p> <p><code>$HOME/autoware</code>\u306bautoware\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3068\u3057\u3066\u8aac\u660e\u3059\u308b\u3002</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch lidar_centerpoint lidar_centerpoint.launch.xml build_only:=true\n</code></pre> <p>\u5909\u63db\u30b3\u30de\u30f3\u30c9\u304c\u7d42\u4e86\u3059\u308b\u3068\u3001engine \u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306b\u5408\u308f\u305b\u3066\u51fa\u529b\u5148\u304c\u5909\u308f\u308b\u306e\u3067\u3001\u9069\u5207\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#ansible_1","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <pre><code>$HOME/autoware_data/lidar_centerpoint/pts_backbone_neck_head_centerpoint_tiny.engine\n$HOME/autoware_data/lidar_centerpoint/pts_voxel_encoder_centerpoint_tiny.engine\n</code></pre>"},{"location":"ja/use_case/perception/#_6","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<pre><code>$HOME/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data/pts_backbone_neck_head_centerpoint_tiny.engine\n$HOME/autoware/install/lidar_centerpoint/share/lidar_centerpoint/data/pts_voxel_encoder_centerpoint_tiny.engine\n</code></pre>"},{"location":"ja/use_case/perception/#_7","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>perception.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>perception_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u70b9\u7fa4\u30c7\u30fc\u30bf\u3092\u51fa\u529b\u3057\u3001perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u8a8d\u8b58\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/perception/object_recognition/{detection, tracking}/objects \u3092 subscribe \u3057\u3066\u3001\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3067 perception_eval \u306e\u95a2\u6570\u3092\u7528\u3044\u3066\u8a55\u4fa1\u3057\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/perception/#_8","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_9","title":"\u6b63\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306eCriterion\u30bf\u30b0\u306eCriteria\u3092\u6e80\u305f\u3059\u3053\u3068\u3002</p> <p>sample\u306escenario.yaml\u306f\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u3063\u3066\u304a\u308a\u3001</p> <pre><code>Criterion:\n  - PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n    CriteriaMethod: num_gt_tp # refer https://github.com/tier4/driving_log_replayer/blob/develop/driving_log_replayer/driving_log_replayer/criteria/perception.py#L136-L152\n    CriteriaLevel: hard # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)\n    Filter:\n      Distance: 0.0-50.0 # [m] null [Do not filter by distance] or lower_limit-(upper_limit) [Upper limit can be omitted. If omitted value is 1.7976931348623157e+308]\n  - PassRate: 95.0 # How much (%) of the evaluation attempts are considered successful.\n    CriteriaMethod: num_gt_tp # refer https://github.com/tier4/driving_log_replayer/blob/develop/driving_log_replayer/driving_log_replayer/criteria/perception.py#L136-L152\n    CriteriaLevel: easy # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)\n    Filter:\n      Distance: 50.0- # [m] null [Do not filter by distance] or lower_limit-(upper_limit) [Upper limit can be omitted. If omitted value is 1.7976931348623157e+308]\n</code></pre> <ul> <li><code>/perception/object_recognition/{detection, tracking}/objects</code>\u306esubscribe 1\u56de\u306b\u5bfe\u3057\u3066\u30010.0-50.0[m]\u306e\u8ddd\u96e2\u306b\u3042\u308bobject\u3067\u3001tp\u306eobject\u6570\u304chard(75.0%)\u4ee5\u4e0a\u306e\u5834\u5408\u3002Result\u306eFrame\u304cSuccess\u306b\u306a\u308b\u3002</li> <li><code>/perception/object_recognition/{detection, tracking}/objects</code>\u306esubscribe 1\u56de\u306b\u5bfe\u3057\u3066\u300150.0-1.7976931348623157e+308[m]\u306e\u8ddd\u96e2\u306b\u3042\u308bobject\u3067\u3001tp\u306eobject\u6570\u304ceasy(25.0%)\u4ee5\u4e0a\u306e\u5834\u5408\u3002Result\u306eFrame\u304cSuccess\u306b\u306a\u308b\u3002</li> <li>\u307e\u305f\u3001<code>PassRate &gt;= \u6b63\u5e38\u6570 / \u5168\u53d7\u4fe1\u6570 * 100</code>\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3059\u3068\u304d\u3001Result\u306eTotal\u304cSuccess\u306b\u306a\u308b\u3002</li> </ul>"},{"location":"ja/use_case/perception/#_10","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/perception/#_11","title":"\u8a55\u4fa1\u30b9\u30ad\u30c3\u30d7","text":"<p>\u4ee5\u4e0b\u306e\u5834\u5408\u306b\u3001FrameSkip\u306b1\u8db3\u3059\u51e6\u7406\u306e\u307f\u884c\u3046\u3002 FrameSkip\u306f\u8a55\u4fa1\u3092skip\u3057\u305f\u56de\u6570\u306e\u30ab\u30a6\u30f3\u30bf\u3002</p> <ul> <li>\u53d7\u4fe1\u3057\u305fobject\u306e\u30d8\u30c3\u30c0\u30fc\u6642\u523b\u306e\u524d\u5f8c75msec\u4ee5\u5185\u306b\u771f\u5024\u304c\u5b58\u5728\u3057\u306a\u3044\u5834\u5408</li> <li>\u53d7\u4fe1\u3057\u305fobject\u306efootprint.points\u306e\u6570\u304c1\u304b2\u306e\u5834\u5408(\u3053\u306e\u6761\u4ef6\u306fperception_eval\u304c\u66f4\u65b0\u3055\u308c\u305f\u3089\u306a\u304f\u306a\u308b\u4e88\u5b9a)</li> </ul>"},{"location":"ja/use_case/perception/#nogtnoobject","title":"\u8a55\u4fa1\u30b9\u30ad\u30c3\u30d7NoGTNoObject","text":"<ul> <li>\u30d5\u30a3\u30eb\u30bf\u6761\u4ef6\u306b\u3088\u3063\u3066\u771f\u5024\u3068\u8a8d\u8b58\u7d50\u679c\u304c\u30d5\u30a3\u30eb\u30bf\u3055\u308c\u8a55\u4fa1\u3055\u308c\u306a\u304b\u3063\u305f\u5834\u5408(\u8a55\u4fa1\u7d50\u679cPassFail\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306e\u4e2d\u8eab\u304c\u7a7a\u306e\u5834\u5408)</li> </ul>"},{"location":"ja/use_case/perception/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/object_recognition/detection/objects autoware_perception_msgs/msg/DetectedObjects /perception/object_recognition/tracking/objects autoware_perception_msgs/msg/TrackedObjects <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /driving_log_replayer/marker/ground_truth visualization_msgs::msg::MarkerArray /driving_log_replayer/marker/results visualization_msgs::msg::MarkerArray"},{"location":"ja/use_case/perception/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false / true (\u30c7\u30d5\u30a9\u30eb\u30c8 false\u3001\u30b7\u30ca\u30ea\u30aa\u306e <code>LaunchSensing</code> \u30ad\u30fc\u3067 t4_dataset \u6bce\u306b\u6307\u5b9a\u3059\u308b)</li> </ul> <p>\u6ce8:\u30a2\u30ce\u30fc\u30c6\u30b7\u30e7\u30f3\u6642\u3068\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u6642\u3067\u81ea\u5df1\u4f4d\u7f6e\u3092\u5408\u308f\u305b\u305f\u3044\u306e\u3067 bag \u306b\u5165\u3063\u3066\u3044\u308b tf \u3092\u4f7f\u3044\u56de\u3059\u3002\u305d\u306e\u305f\u3081 localization \u306f\u7121\u52b9\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_12","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea","text":"<p>\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1\u306fperception_eval\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/perception/#driving_log_replayer","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e driving_log_replayer \u306e\u5f79\u5272\u5206\u62c5","text":"<p>driving_log_replayer \u304c ROS \u3068\u306e\u63a5\u7d9a\u90e8\u5206\u3092\u62c5\u5f53\u3057\u3001perception_eval \u304c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u3063\u3066\u5b9f\u969b\u306b\u8a55\u4fa1\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3068\u3044\u3046\u5206\u62c5\u306b\u306a\u3063\u3066\u3044\u308b\u3002 perception_eval \u306f ROS \u975e\u4f9d\u5b58\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306a\u306e\u3067\u3001ROS \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002 \u307e\u305f\u3001timestamp \u304c ROS \u3067\u306f\u30ca\u30ce\u79d2\u3001t4_dataset \u306f <code>nuScenes</code> \u3092\u30d9\u30fc\u30b9\u3057\u3066\u3044\u308b\u305f\u3081\u30df\u30ea\u79d2\u304c\u63a1\u7528\u3055\u308c\u3066\u3044\u308b\u3002 \u3053\u306e\u305f\u3081\u3001\u30e9\u30a4\u30d6\u30e9\u30ea\u4f7f\u7528\u524d\u306b\u9069\u5207\u306a\u5909\u63db\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002</p> <p>driving_log_replayer \u306f\u3001autoware \u306e perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304b\u3089\u51fa\u529b\u3055\u308c\u305f topic \u3092 subscribe \u3057\u3001perception_eval \u3067\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b class \u306b\u5408\u308f\u305b\u305f\u30c7\u30fc\u30bf\u5f62\u5f0f\u306b\u5909\u63db\u3057\u3066\u6e21\u3059\u3002 \u307e\u305f\u3001perception_eval \u304b\u3089\u8fd4\u3063\u3066\u304f\u308b\u8a55\u4fa1\u7d50\u679c\u306e ROS \u306e topic \u3067 publish \u3057\u53ef\u8996\u5316\u3059\u308b\u90e8\u5206\u3082\u62c5\u5f53\u3059\u308b\u3002</p> <p>perception_eval \u306f\u3001driving_log_replayer \u304b\u3089\u6e21\u3055\u308c\u305f\u691c\u77e5\u7d50\u679c\u3068 GroundTruth \u3092\u6bd4\u8f03\u3057\u3066\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3001\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>t4_dataset \u3067\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068</p> <p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b\u3002 /sensing/lidar/concatenated/pointcloud \u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306e LaunchSensing: false \u306e\u5834\u5408\u306b\u4f7f\u7528\u3055\u308c\u308b\u3002</p> <p>CAMERA \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e camera_info \u3068 image_rect_color_compressed \u3092\u542b\u3081\u308b</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /localization/kinematic_state nav_msgs/msg/Odometry /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /localization/kinematic_state nav_msgs/msg/Odometry /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/perception/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/perception/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_13","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u8a55\u4fa1\u3068\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e 2 \u7a2e\u985e\u306e\u8a55\u4fa1\u304c\u3042\u308b\u3002 \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f 1 \u500b\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u884c\u3046\u8a55\u4fa1\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u8907\u6570\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306e\u7d50\u679c\u306e\u5e73\u5747\u3092\u53d6\u308b\u8a55\u4fa1\u3067\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u5024\u306e\u5909\u66f4\u304c\u3042\u308a\u5f97\u308b\u306e\u3067 vehicle_id \u3092\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306b\u8a2d\u5b9a\u51fa\u6765\u308b\u3088\u3046\u306b\u3059\u308b\u3002 \u307e\u305f\u3001Sensing \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3059\u308b\u304b\u3069\u3046\u304b\u306e\u8a2d\u5b9a\u3082\u884c\u3046\u3002</p> <p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/perception/#_14","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>perception \u3067\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3057\u305f\u6761\u4ef6\u3067 perception_eval \u304c\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u3092\u5404 frame \u6bce\u306b\u51fa\u529b\u3059\u308b\u3002 \u5168\u3066\u306e\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u7d42\u308f\u3063\u305f\u3042\u3068\u306b\u3001\u6700\u7d42\u7684\u306a\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u8a08\u7b97\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u6700\u7d42\u884c\u3060\u3051\u3001\u4ed6\u306e\u884c\u3068\u5f62\u5f0f\u304c\u7570\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3068\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u305ft4_dataset\u306e\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\",\n    \"FrameSkip\": \"\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u5408\u8a08\u3002\u767a\u751f\u3059\u308b\u6761\u4ef6\u306f\u8a55\u4fa1\u7d50\u679c\u306e\u9805\u76ee\u3092\u53c2\u7167\",\n    \"criteria0\": {\n      // criteria0\u306e\u7d50\u679c\u3001\u771f\u5024\u3068\u8a8d\u8b58\u7d50\u679c\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\n      \"PassFail\": {\n        \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n        \"Info\": {\n          \"TP\": \"\u30d5\u30a3\u30eb\u30bf\u6e08\u307fobject\u306e\u4e2d\u3067TP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n          \"FP\": \"\u30d5\u30a3\u30eb\u30bf\u6e08\u307fobject\u306e\u4e2d\u3067FP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n          \"FN\": \"\u30d5\u30a3\u30eb\u30bf\u6e08\u307fobject\u306e\u4e2d\u3067FN\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\"\n        },\n        \"Objects\": {\n          // \u8a55\u4fa1\u3057\u305fobject\u306e\u60c5\u5831 \u5225\u9014\u8aac\u660e\u3059\u308b\n        }\n      }\n    },\n    \"criteria1\": {\n      // criteria1\u306e\u7d50\u679c\u3001\u771f\u5024\u3068\u8a8d\u8b58\u7d50\u679c\u304c\u5b58\u5728\u3057\u306a\u3044\u5834\u5408\n      \"NoGTNoObj\": \"\u771f\u5024\u3068\u8a8d\u8b58\u7d50\u679c\u304c\u30d5\u30a3\u30eb\u30bf\u3055\u308c\u3066\u8a55\u4fa1\u3067\u304d\u306a\u304b\u3063\u305f\u56de\u6570\"\n    }\n  }\n}\n</code></pre> <p>\u8b66\u544a\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"Warning\": \"\u8b66\u544a\u306e\u30e1\u30c3\u30bb\u30fc\u30b8\",\n    \"FrameSkip\": \"\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u5408\u8a08\u3002object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u5834\u5408\u3001\u307e\u305f\u306f\u3001footprint.points\u306e\u6570\u304c1\u304b2\u306e\u5834\u5408\u306b\u767a\u751f\u3059\u308b\"\n  }\n}\n</code></pre> <p>Objects\u30c7\u30fc\u30bf\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <p>json schema\u3092\u53c2\u7167</p> <p>\u30e1\u30c8\u30ea\u30af\u30b9\u30c7\u30fc\u30bf\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <p>evaluation_task\u304cdetection\u307e\u305f\u306ftracking\u306e\u5834\u5408</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTP\u7387\",\n          \"label0\": \"label0\u306eTP\u7387\",\n          \"label1\": \"label1\u306eTP\u7387\"\n        },\n        \"FP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFP\u7387\",\n          \"label0\": \"label0\u306eFP\u7387\",\n          \"label1\": \"label1\u306eFP\u7387\"\n        },\n        \"FN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFN\u7387\",\n          \"label0\": \"label0\u306eFN\u7387\",\n          \"label1\": \"label1\u306eFN\u7387\"\n        },\n        \"TN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTN\u7387\",\n          \"label0\": \"label0\u306eTN\u7387\",\n          \"label1\": \"label1\u306eTN\u7387\"\n        },\n        \"AP(Center Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(Center Distance)\",\n          \"label0\": \"label0\u306eAP\u7387(Center Distance)\",\n          \"label1\": \"label1\u306eAP\u7387(Center Distance)\"\n        },\n        \"APH(Center Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(Center Distance)\",\n          \"label0\": \"label0\u306eAPH\u7387(Center Distance)\",\n          \"label1\": \"label1\u306eAPH\u7387(Center Distance)\"\n        },\n        \"AP(IoU 2D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(IoU 2D)\",\n          \"label0\": \"label0\u306eAP\u7387(IoU 2D)\",\n          \"label1\": \"label1\u306eAP\u7387(IoU 2D)\"\n        },\n        \"APH(IoU 2D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(IoU 2D)\",\n          \"label0\": \"label0\u306eAPH\u7387(IoU 2D)\",\n          \"label1\": \"label1\u306eAPH\u7387(IoU 2D)\"\n        },\n        \"AP(IoU 3D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(IoU 3D)\",\n          \"label0\": \"label0\u306eAP\u7387(IoU 3D)\",\n          \"label1\": \"label1\u306eAP\u7387(IoU 3D)\"\n        },\n        \"APH(IoU 3D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(IoU 3D)\",\n          \"label0\": \"label0\u306eAPH\u7387(IoU 3D)\",\n          \"label1\": \"label1\u306eAPH\u7387(IoU 3D)\"\n        },\n        \"AP(Plane Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(Plane Distance)\",\n          \"label0\": \"label0\u306eAP\u7387(Plane Distance)\",\n          \"label1\": \"label1\u306eAP\u7387(Plane Distance)\"\n        },\n        \"APH(Plane Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(Plane Distance)\",\n          \"label0\": \"label0\u306eAPH\u7387(Plane Distance)\",\n          \"label1\": \"label1\u306eAPH\u7387(Plane Distance)\"\n        }\n      },\n      \"MOTA\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/ja/perception/metrics.md#tracking\"},\n      \"MOTA\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/ja/perception/metrics.md#tracking\"},\n      \"IDswitch\": {\"https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/ja/perception/metrics.md#id-switch\"},\n      \"Error\": {\n        \"ALL\": {\n          \"average\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          },\n          \"rms\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          },\n          \"std\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          },\n          \"max\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          },\n          \"min\": {\n            \"x\": \"x\u5ea7\u6a19\",\n            \"y\": \"y\u5ea7\u6a19\",\n            \"yaw\": \"\u30e8\u30fc\u89d2\",\n            \"length\": \"\u9577\u3055\",\n            \"width\": \"\u5e45\",\n            \"vx\": \"x\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"vy\": \"y\u65b9\u5411\u306e\u901f\u5ea6\",\n            \"nn_plane\": \"\u6700\u8fd1\u508d\u9762\u306e\u8ddd\u96e2\"\n          }\n        },\n        \"label0\": \"label0\u306e\u8aa4\u5dee\u30e1\u30c8\u30ea\u30af\u30b9\"\n      }\n    }\n  }\n}\n</code></pre> <p>evaluation_task\u304cfp_validation\u306e\u5834\u5408</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"GroundTruthStatus\": {\n        \"UUID\": {\n          \"rate\": {\n            \"TP\": \"\u8868\u793aUUID\u306eTP\u7387\",\n            \"FP\": \"\u8868\u793aUUID\u306eFP\u7387\",\n            \"TN\": \"\u8868\u793aUUID\u306eTN\u7387\",\n            \"FN\": \"\u8868\u793aUUID\u306eFN\u7387\"\n          },\n          \"frame_nums\": {\n            \"total\": \"GT\u304c\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\",\n            \"TP\": \"GT\u304cTP\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\",\n            \"FP\": \"GT\u304cFP\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\",\n            \"TN\": \"GT\u304cTN\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\",\n            \"FN\": \"GT\u304cFN\u3068\u3057\u3066\u8a55\u4fa1\u3055\u308c\u308b\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\u306e\u30ea\u30b9\u30c8\"\n          }\n        }\n      },\n      \"Scene\": {\n        \"TP\": \"\u30b7\u30fc\u30f3\u306eTP\u7387\",\n        \"FP\": \"\u30b7\u30fc\u30f3\u306eFP\u7387\",\n        \"TN\": \"\u30b7\u30fc\u30f3\u306eTN\u7387\",\n        \"FN\": \"\u30b7\u30fc\u30f3\u306eFN\u7387\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/perception/#pickle","title":"pickle \u30d5\u30a1\u30a4\u30eb","text":"<p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u8907\u6570\u306e bag \u3092\u518d\u751f\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\u3001ROS \u306e\u4ed5\u69d8\u4e0a\u30011 \u56de\u306e launch \u3067\u3001\u8907\u6570\u306e bag \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u306f\u51fa\u6765\u306a\u3044\u3002 1 \u3064\u306e bag\u3001\u3059\u306a\u308f\u3061 1 \u3064\u306e t4_dataset \u306b\u5bfe\u3057\u3066 launch \u3092 1 \u56de\u53e9\u304f\u3053\u3068\u306a\u308b\u306e\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u542b\u307e\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6570\u3060\u3051 launch \u3092\u5b9f\u884c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306f 1 \u56de\u306e launch \u3067\u8a55\u4fa1\u3067\u304d\u306a\u3044\u305f\u3081\u3001perception \u3067\u306f\u3001result.jsonl \u306e\u4ed6\u306b scene_result.pkl \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u3092\u51fa\u529b\u3059\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306f python \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u305f\u3082\u306e\u3067\u3042\u308a\u3001perception_eval \u306e PerceptionEvaluationManager.frame_results \u3092\u4fdd\u5b58\u3057\u3066\u3044\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3057\u305f object \u3092\u3059\u3079\u3066\u8aad\u307f\u8fbc\u307f\u3001dataset \u306e\u5e73\u5747\u306e\u6307\u6a19\u3092\u51fa\u529b\u3059\u308b\u3053\u3068\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u8a55\u4fa1\u304c\u884c\u3048\u308b\u3002</p>"},{"location":"ja/use_case/perception/#_15","title":"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306b\u8907\u6570\u306e dataset \u3092\u8a18\u8ff0\u3057\u305f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u5834\u5408\u306b\u306f\u3001\u7d50\u679c\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b database_result.json \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u5f62\u5f0f\u306f\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8 \u3068\u540c\u3058</p>"},{"location":"ja/use_case/perception_2d/","title":"\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1(\u30ab\u30e1\u30e9)","text":"<p>Autoware \u306e\u8a8d\u8b58\u6a5f\u80fd(perception)\u306e\u8a8d\u8b58\u7d50\u679c\u304b\u3089 mAP(mean Average Precision)\u306a\u3069\u306e\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3066\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>perception \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3057\u3066\u51fa\u529b\u3055\u308c\u308b perception \u306e topic \u3092\u8a55\u4fa1\u7528\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u6e21\u3057\u3066\u8a55\u4fa1\u3092\u884c\u3046\u3002</p>"},{"location":"ja/use_case/perception_2d/#_2","title":"\u4e8b\u524d\u6e96\u5099","text":"<p>perception \u3067\u306f\u3001\u6a5f\u68b0\u5b66\u7fd2\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3002 \u30e2\u30c7\u30eb\u3092\u4e8b\u524d\u306b\u6e96\u5099\u3057\u3066\u3044\u306a\u3044\u3068Autoware\u304b\u3089\u8a8d\u8b58\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u306a\u3044\u3002 \u4f55\u3082\u8a55\u4fa1\u7d50\u679c\u304c\u51fa\u3066\u3053\u306a\u3044\u5834\u5408\u306f\u3001\u3053\u306e\u4f5c\u696d\u304c\u6b63\u3057\u304f\u51fa\u6765\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_3","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30e2\u30c7\u30eb\u306fAutoware\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6642\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306f\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b\u306bAutoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u306e\u3067\u3069\u3061\u3089\u306e\u624b\u6cd5\u304c\u4f7f\u308f\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u4ee5\u4e0b\u306e\u30d1\u30bf\u30fc\u30f3\u304c\u5b58\u5728\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#ansible","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30b9\u30af\u30ea\u30d7\u30c8\u5b9f\u884c\u6642\u306b<code>Download artifacts? [y/N]</code>\u3068\u51fa\u3066\u304f\u308b\u306e\u3067<code>y</code>\u3092\u5165\u529b\u3057\u3066\u30a8\u30f3\u30bf\u30fc\u3092\u62bc\u3059(Autoware foundation\u306emain\u3060\u3068\u3053\u3061\u3089) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"ja/use_case/perception_2d/#_4","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u5c11\u3057\u53e4\u3044Autoware.universe\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3053\u3061\u3089\u3001<code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>\u306e\u30b3\u30df\u30c3\u30c8\u30cf\u30c3\u30b7\u30e5\u307e\u3067\u306f\u3053\u3061\u3089\u304c\u4f7f\u7528\u3055\u308c\u308b\u3002 tensorrt_yolox/CMakeList.txt</p>"},{"location":"ja/use_case/perception_2d/#_5","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u63db","text":"<p>\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f onnx \u30d5\u30a1\u30a4\u30eb\u306f\u305d\u306e\u307e\u307e\u4f7f\u7528\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001TensorRT \u306e engine \u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u3066\u5229\u7528\u3059\u308b\u3002 \u5909\u63db\u7528\u306e\u30b3\u30de\u30f3\u30c9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001autoware \u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092 source \u3057\u3066\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002</p> <p><code>$HOME/autoware</code>\u306bautoware\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3068\u3057\u3066\u8aac\u660e\u3059\u308b\u3002</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch tensorrt_yolox yolox.launch.xml use_decompress:=false build_only:=true\n</code></pre>"},{"location":"ja/use_case/perception_2d/#ansible_1","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <pre><code>$HOME/autoware_data/tensorrt_yolox/yolox-sPlus-T4-960x960-pseudo-finetune.EntropyV2-int8-batch1.engine\n</code></pre>"},{"location":"ja/use_case/perception_2d/#_6","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<pre><code>$HOME/autoware/install/tensorrt_yolox/share/tensorrt_yolox/data/yolox-sPlus-T4-960x960-pseudo-finetune.EntropyV2-int8-batch1.engine\n</code></pre>"},{"location":"ja/use_case/perception_2d/#pc1launch","title":"(PC1\u53f0\u3067\u8a55\u4fa1\u3059\u308b\u5834\u5408)launch\u30d5\u30a1\u30a4\u30eb\u306e\u4fee\u6b63","text":"<p>PC \u4e00\u53f0\u3067\u8a55\u4fa1\u3059\u308b\u306b\u306f\u3001launch \u3092\u3044\u3058\u3063\u3066\u3001\u30ab\u30e1\u30e9\u306e\u8a8d\u8b58\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u3088\u3046\u306b\u5909\u66f4\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 \u4ee5\u4e0b\u306e\u3088\u3046\u306b\u3001launch \u3092\u5909\u66f4\u3059\u308b\u3002</p> <pre><code>\u276f vcs diff src/\n.................................\ndiff --git a/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml b/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\nindex 9ca8ea3df..a35e8d00f 100644\n--- a/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\n+++ b/launch/tier4_perception_launch/launch/object_recognition/detection/camera_lidar_fusion_based_detection.launch.xml\n@@ -30,6 +30,14 @@\n   &lt;arg name=\"remove_unknown\" default=\"true\"/&gt;\n   &lt;arg name=\"trust_distance\" default=\"30.0\"/&gt;\n\n+  &lt;group&gt;\n+    &lt;include file=\"$(find-pkg-share tensorrt_yolox)/launch/yolox.launch.xml\" /&gt;\n+  &lt;/group&gt;\n+\n+  &lt;group&gt;\n+    &lt;include file=\"$(find-pkg-share bytetrack)/launch/bytetrack.launch.xml\" /&gt;\n+  &lt;/group&gt;\n+\n   &lt;!-- Jetson AGX --&gt;\n   &lt;!-- &lt;include file=\"$(find-pkg-share tensorrt_yolo)/launch/yolo.launch.xml\"&gt;\n     &lt;arg name=\"image_raw0\" value=\"$(var image_raw0)\"/&gt;\ndiff --git a/launch/tier4_perception_launch/launch/perception.launch.xml b/launch/tier4_perception_launch/launch/perception.launch.xml\nindex 0a2ef57f6..9a9b06379 100644\n--- a/launch/tier4_perception_launch/launch/perception.launch.xml\n+++ b/launch/tier4_perception_launch/launch/perception.launch.xml\n@@ -33,7 +33,7 @@\n   &lt;arg name=\"camera_info6\" default=\"/sensing/camera/camera6/camera_info\"/&gt;\n   &lt;arg name=\"image_raw7\" default=\"/sensing/camera/camera7/image_rect_color\"/&gt;\n   &lt;arg name=\"camera_info7\" default=\"/sensing/camera/camera7/camera_info\"/&gt;\n-  &lt;arg name=\"image_number\" default=\"6\" description=\"choose image raw number(0-7)\"/&gt;\n+  &lt;arg name=\"image_number\" default=\"1\" description=\"choose image raw number(0-7)\"/&gt;\n   &lt;arg name=\"use_vector_map\" default=\"true\" description=\"use vector map in prediction\"/&gt;\n   &lt;arg name=\"use_pointcloud_map\" default=\"true\" description=\"use pointcloud map in detection\"/&gt;\n   &lt;arg name=\"use_object_filter\" default=\"true\" description=\"use object filter\"/&gt;\ndiff --git a/perception/tensorrt_yolox/launch/yolox.launch.xml b/perception/tensorrt_yolox/launch/yolox.launch.xml\nindex b697b1f50..b9cb53102 100644\n--- a/perception/tensorrt_yolox/launch/yolox.launch.xml\n+++ b/perception/tensorrt_yolox/launch/yolox.launch.xml\n@@ -1,7 +1,7 @@\n &lt;?xml version=\"1.0\"?&gt;\n &lt;launch&gt;\n   &lt;arg name=\"input/image\" default=\"/sensing/camera/camera0/image_rect_color\"/&gt;\n-  &lt;arg name=\"output/objects\" default=\"/perception/object_recognition/detection/rois0\"/&gt;\n+  &lt;arg name=\"output/objects_yolox\" default=\"/perception/object_recognition/detection/rois0\"/&gt;\n   &lt;arg name=\"model_name\" default=\"yolox-tiny\"/&gt;\n   &lt;arg name=\"model_path\" default=\"$(find-pkg-share tensorrt_yolox)/data\"/&gt;\n   &lt;arg name=\"score_threshold\" default=\"0.35\"/&gt;\n@@ -16,7 +16,7 @@\n\n   &lt;node pkg=\"tensorrt_yolox\" exec=\"tensorrt_yolox_node_exe\" name=\"tensorrt_yolox\" output=\"screen\"&gt;\n     &lt;remap from=\"~/in/image\" to=\"$(var input/image)\"/&gt;\n-    &lt;remap from=\"~/out/objects\" to=\"$(var output/objects)\"/&gt;\n+    &lt;remap from=\"~/out/objects\" to=\"$(var output/objects_yolox)\"/&gt;\n     &lt;param name=\"score_threshold\" value=\"$(var score_threshold)\"/&gt;\n     &lt;param name=\"nms_threshold\" value=\"$(var nms_threshold)\"/&gt;\n     &lt;param name=\"model_path\" value=\"$(var model_path)/$(var model_name).onnx\"/&gt;\n</code></pre>"},{"location":"ja/use_case/perception_2d/#_7","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>perception.launch_2d.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>perception_2d_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u30ab\u30e1\u30e9\u30c7\u30fc\u30bf\u3092\u51fa\u529b\u3057\u3001perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u8a8d\u8b58\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/perception/object_recognition/detection{/tracked}/rois{camera_no} \u3092 subscribe \u3057\u3066\u3001\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3067 perception_eval \u306e\u95a2\u6570\u3092\u7528\u3044\u3066\u8a55\u4fa1\u3057\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/perception_2d/#_8","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_9","title":"\u6b63\u5e38","text":"<p>perception_eval \u306e\u8a55\u4fa1\u95a2\u6570\u3092\u5b9f\u884c\u3057\u3066\u4ee5\u4e0b\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3059\u3068\u304d</p> <ol> <li>frame_result.pass_fail_result \u306b object \u304c\u6700\u4f4e 1 \u3064\u5165\u3063\u3066\u3044\u308b (<code>tp_object_results != [] and fp_object_results != [] and fn_objects != []</code>)</li> <li>\u8a55\u4fa1\u5931\u6557\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c 0 \u500b (<code>frame_result.pass_fail_result.get_fail_object_num() == 0</code>)</li> </ol>"},{"location":"ja/use_case/perception_2d/#_10","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/perception_2d/#_11","title":"\u8a55\u4fa1\u30b9\u30ad\u30c3\u30d7","text":"<p>\u4ee5\u4e0b\u306e\u5834\u5408\u306b\u3001\u8a55\u4fa1\u3092\u305b\u305a\u306b\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u30ab\u30a6\u30f3\u30c8(FrameSkip)\u30921\u8db3\u3059\u51e6\u7406\u306e\u307f\u884c\u3046</p> <ul> <li>\u53d7\u4fe1\u3057\u305fobject\u306e\u30d8\u30c3\u30c0\u30fc\u6642\u523b\u306e\u524d\u5f8c75msec\u4ee5\u5185\u306b\u771f\u5024\u304c\u5b58\u5728\u3057\u306a\u3044\u5834\u5408</li> </ul>"},{"location":"ja/use_case/perception_2d/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/object_recognition/detection/rois{camera_no} tier4_perception_msgs/msg/DetectedObjectsWithFeature /perception/object_recognition/detection/tracked/rois{camera_no} tier4_perception_msgs/msg/DetectedObjectsWithFeature <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b - -"},{"location":"ja/use_case/perception_2d/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false / true (\u30c7\u30d5\u30a9\u30eb\u30c8 false\u3001\u30b7\u30ca\u30ea\u30aa\u306e <code>LaunchSensing</code> \u30ad\u30fc\u3067 t4_dataset \u6bce\u306b\u6307\u5b9a\u3059\u308b)</li> <li>perception_mode: camera_lidar_fusion</li> </ul> <p>\u6ce8:\u30a2\u30ce\u30fc\u30c6\u30b7\u30e7\u30f3\u6642\u3068\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u6642\u3067\u81ea\u5df1\u4f4d\u7f6e\u3092\u5408\u308f\u305b\u305f\u3044\u306e\u3067 bag \u306b\u5165\u3063\u3066\u3044\u308b tf \u3092\u4f7f\u3044\u56de\u3059\u3002\u305d\u306e\u305f\u3081 localization \u306f\u7121\u52b9\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_12","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea","text":"<p>\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1\u306fperception_eval\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#driving_log_replayer","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e driving_log_replayer \u306e\u5f79\u5272\u5206\u62c5","text":"<p>driving_log_replayer \u304c ROS \u3068\u306e\u63a5\u7d9a\u90e8\u5206\u3092\u62c5\u5f53\u3057\u3001perception_eval \u304c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u3063\u3066\u5b9f\u969b\u306b\u8a55\u4fa1\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3068\u3044\u3046\u5206\u62c5\u306b\u306a\u3063\u3066\u3044\u308b\u3002 perception_eval \u306f ROS \u975e\u4f9d\u5b58\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306a\u306e\u3067\u3001ROS \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002 \u307e\u305f\u3001timestamp \u304c ROS \u3067\u306f\u30ca\u30ce\u79d2\u3001t4_dataset \u306f <code>nuScenes</code> \u3092\u30d9\u30fc\u30b9\u3057\u3066\u3044\u308b\u305f\u3081\u30df\u30ea\u79d2\u304c\u63a1\u7528\u3055\u308c\u3066\u3044\u308b\u3002 \u3053\u306e\u305f\u3081\u3001\u30e9\u30a4\u30d6\u30e9\u30ea\u4f7f\u7528\u524d\u306b\u9069\u5207\u306a\u5909\u63db\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002</p> <p>driving_log_replayer \u306f\u3001autoware \u306e perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304b\u3089\u51fa\u529b\u3055\u308c\u305f topic \u3092 subscribe \u3057\u3001perception_eval \u3067\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b class \u306b\u5408\u308f\u305b\u305f\u30c7\u30fc\u30bf\u5f62\u5f0f\u306b\u5909\u63db\u3057\u3066\u6e21\u3059\u3002 \u307e\u305f\u3001perception_eval \u304b\u3089\u8fd4\u3063\u3066\u304f\u308b\u8a55\u4fa1\u7d50\u679c\u306e ROS \u306e topic \u3067 publish \u3057\u53ef\u8996\u5316\u3059\u308b\u90e8\u5206\u3082\u62c5\u5f53\u3059\u308b\u3002</p> <p>perception_eval \u306f\u3001driving_log_replayer \u304b\u3089\u6e21\u3055\u308c\u305f\u691c\u77e5\u7d50\u679c\u3068 GroundTruth \u3092\u6bd4\u8f03\u3057\u3066\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3001\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>t4_dataset \u3067\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068</p> <p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b\u3002 /sensing/lidar/concatenated/pointcloud \u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306e LaunchSensing: false \u306e\u5834\u5408\u306b\u4f7f\u7528\u3055\u308c\u308b\u3002</p> <p>CAMERA \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e camera_info \u3068 image_rect_color_compressed \u3092\u542b\u3081\u308b</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/perception_2d/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/perception_2d/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_13","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u8a55\u4fa1\u3068\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e 2 \u7a2e\u985e\u306e\u8a55\u4fa1\u304c\u3042\u308b\u3002 \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f 1 \u500b\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u884c\u3046\u8a55\u4fa1\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u8907\u6570\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306e\u7d50\u679c\u306e\u5e73\u5747\u3092\u53d6\u308b\u8a55\u4fa1\u3067\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u5024\u306e\u5909\u66f4\u304c\u3042\u308a\u5f97\u308b\u306e\u3067 vehicle_id \u3092\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306b\u8a2d\u5b9a\u51fa\u6765\u308b\u3088\u3046\u306b\u3059\u308b\u3002 \u307e\u305f\u3001Sensing \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3059\u308b\u304b\u3069\u3046\u304b\u306e\u8a2d\u5b9a\u3082\u884c\u3046\u3002</p> <p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/perception_2d/#_14","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>perception \u3067\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3057\u305f\u6761\u4ef6\u3067 perception_eval \u304c\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u3092\u5404 frame \u6bce\u306b\u51fa\u529b\u3059\u308b\u3002 \u5168\u3066\u306e\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u7d42\u308f\u3063\u305f\u3042\u3068\u306b\u3001\u6700\u7d42\u7684\u306a\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u8a08\u7b97\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u6700\u7d42\u884c\u3060\u3051\u3001\u4ed6\u306e\u884c\u3068\u5f62\u5f0f\u304c\u7570\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3068\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"CameraType\": \"\u8a55\u4fa1\u3057\u305f\u30ab\u30e1\u30e9\",\n    \"FrameName\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u305ft4_dataset\u306e\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\",\n    \"FrameSkip\": \"object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u8a55\u4fa1\u3092\u98db\u3070\u3055\u308c\u305f\u56de\u6570\",\n    \"PassFail\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TP\": \"TP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n        \"FP\": \"FP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n        \"FN\": \"FN\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\"\n      }\n    }\n  }\n}\n</code></pre> <p>\u30e1\u30c8\u30ea\u30af\u30b9\u30c7\u30fc\u30bf\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTP\u7387\",\n          \"label0\": \"label0\u306eTP\u7387\",\n          \"label1\": \"label1\u306eTP\u7387\"\n        },\n        \"FP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFP\u7387\",\n          \"label0\": \"label0\u306eFP\u7387\",\n          \"label1\": \"label1\u306eFP\u7387\"\n        },\n        \"FN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFN\u7387\",\n          \"label0\": \"label0\u306eFN\u7387\",\n          \"label1\": \"label1\u306eFN\u7387\"\n        },\n        \"TN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTN\u7387\",\n          \"label0\": \"label0\u306eTN\u7387\",\n          \"label1\": \"label1\u306eTN\u7387\"\n        },\n        \"AP(Center Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(Center Distance)\",\n          \"label0\": \"label0\u306eAP\u7387(Center Distance)\",\n          \"label1\": \"label1\u306eAP\u7387(Center Distance)\"\n        },\n        \"APH(Center Distance)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(Center Distance)\",\n          \"label0\": \"label0\u306eAPH\u7387(Center Distance)\",\n          \"label1\": \"label1\u306eAPH\u7387(Center Distance)\"\n        },\n        \"AP(IoU 2D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAP\u7387(IoU 2D)\",\n          \"label0\": \"label0\u306eAP\u7387(IoU 2D)\",\n          \"label1\": \"label1\u306eAP\u7387(IoU 2D)\"\n        },\n        \"APH(IoU 2D)\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAPH\u7387(IoU 2D)\",\n          \"label0\": \"label0\u306eAPH\u7387(IoU 2D)\",\n          \"label1\": \"label1\u306eAPH\u7387(IoU 2D)\"\n        }\n      },\n      \"ConfusionMatrix\": {\n        \"label0(\u771f\u5024)\": {\n          \"label0(\u4e88\u6e2c\u5024)\": \"\u5024\",\n          \"label1(\u4e88\u6e2c\u5024)\": \"\u5024\"\n        },\n        \"label1(\u771f\u5024)\": {\n          \"label0(\u4e88\u6e2c\u5024)\": \"\u5024\",\n          \"label1(\u4e88\u6e2c\u5024)\": \"\u5024\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/perception_2d/#pickle","title":"pickle \u30d5\u30a1\u30a4\u30eb","text":"<p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u8907\u6570\u306e bag \u3092\u518d\u751f\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\u3001ROS \u306e\u4ed5\u69d8\u4e0a\u30011 \u56de\u306e launch \u3067\u3001\u8907\u6570\u306e bag \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u306f\u51fa\u6765\u306a\u3044\u3002 1 \u3064\u306e bag\u3001\u3059\u306a\u308f\u3061 1 \u3064\u306e t4_dataset \u306b\u5bfe\u3057\u3066 launch \u3092 1 \u56de\u53e9\u304f\u3053\u3068\u306a\u308b\u306e\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u542b\u307e\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6570\u3060\u3051 launch \u3092\u5b9f\u884c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306f 1 \u56de\u306e launch \u3067\u8a55\u4fa1\u3067\u304d\u306a\u3044\u305f\u3081\u3001perception \u3067\u306f\u3001result.jsonl \u306e\u4ed6\u306b scene_result.pkl \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u3092\u51fa\u529b\u3059\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306f python \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u305f\u3082\u306e\u3067\u3042\u308a\u3001perception_eval \u306e PerceptionEvaluationManager.frame_results \u3092\u4fdd\u5b58\u3057\u3066\u3044\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3057\u305f object \u3092\u3059\u3079\u3066\u8aad\u307f\u8fbc\u307f\u3001dataset \u306e\u5e73\u5747\u306e\u6307\u6a19\u3092\u51fa\u529b\u3059\u308b\u3053\u3068\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u8a55\u4fa1\u304c\u884c\u3048\u308b\u3002</p>"},{"location":"ja/use_case/perception_2d/#_15","title":"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306b\u8907\u6570\u306e dataset \u3092\u8a18\u8ff0\u3057\u305f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u5834\u5408\u306b\u306f\u3001\u7d50\u679c\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b database_result.json \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u5f62\u5f0f\u306f\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8 \u3068\u540c\u3058</p>"},{"location":"ja/use_case/performance_diag/","title":"\u8a3a\u65ad\u6a5f\u80fd\u306e\u8a55\u4fa1","text":"<p>Autoware \u306e\u8a3a\u65ad\u6a5f\u80fd(diagnostics)\u304c\u610f\u56f3\u901a\u308a\u306b\u6a5f\u80fd\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>\u73fe\u5728\u306f\u3001lidar \u306e visibility \u3068 blockage \u306e\u8a55\u4fa1\u306b\u5bfe\u5fdc\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>visibility: \u9727\u3084\u96e8\u306a\u3069\u3067\u8996\u754c\u304c\u60aa\u304f\u306a\u3063\u3066\u3044\u306a\u3044\u304b\u3092\u5224\u5b9a\u3059\u308b\u6a5f\u80fd</li> <li>blockage: LiDAR \u306b\u8449\u3063\u3071\u306a\u3069\u304c\u4ed8\u7740\u3057\u3066\u8a08\u6e2c\u306e\u59a8\u3052\u3092\u3057\u3066\u3044\u306a\u3044\u304b\u3092\u5224\u5b9a\u3059\u308b\u6a5f\u80fd</li> </ul>"},{"location":"ja/use_case/performance_diag/#_2","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>performance_diag.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>performance_diag_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001/diagnostics \u3092\u51fa\u529b\u3059\u308b</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/diagnostics \u3092 subscribe \u3057\u3066\u3001\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3067\u8a55\u4fa1\u3092\u884c\u3044\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b\u3002</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/performance_diag/#visibility","title":"visibility \u8a55\u4fa1","text":"<p>visibility \u306e\u8a55\u4fa1\u3067\u306f\u3001\u96e8\u5929\u6642\u3084\u4eba\u5de5\u7684\u306b\u96e8\u3092\u964d\u3089\u305b\u3089\u308c\u308b\u65bd\u8a2d\u3067\u53d6\u5f97\u3057\u305f\u30c7\u30fc\u30bf\u3092\u7528\u3044\u3066 visibility \u306e ERROR \u304c\u4e00\u5b9a\u30ec\u30fc\u30c8\u4ee5\u4e0a\u51fa\u529b\u3055\u308c\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002 \u307e\u305f\u3001\u6674\u5929\u6642\u306e\u30c7\u30fc\u30bf\u3092\u5229\u7528\u3057\u3066\u3001ERROR \u304c\u4e00\u5ea6\u3082\u51fa\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002</p> <p><code>/diagnostics</code>\u306e<code>status.name</code>\u304c<code>dual_return_filter: /sensing/lidar/.*: visibility_validation</code>\u306b\u8a72\u5f53\u3059\u308b\u3082\u306e\u3092\u5224\u5b9a\u306b\u5229\u7528\u3059\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#blockage","title":"blockage \u8a55\u4fa1","text":"<p>blockage \u306e\u8a55\u4fa1\u3067\u306f\u3001LiDAR \u3092\u610f\u56f3\u7684\u306b\u30ec\u30fc\u30b6\u30fc\u5149\u3092\u901a\u3055\u306a\u3044\u7d20\u6750(\u7bb1\u306a\u3069)\u3067\u8986\u3063\u305f\u72b6\u614b\u3067\u30c7\u30fc\u30bf\u3092\u53d6\u5f97\u3057 blockage \u306e ERROR \u304c\u4e00\u5b9a\u30ec\u30fc\u30c8\u4ee5\u4e0a\u51fa\u529b\u3055\u308c\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002 \u307e\u305f\u3001\u8986\u3063\u3066\u306a\u3044 LiDAR \u306b\u3064\u3044\u3066\u306f ERROR \u304c\u4e00\u5ea6\u3082\u51fa\u306a\u3044\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002</p> <p><code>/diagnostics</code>\u306e<code>status.name</code>\u304c<code>blockage_return_diag: /sensing/lidar/.*: blockage_validation</code>\u306b\u8a72\u5f53\u3059\u308b\u3082\u306e\u3092\u5224\u5b9a\u306b\u5229\u7528\u3059\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#_3","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>LiDAR \u306e\u8a3a\u65ad\u7d50\u679c\u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u8a55\u4fa1\u3057\u305f\u3044\u5185\u5bb9\u306b\u3088\u3063\u3066 ERROR \u304c\u51fa\u308b\u5834\u5408\u3092\u6210\u529f\u3068\u3059\u308b\u304b\u5931\u6557\u3068\u3059\u308b\u304b\u304c\u5206\u304b\u308c\u308b\u306e\u3067\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u30bf\u30a4\u30d7\u3092\u8a18\u8ff0\u3059\u308b\u3053\u3068\u3067\u5909\u66f4\u3067\u304d\u308b\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u308b\u3002</p> <ul> <li>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c TP \u306e\u5834\u5408\u306f Diag \u304c ERROR \u306b\u306a\u308c\u3070\u6210\u529f</li> <li>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c FP \u306e\u5834\u5408\u306f Diag \u304c ERROR \u306b\u306a\u3089\u306a\u3051\u308c\u3070\u6210\u529f</li> <li>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c null \u306e\u5834\u5408\u306f\u30c6\u30b9\u30c8\u3092\u7701\u7565\u3059\u308b</li> </ul>"},{"location":"ja/use_case/performance_diag/#tp","title":"TP \u6b63\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c TP \u306e\u5834\u5408\u3067\u3001\u8a3a\u65ad\u60c5\u5831\u306e level \u304c ERROR(=2)\u306e\u5834\u5408</p>"},{"location":"ja/use_case/performance_diag/#tp_1","title":"TP \u7570\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c TP \u306e\u5834\u5408\u3067\u3001\u8a3a\u65ad\u60c5\u5831\u306e level \u304c ERROR \u3067\u306a\u3044(!=2)\u306e\u5834\u5408</p>"},{"location":"ja/use_case/performance_diag/#fp","title":"FP \u6b63\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c FP \u306e\u5834\u5408\u3067\u3001\u8a3a\u65ad\u60c5\u5831\u306e level \u304c ERROR \u3067\u306a\u3044(!=2)\u306e\u5834\u5408</p>"},{"location":"ja/use_case/performance_diag/#fp_1","title":"FP \u7570\u5e38","text":"<p>\u30b7\u30ca\u30ea\u30aa\u7a2e\u985e\u304c FP \u306e\u5834\u5408\u3067\u3001\u8a3a\u65ad\u60c5\u5831\u306e level \u304c ERROR(=2)\u306e\u5834\u5408</p>"},{"location":"ja/use_case/performance_diag/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/obstacle_segmentation/pointcloud sensor_msgs::msg::PointCloud2 /diagnostics diagnostic_msgs::msg::DiagnosticArray /tf tf2_msgs/msg/TFMessage <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /driving_log_replayer/visibility/value example_interfaces::msg::Float64 /driving_log_replayer/visibility/level example_interfaces::msg::Byte /driving_log_replayer/blockage/{lidar_name}/ground/ratio example_interfaces::msg::Float64 /driving_log_replayer/blockage/{lidar_name}/sky/ratio example_interfaces::msg::Float64 /driving_log_replayer/blockage/{lidar_name}/level example_interfaces::msg::Byte <p>{lidar_name}\u306b\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b lidar \u306e\u540d\u524d\u304c\u5165\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /api/localization/initialize InitializeLocalization"},{"location":"ja/use_case/performance_diag/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>planning: false</li> <li>control: false</li> <li>localization: false / true (\u30c7\u30d5\u30a9\u30eb\u30c8 false\u3001\u30b7\u30ca\u30ea\u30aa\u3067\u6307\u5b9a\u3059\u308b)</li> </ul>"},{"location":"ja/use_case/performance_diag/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport <p>\u6ce8:localization \u304c false(\u30c7\u30d5\u30a9\u30eb\u30c8\u3067 false)\u306e\u5834\u5408\u306f/tf \u304c\u4f7f\u7528\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/performance_diag/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/performance_diag/#_4","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/performance_diag/#_5","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>performance_diag \u3067\u306f\u3001visibility \u3068 blockage \u306e 2 \u3064\u3092\u8a55\u4fa1\u3057\u3066\u3044\u308b\u3002 Result \u306f visibility \u3068 blockage \u306e\u4e21\u65b9\u3092\u30d1\u30b9\u3057\u3066\u3044\u308c\u3070 true \u3067\u305d\u308c\u4ee5\u5916\u306f false \u5931\u6557\u3068\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>visibility\u306e\u7d50\u679c(Frame \u306b Visibility \u306e\u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Visibility\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Invalid\" },\n    \"Info\": {\n      \"Level\": \"diag\u306e\u30ec\u30d9\u30eb\",\n      \"Visibility\": \"visibility\u306e\u5024\"\n    }\n  }\n}\n</code></pre> <p>blockage\u306e\u7d50\u679c(Frame \u306b Blockage \u306e\u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Blockage\": {\n    \"LiDAR1\u306e\u540d\u524d\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"Level\": \"diag\u306e\u30ec\u30d9\u30eb\",\n        \"GroundBlockageRatio\": \"\u5730\u4e0a\u5074\u306eblockage\u6bd4\u7387\",\n        \"GroundBlockageCount\": \"\u53c2\u8003\u5024\",\n        \"SkyBlockageRatio\": \"\u7a7a\u4e2d\u5074\u306eblockage\u6bd4\u7387\",\n        \"SkyBlockageCount\": \"\u53c2\u8003\u5024\"\n      }\n    },\n    \"LiDAR2\u306e\u540d\u524d\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"Level\": \"diag\u306e\u30ec\u30d9\u30eb\",\n        \"GroundBlockageRatio\": \"\u5730\u4e0a\u5074\u306eblockage\u6bd4\u7387\",\n        \"GroundBlockageCount\": \"\u53c2\u8003\u5024\",\n        \"SkyBlockageRatio\": \"\u7a7a\u4e2d\u5074\u306eblockage\u6bd4\u7387\",\n        \"SkyBlockageCount\": \"\u53c2\u8003\u5024\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/traffic_light/","title":"\u4fe1\u53f7\u6a5f\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1","text":"<p>Autoware \u306e\u8a8d\u8b58\u6a5f\u80fd(perception)\u306e\u8a8d\u8b58\u7d50\u679c\u304b\u3089 mAP(mean Average Precision)\u306a\u3069\u306e\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3066\u6027\u80fd\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <p>perception \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3057\u3066\u51fa\u529b\u3055\u308c\u308b perception \u306e topic \u3092\u8a55\u4fa1\u7528\u30e9\u30a4\u30d6\u30e9\u30ea\u306b\u6e21\u3057\u3066\u8a55\u4fa1\u3092\u884c\u3046\u3002</p> <p>\u73fe\u72b6\u3001<code>classification2d</code> \u306e\u8a55\u4fa1\u306e\u307f\u3002</p>"},{"location":"ja/use_case/traffic_light/#_2","title":"\u4e8b\u524d\u6e96\u5099","text":"<p>perception \u3067\u306f\u3001\u6a5f\u68b0\u5b66\u7fd2\u306e\u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u4f7f\u7528\u3059\u308b\u3002 \u30e2\u30c7\u30eb\u3092\u4e8b\u524d\u306b\u6e96\u5099\u3057\u3066\u3044\u306a\u3044\u3068Autoware\u304b\u3089\u8a8d\u8b58\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u306a\u3044\u3002 \u4f55\u3082\u8a55\u4fa1\u7d50\u679c\u304c\u51fa\u3066\u3053\u306a\u3044\u5834\u5408\u306f\u3001\u3053\u306e\u4f5c\u696d\u304c\u6b63\u3057\u304f\u51fa\u6765\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_3","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30e2\u30c7\u30eb\u306fAutoware\u306e\u30bb\u30c3\u30c8\u30a2\u30c3\u30d7\u6642\u306b\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3055\u308c\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306f\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b\u306bAutoware\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306b\u3088\u3063\u3066\u7570\u306a\u308b\u306e\u3067\u3069\u3061\u3089\u306e\u624b\u6cd5\u304c\u4f7f\u308f\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002 \u4ee5\u4e0b\u306e\u30d1\u30bf\u30fc\u30f3\u304c\u5b58\u5728\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#ansible","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u30b9\u30af\u30ea\u30d7\u30c8\u5b9f\u884c\u6642\u306b<code>Download artifacts? [y/N]</code>\u3068\u51fa\u3066\u304f\u308b\u306e\u3067<code>y</code>\u3092\u5165\u529b\u3057\u3066\u30a8\u30f3\u30bf\u30fc\u3092\u62bc\u3059(Autoware foundation\u306emain\u3060\u3068\u3053\u3061\u3089) https://github.com/autowarefoundation/autoware/blob/main/ansible/roles/artifacts/tasks/main.yaml</p>"},{"location":"ja/use_case/traffic_light/#_4","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u5c11\u3057\u53e4\u3044Autoware.universe\u3092\u4f7f\u7528\u3057\u3066\u3044\u308b\u5834\u5408\u306f\u3053\u3061\u3089\u3001<code>13b96ad3c636389b32fea3a47dfb7cfb7813cadc</code>\u306e\u30b3\u30df\u30c3\u30c8\u30cf\u30c3\u30b7\u30e5\u307e\u3067\u306f\u3053\u3061\u3089\u304c\u4f7f\u7528\u3055\u308c\u308b\u3002 traffic_light_classifier/CMakeList.txt</p>"},{"location":"ja/use_case/traffic_light/#_5","title":"\u30e2\u30c7\u30eb\u30d5\u30a1\u30a4\u30eb\u306e\u5909\u63db","text":"<p>\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u3057\u305f onnx \u30d5\u30a1\u30a4\u30eb\u306f\u305d\u306e\u307e\u307e\u4f7f\u7528\u3059\u308b\u306e\u3067\u306f\u306a\u304f\u3001TensorRT \u306e engine \u30d5\u30a1\u30a4\u30eb\u306b\u5909\u63db\u3057\u3066\u5229\u7528\u3059\u308b\u3002 \u5909\u63db\u7528\u306e\u30b3\u30de\u30f3\u30c9\u304c\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u306e\u3067\u3001autoware \u306e\u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9\u3092 source \u3057\u3066\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3059\u308b\u3002</p> <p><code>$HOME/autoware</code>\u306bautoware\u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u3057\u305f\u3068\u3057\u3066\u8aac\u660e\u3059\u308b\u3002</p> <pre><code>source $HOME/autoware/install/setup.bash\nros2 launch traffic_light_classifier traffic_light_classifier.launch.xml use_gpu:=true  build_only:=true\nros2 launch traffic_light_fine_detector traffic_light_fine_detector.launch.xml build_only:=true\n</code></pre> <p>\u5909\u63db\u30b3\u30de\u30f3\u30c9\u304c\u7d42\u4e86\u3059\u308b\u3068\u3001engine \u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u3002 \u30e2\u30c7\u30eb\u306e\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9\u65b9\u6cd5\u306b\u5408\u308f\u305b\u3066\u51fa\u529b\u5148\u304c\u5909\u308f\u308b\u306e\u3067\u3001\u9069\u5207\u306a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u78ba\u8a8d\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#ansible_1","title":"ansible\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <pre><code>$HOME/autoware_data/traffic_light_classifier/traffic_light_classifier_mobilenetv2_batch_6.fp16-batch6.engine\n$HOME/autoware_data/traffic_light_fine_detector/tlr_yolox_s_batch_6.fp16-batch6.engine\n</code></pre>"},{"location":"ja/use_case/traffic_light/#_6","title":"\u30d1\u30c3\u30b1\u30fc\u30b8\u306e\u30d3\u30eb\u30c9\u6642\u306b\u81ea\u52d5\u3067\u30c0\u30a6\u30f3\u30ed\u30fc\u30c9","text":"<p>\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b</p> <pre><code>$HOME/autoware/install/traffic_light_classifier/share/traffic_light_classifier/data/traffic_light_classifier_mobilenetv2_batch_6.fp16-batch6.engine\n$HOME/autoware/install/traffic_light_fine_detector/share/traffic_light_fine_detector/data/tlr_yolox_s_batch_6.fp16-batch6.engine\n</code></pre>"},{"location":"ja/use_case/traffic_light/#pc1launch","title":"(PC1\u53f0\u3067\u8a55\u4fa1\u3059\u308b\u5834\u5408)launch\u30d5\u30a1\u30a4\u30eb\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u66f8\u304d\u63db\u3048","text":"<p>autoware.universe/launch/tier4_perception_launch/launch/perception.launch.xml \u306e traffic_light_recognition/fusion_only \u3092 <code>false</code>\u306b\u3059\u308b\u3002 https://github.com/autowarefoundation/autoware.universe/blob/main/launch/tier4_perception_launch/launch/perception.launch.xml#L79</p> <p>Autoware Foundation\u306emain\u3067\u306f\u3001<code>false</code>\u306b\u306a\u3063\u3066\u3044\u308b\u304c\u3001\u5b9f\u8eca\u4e21\u3067\u5229\u7528\u3057\u3066\u3044\u308bAutoware\u306e\u5834\u5408\u306f\u3001<code>true</code>\u306b\u306a\u3063\u3066\u3044\u3053\u3068\u304c\u3042\u308b\u3002 <code>true</code>\u306f\u3001\u5225\u306e\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u304b\u3089\u3001\u8a8d\u8b58\u7d50\u679c\u304c\u9001\u3089\u308c\u3066\u304f\u308b\u3068\u3044\u3046\u8a2d\u5b9a\u3067\u3042\u308b\u305f\u3081\u3001PC1\u53f0\u3067\u8a55\u4fa1\u3059\u308b\u5834\u5408\u306b\u306f<code>false</code>\u306b\u623b\u3057\u3066\u304b\u3089\u5b9f\u884c\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_7","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>traffic_light.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>traffic_light_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u30ab\u30e1\u30e9\u30c7\u30fc\u30bf\u3092\u51fa\u529b\u3057\u3001perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304c\u8a8d\u8b58\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c/perception/traffic_light_recognition/traffic_signals \u3092 subscribe \u3057\u3066\u3001\u30b3\u30fc\u30eb\u30d0\u30c3\u30af\u3067 perception_eval \u306e\u95a2\u6570\u3092\u7528\u3044\u3066\u8a55\u4fa1\u3057\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/traffic_light/#_8","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_9","title":"\u6b63\u5e38","text":"<p>perception_eval \u306e\u8a55\u4fa1\u95a2\u6570\u3092\u5b9f\u884c\u3057\u3066\u4ee5\u4e0b\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3059\u3068\u304d</p> <ol> <li>frame_result.pass_fail_result \u306b object \u304c\u6700\u4f4e 1 \u3064\u5165\u3063\u3066\u3044\u308b (<code>tp_object_results != [] and fp_object_results != [] and fn_objects != []</code>)</li> <li>\u8a55\u4fa1\u5931\u6557\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304c 0 \u500b (<code>frame_result.pass_fail_result.get_fail_object_num() == 0</code>)</li> </ol>"},{"location":"ja/use_case/traffic_light/#_10","title":"\u7570\u5e38","text":"<p>\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/traffic_light/#_11","title":"\u8a55\u4fa1\u30b9\u30ad\u30c3\u30d7","text":"<p>\u4ee5\u4e0b\u306e\u5834\u5408\u306b\u3001\u8a55\u4fa1\u3092\u305b\u305a\u306b\u8a55\u4fa1\u304c\u98db\u3070\u3055\u308c\u305f\u56de\u6570\u306e\u30ab\u30a6\u30f3\u30c8(FrameSkip)\u30921\u8db3\u3059\u51e6\u7406\u306e\u307f\u884c\u3046</p> <ul> <li>\u53d7\u4fe1\u3057\u305fobject\u306e\u30d8\u30c3\u30c0\u30fc\u6642\u523b\u306e\u524d\u5f8c75msec\u4ee5\u5185\u306b\u771f\u5024\u304c\u5b58\u5728\u3057\u306a\u3044\u5834\u5408</li> </ul>"},{"location":"ja/use_case/traffic_light/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b /perception/traffic_light_recognition/traffic_signals tier4_perception_msgs/msg/TrafficSignalArray <p>Published topics:</p> topic \u540d \u30c7\u30fc\u30bf\u578b - -"},{"location":"ja/use_case/traffic_light/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>localization: false</li> <li>planning: false</li> <li>control: false</li> <li>sensing: false / true (\u30c7\u30d5\u30a9\u30eb\u30c8 false\u3001\u30b7\u30ca\u30ea\u30aa\u306e <code>LaunchSensing</code> \u30ad\u30fc\u3067 t4_dataset \u6bce\u306b\u6307\u5b9a\u3059\u308b)</li> <li>perception_mode: camera_lidar_fusion</li> </ul> <p>\u6ce8:\u30a2\u30ce\u30fc\u30c6\u30b7\u30e7\u30f3\u6642\u3068\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u6642\u3067\u81ea\u5df1\u4f4d\u7f6e\u3092\u5408\u308f\u305b\u305f\u3044\u306e\u3067 bag \u306b\u5165\u3063\u3066\u3044\u308b tf \u3092\u4f7f\u3044\u56de\u3059\u3002\u305d\u306e\u305f\u3081 localization \u306f\u7121\u52b9\u3067\u3042\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_12","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea","text":"<p>\u8a8d\u8b58\u6a5f\u80fd\u306e\u8a55\u4fa1\u306fperception_eval\u306b\u4f9d\u5b58\u3057\u3066\u3044\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#driving_log_replayer","title":"\u4f9d\u5b58\u30e9\u30a4\u30d6\u30e9\u30ea\u3068\u306e driving_log_replayer \u306e\u5f79\u5272\u5206\u62c5","text":"<p>driving_log_replayer \u304c ROS \u3068\u306e\u63a5\u7d9a\u90e8\u5206\u3092\u62c5\u5f53\u3057\u3001perception_eval \u304c\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u4f7f\u3063\u3066\u5b9f\u969b\u306b\u8a55\u4fa1\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3068\u3044\u3046\u5206\u62c5\u306b\u306a\u3063\u3066\u3044\u308b\u3002 perception_eval \u306f ROS \u975e\u4f9d\u5b58\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u306a\u306e\u3067\u3001ROS \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u53d7\u3051\u53d6\u308b\u3053\u3068\u304c\u3067\u304d\u306a\u3044\u3002 \u307e\u305f\u3001timestamp \u304c ROS \u3067\u306f\u30ca\u30ce\u79d2\u3001t4_dataset \u306f <code>nuScenes</code> \u3092\u30d9\u30fc\u30b9\u3057\u3066\u3044\u308b\u305f\u3081\u30df\u30ea\u79d2\u304c\u63a1\u7528\u3055\u308c\u3066\u3044\u308b\u3002 \u3053\u306e\u305f\u3081\u3001\u30e9\u30a4\u30d6\u30e9\u30ea\u4f7f\u7528\u524d\u306b\u9069\u5207\u306a\u5909\u63db\u304c\u5fc5\u8981\u3068\u306a\u308b\u3002</p> <p>driving_log_replayer \u306f\u3001autoware \u306e perception \u30e2\u30b8\u30e5\u30fc\u30eb\u304b\u3089\u51fa\u529b\u3055\u308c\u305f topic \u3092 subscribe \u3057\u3001perception_eval \u3067\u5b9a\u7fa9\u3055\u308c\u3066\u3044\u308b class \u306b\u5408\u308f\u305b\u305f\u30c7\u30fc\u30bf\u5f62\u5f0f\u306b\u5909\u63db\u3057\u3066\u6e21\u3059\u3002 \u307e\u305f\u3001perception_eval \u304b\u3089\u8fd4\u3063\u3066\u304f\u308b\u8a55\u4fa1\u7d50\u679c\u306e ROS \u306e topic \u3067 publish \u3057\u53ef\u8996\u5316\u3059\u308b\u90e8\u5206\u3082\u62c5\u5f53\u3059\u308b\u3002</p> <p>perception_eval \u306f\u3001driving_log_replayer \u304b\u3089\u6e21\u3055\u308c\u305f\u691c\u77e5\u7d50\u679c\u3068 GroundTruth \u3092\u6bd4\u8f03\u3057\u3066\u6307\u6a19\u3092\u8a08\u7b97\u3057\u3001\u7d50\u679c\u3092\u51fa\u529b\u3059\u308b\u90e8\u5206\u3092\u62c5\u5f53\u3059\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"<p>t4_dataset \u3067\u5fc5\u8981\u306a\u30c8\u30d4\u30c3\u30af\u304c\u542b\u307e\u308c\u3066\u3044\u308b\u3053\u3068</p> <p>\u8eca\u4e21\u306e ECU \u306e CAN \u3068\u3001\u4f7f\u7528\u3057\u3066\u3044\u308b sensor \u306e topic \u304c\u5fc5\u8981 \u4ee5\u4e0b\u306f\u4f8b\u3067\u3042\u308a\u3001\u9055\u3046\u30bb\u30f3\u30b5\u30fc\u3092\u4f7f\u3063\u3066\u3044\u308b\u5834\u5408\u306f\u9069\u5b9c\u8aad\u307f\u66ff\u3048\u308b\u3002</p> <p>LiDAR \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e LiDAR \u306e packets \u3092\u542b\u3081\u308b\u3002 /sensing/lidar/concatenated/pointcloud \u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306e LaunchSensing: false \u306e\u5834\u5408\u306b\u4f7f\u7528\u3055\u308c\u308b\u3002</p> <p>CAMERA \u304c\u8907\u6570\u3064\u3044\u3066\u3044\u308b\u5834\u5408\u306f\u3001\u642d\u8f09\u3055\u308c\u3066\u3044\u308b\u3059\u3079\u3066\u306e camera_info \u3068 image_rect_color_compressed \u3092\u542b\u3081\u308b</p> topic \u540d \u30c7\u30fc\u30bf\u578b /pacmod/from_can_bus can_msgs/msg/Frame /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage <p>CAN \u306e\u4ee3\u308f\u308a\u306b vehicle \u306e topic \u3092\u542b\u3081\u3066\u3082\u826f\u3044\u3002</p> topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/camera/camera*/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/camera*/image_rect_color/compressed sensor_msgs/msg/CompressedImage /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/gnss/ublox/fix_velocity geometry_msgs/msg/TwistWithCovarianceStamped /sensing/gnss/ublox/nav_sat_fix sensor_msgs/msg/NavSatFix /sensing/gnss/ublox/navpvt ublox_msgs/msg/NavPVT /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /sensing/lidar/concatenated/pointcloud sensor_msgs/msg/PointCloud2 /sensing/lidar/*/velodyne_packets velodyne_msgs/VelodyneScan /tf tf2_msgs/msg/TFMessage /vehicle/status/control_mode autoware_vehicle_msgs/msg/ControlModeReport /vehicle/status/gear_status autoware_vehicle_msgs/msg/GearReport /vehicle/status/steering_status autoware_vehicle_msgs/SteeringReport /vehicle/status/turn_indicators_status autoware_vehicle_msgs/msg/TurnIndicatorsReport /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/traffic_light/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/traffic_light/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_13","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u8a55\u4fa1\u3068\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e 2 \u7a2e\u985e\u306e\u8a55\u4fa1\u304c\u3042\u308b\u3002 \u30e6\u30fc\u30b9\u30b1\u30fc\u30b9\u306f 1 \u500b\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3067\u884c\u3046\u8a55\u4fa1\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u306f\u8907\u6570\u306e\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3092\u7528\u3044\u3066\u3001\u5404\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306e\u7d50\u679c\u306e\u5e73\u5747\u3092\u53d6\u308b\u8a55\u4fa1\u3067\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u30ad\u30e3\u30ea\u30d6\u30ec\u30fc\u30b7\u30e7\u30f3\u5024\u306e\u5909\u66f4\u304c\u3042\u308a\u5f97\u308b\u306e\u3067 vehicle_id \u3092\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u6bce\u306b\u8a2d\u5b9a\u51fa\u6765\u308b\u3088\u3046\u306b\u3059\u308b\u3002 \u307e\u305f\u3001Sensing \u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8d77\u52d5\u3059\u308b\u304b\u3069\u3046\u304b\u306e\u8a2d\u5b9a\u3082\u884c\u3046\u3002</p> <p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/traffic_light/#_14","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>perception \u3067\u306f\u3001\u30b7\u30ca\u30ea\u30aa\u306b\u6307\u5b9a\u3057\u305f\u6761\u4ef6\u3067 perception_eval \u304c\u8a55\u4fa1\u3057\u305f\u7d50\u679c\u3092\u5404 frame \u6bce\u306b\u51fa\u529b\u3059\u308b\u3002 \u5168\u3066\u306e\u30c7\u30fc\u30bf\u3092\u6d41\u3057\u7d42\u308f\u3063\u305f\u3042\u3068\u306b\u3001\u6700\u7d42\u7684\u306a\u30e1\u30c8\u30ea\u30af\u30b9\u3092\u8a08\u7b97\u3057\u3066\u3044\u308b\u305f\u3081\u3001\u6700\u7d42\u884c\u3060\u3051\u3001\u4ed6\u306e\u884c\u3068\u5f62\u5f0f\u304c\u7570\u306a\u308b\u3002</p> <p>\u4ee5\u4e0b\u306b\u3001\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3068\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3092\u793a\u3059\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>\u5404\u30d5\u30ec\u30fc\u30e0\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"FrameName\": \"\u8a55\u4fa1\u306b\u4f7f\u7528\u3057\u305ft4_dataset\u306e\u30d5\u30ec\u30fc\u30e0\u756a\u53f7\",\n    \"FrameSkip\": \"object\u306e\u8a55\u4fa1\u3092\u4f9d\u983c\u3057\u305f\u304cdataset\u306b75msec\u4ee5\u5185\u306e\u771f\u5024\u304c\u306a\u304f\u8a55\u4fa1\u3092\u98db\u3070\u3055\u308c\u305f\u56de\u6570\",\n    \"PassFail\": {\n      \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success or Fail\" },\n      \"Info\": {\n        \"TP\": \"TP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n        \"FP\": \"FP\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\",\n        \"FN\": \"FN\u3068\u5224\u5b9a\u3055\u308c\u305f\u6570\"\n      }\n    }\n  }\n}\n</code></pre> <p>\u30e1\u30c8\u30ea\u30af\u30b9\u30c7\u30fc\u30bf\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8</p> <pre><code>{\n  \"Frame\": {\n    \"FinalScore\": {\n      \"Score\": {\n        \"TP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTP\u7387\",\n          \"label0\": \"label0\u306eTP\u7387\",\n          \"label1\": \"label1\u306eTP\u7387\"\n        },\n        \"FP\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFP\u7387\",\n          \"label0\": \"label0\u306eFP\u7387\",\n          \"label1\": \"label1\u306eFP\u7387\"\n        },\n        \"FN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eFN\u7387\",\n          \"label0\": \"label0\u306eFN\u7387\",\n          \"label1\": \"label1\u306eFN\u7387\"\n        },\n        \"TN\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eTN\u7387\",\n          \"label0\": \"label0\u306eTN\u7387\",\n          \"label1\": \"label1\u306eTN\u7387\"\n        },\n        \"Accuracy\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eAccuracy\",\n          \"label0\": \"label0\u306eAccuracy\",\n          \"label1\": \"label1\u306eAccuracy\"\n        },\n        \"Precision\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306ePrecision\",\n          \"label0\": \"label0\u306ePrecision\",\n          \"label1\": \"label1\u306ePrecision\"\n        },\n        \"Recall\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eRecall\",\n          \"label0\": \"label0\u306eRecall\",\n          \"label1\": \"label1\u306eRecall\"\n        },\n        \"F1score\": {\n          \"ALL\": \"\u3059\u3079\u3066\u306e\u30e9\u30d9\u30eb\u306eF1score\",\n          \"label0\": \"label0\u306eF1score\",\n          \"label1\": \"label1\u306eF1score\"\n        }\n      },\n      \"ConfusionMatrix\": {\n        \"label0(\u771f\u5024)\": {\n          \"label0(\u4e88\u6e2c\u5024)\": \"\u5024\",\n          \"label1(\u4e88\u6e2c\u5024)\": \"\u5024\"\n        },\n        \"label1(\u771f\u5024)\": {\n          \"label0(\u4e88\u6e2c\u5024)\": \"\u5024\",\n          \"label1(\u4e88\u6e2c\u5024)\": \"\u5024\"\n        }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"ja/use_case/traffic_light/#pickle","title":"pickle \u30d5\u30a1\u30a4\u30eb","text":"<p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u8907\u6570\u306e bag \u3092\u518d\u751f\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u304c\u3001ROS \u306e\u4ed5\u69d8\u4e0a\u30011 \u56de\u306e launch \u3067\u3001\u8907\u6570\u306e bag \u3092\u5229\u7528\u3059\u308b\u3053\u3068\u306f\u51fa\u6765\u306a\u3044\u3002 1 \u3064\u306e bag\u3001\u3059\u306a\u308f\u3061 1 \u3064\u306e t4_dataset \u306b\u5bfe\u3057\u3066 launch \u3092 1 \u56de\u53e9\u304f\u3053\u3068\u306a\u308b\u306e\u3067\u3001\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u3067\u306f\u3001\u542b\u307e\u308c\u308b\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u306e\u6570\u3060\u3051 launch \u3092\u5b9f\u884c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002</p> <p>\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306f 1 \u56de\u306e launch \u3067\u8a55\u4fa1\u3067\u304d\u306a\u3044\u305f\u3081\u3001perception \u3067\u306f\u3001result.jsonl \u306e\u4ed6\u306b scene_result.pkl \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u3092\u51fa\u529b\u3059\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306f python \u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30d5\u30a1\u30a4\u30eb\u3068\u3057\u3066\u4fdd\u5b58\u3057\u305f\u3082\u306e\u3067\u3042\u308a\u3001perception_eval \u306e PerceptionEvaluationManager.frame_results \u3092\u4fdd\u5b58\u3057\u3066\u3044\u308b\u3002 pickle \u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3057\u305f object \u3092\u3059\u3079\u3066\u8aad\u307f\u8fbc\u307f\u3001dataset \u306e\u5e73\u5747\u306e\u6307\u6a19\u3092\u51fa\u529b\u3059\u308b\u3053\u3068\u3067\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u8a55\u4fa1\u304c\u884c\u3048\u308b\u3002</p>"},{"location":"ja/use_case/traffic_light/#_15","title":"\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u7d50\u679c\u30d5\u30a1\u30a4\u30eb","text":"<p>\u30b7\u30ca\u30ea\u30aa\u306b\u8907\u6570\u306e dataset \u3092\u8a18\u8ff0\u3057\u305f\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u8a55\u4fa1\u306e\u5834\u5408\u306b\u306f\u3001\u7d50\u679c\u51fa\u529b\u5148\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b database_result.json \u3068\u3044\u3046\u30d5\u30a1\u30a4\u30eb\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p> <p>\u5f62\u5f0f\u306f\u30e1\u30c8\u30ea\u30af\u30b9\u306e\u30d5\u30a9\u30fc\u30de\u30c3\u30c8 \u3068\u540c\u3058</p>"},{"location":"ja/use_case/yabloc/","title":"YabLoc\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u306e\u8a55\u4fa1","text":"<p>Autoware \u306eYabLoc\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u304c\u5b89\u5b9a\u3057\u3066\u52d5\u4f5c\u3057\u3066\u3044\u308b\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#_1","title":"\u8a55\u4fa1\u65b9\u6cd5","text":"<p><code>yabloc.launch.py</code> \u3092\u4f7f\u7528\u3057\u3066\u8a55\u4fa1\u3059\u308b\u3002 launch \u3092\u7acb\u3061\u4e0a\u3052\u308b\u3068\u4ee5\u4e0b\u306e\u3053\u3068\u304c\u5b9f\u884c\u3055\u308c\u3001\u8a55\u4fa1\u3055\u308c\u308b\u3002</p> <ol> <li>launch \u3067\u8a55\u4fa1\u30ce\u30fc\u30c9(<code>yabloc_evaluator_node</code>)\u3068 <code>logging_simulator.launch</code>\u3001<code>ros2 bag play</code>\u30b3\u30de\u30f3\u30c9\u3092\u7acb\u3061\u4e0a\u3052\u308b</li> <li>bag \u304b\u3089\u51fa\u529b\u3055\u308c\u305f\u30bb\u30f3\u30b5\u30fc\u30c7\u30fc\u30bf\u3092 autoware \u304c\u53d7\u3051\u53d6\u3063\u3066\u3001\u81ea\u5df1\u4f4d\u7f6e\u63a8\u5b9a\u3092\u884c\u3046</li> <li>\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c topic \u3092 subscribe \u3057\u3066\u3001\u5404\u57fa\u6e96\u3092\u6e80\u305f\u3057\u3066\u3044\u308b\u304b\u3092\u5224\u5b9a\u3057\u3066\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u306b\u8a18\u9332\u3059\u308b</li> <li>bag \u306e\u518d\u751f\u304c\u7d42\u4e86\u3059\u308b\u3068\u81ea\u52d5\u3067 launch \u304c\u7d42\u4e86\u3057\u3066\u8a55\u4fa1\u304c\u7d42\u4e86\u3059\u308b</li> </ol>"},{"location":"ja/use_case/yabloc/#yabloc_1","title":"YabLoc \u306e\u53ef\u7528\u6027","text":"<p>\u672c\u9805\u76ee\u3067\u306f\u3001YabLoc\u306e\u53ef\u7528\u6027\u3092\u8a55\u4fa1\u3059\u308b\u305f\u3081\u306b\u7528\u610f\u3055\u308c\u3066\u3044\u308b\u3002\u3053\u308c\u306f\u3001\u5177\u4f53\u7684\u306b\u306f\u3001\u4e0b\u8a18\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3092\u691c\u77e5\u3059\u308b\u3053\u3068\u3092\u76ee\u7684\u3068\u3059\u308b\u3002</p> <ul> <li>Runtime error\u7b49\u306b\u3088\u308a <code>image_processing</code> \u304c\u843d\u3061\u3066\u3044\u308b</li> <li>Runtime error\u7b49\u306b\u3088\u308a <code>particle_filter</code> \u304c\u843d\u3061\u3066\u3044\u308b</li> </ul> <p>\u305d\u306e\u305f\u3081\u306b\u3001\u672c\u9805\u76ee\u3067\u306f\u4e0b\u8a18\u306e\u51fa\u529b\u304c\u5b9a\u671f\u7684\u306b\u51fa\u529b\u3055\u308c\u3066\u3044\u308b\u304b\u3069\u3046\u304b\u3092\u8a55\u4fa1\u3059\u308b\u3002</p> <ul> <li>/localization/pose_estimator/yabloc/pf/pose</li> </ul> <p>\u3053\u308c\u306f\u3001YabLoc Monitor\u3068\u3044\u3046Autoware\u5185\u306e\u30d1\u30c3\u30b1\u30fc\u30b8\u3092\u9593\u63a5\u7684\u306b\u5229\u7528\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u5b9f\u73fe\u3055\u308c\u308b\u3002\u672c\u30c4\u30fc\u30eb\u306f\u3001\u4e0b\u8a18\u306e\u30c8\u30d4\u30c3\u30af\u3092\u76e3\u8996\u3059\u308b\u3053\u3068\u306b\u3088\u3063\u3066\u305d\u306e\u60c5\u5831\u3092\u53d6\u5f97\u3059\u308b\u3002</p> <ul> <li>/diagnostics</li> </ul>"},{"location":"ja/use_case/yabloc/#_2","title":"\u8a55\u4fa1\u7d50\u679c","text":"<p>topic \u306e subscribe 1 \u56de\u306b\u3064\u304d\u3001\u4ee5\u4e0b\u306b\u8a18\u8ff0\u3059\u308b\u5224\u5b9a\u7d50\u679c\u304c\u51fa\u529b\u3055\u308c\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#_3","title":"\u53ef\u7528\u6027\u6b63\u5e38","text":"<p>YabLoc Monitor\u304c\u51fa\u529b\u3059\u308b <code>/diagnostics</code> \u306e\u4e2d\u304b\u3089\u3001\u76e3\u8996\u30c8\u30d4\u30c3\u30af\u306b\u95a2\u3059\u308b\u60c5\u5831\u3092\u62bd\u51fa\u3059\u308b\u3002 \u6700\u65b0\u306e\u60c5\u5831\u306b\u304a\u3051\u308bAvailability\u304c <code>OK</code> \u3067\u3042\u308b\u5834\u5408\u3001\u6b63\u5e38\u3067\u3042\u308b\u3068\u5224\u65ad\u3059\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#_4","title":"\u53ef\u7528\u6027\u7570\u5e38","text":"<p>\u53ef\u7528\u6027\u6b63\u5e38\u306e\u6761\u4ef6\u3092\u6e80\u305f\u3055\u306a\u3044\u5834\u5408</p>"},{"location":"ja/use_case/yabloc/#topic","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Topic \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"<p>Subscribed topics:</p> Topic name Data type /diagnostics diagnostic_msgs::msg::DiagnosticArray <p>Published topics:</p> Topic name Data type N/A N/A"},{"location":"ja/use_case/yabloc/#service","title":"\u8a55\u4fa1\u30ce\u30fc\u30c9\u304c\u4f7f\u7528\u3059\u308b Service \u540d\u3068\u30c7\u30fc\u30bf\u578b","text":"service \u540d \u30c7\u30fc\u30bf\u578b /api/localization/initialize InitializeLocalization"},{"location":"ja/use_case/yabloc/#logging_simulatorlaunch","title":"logging_simulator.launch \u306b\u6e21\u3059\u5f15\u6570","text":"<p>autoware \u306e\u51e6\u7406\u3092\u8efd\u304f\u3059\u308b\u305f\u3081\u3001\u8a55\u4fa1\u306b\u95a2\u4fc2\u306e\u306a\u3044\u30e2\u30b8\u30e5\u30fc\u30eb\u306f launch \u306e\u5f15\u6570\u306b false \u3092\u6e21\u3059\u3053\u3068\u3067\u7121\u52b9\u5316\u3059\u308b\u3002\u4ee5\u4e0b\u3092\u8a2d\u5b9a\u3057\u3066\u3044\u308b\u3002</p> <ul> <li>perception: false</li> <li>planning: false</li> <li>control: false</li> </ul>"},{"location":"ja/use_case/yabloc/#simulation","title":"simulation","text":"<p>\u30b7\u30df\u30e5\u30ec\u30fc\u30b7\u30e7\u30f3\u5b9f\u884c\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#rosbag-topic","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u308b\u3079\u304d topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /sensing/camera/traffic_light/camera_info sensor_msgs/msg/CameraInfo /sensing/camera/traffic_light/image_raw/compressed sensor_msgs/msg/CompressedImage /sensing/imu/tamagawa/imu_raw sensor_msgs/msg/Imu /vehicle/status/velocity_status autoware_vehicle_msgs/msg/VelocityReport"},{"location":"ja/use_case/yabloc/#rosbag-topic_1","title":"\u5165\u529b rosbag \u306b\u542b\u307e\u308c\u3066\u306f\u3044\u3051\u306a\u3044 topic","text":"topic \u540d \u30c7\u30fc\u30bf\u578b /clock rosgraph_msgs/msg/Clock <p>clock \u306f\u3001ros2 bag play \u306e--clock \u30aa\u30d7\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066\u51fa\u529b\u3057\u3066\u3044\u308b\u306e\u3067\u3001bag \u81ea\u4f53\u306b\u8a18\u9332\u3055\u308c\u3066\u3044\u308b\u3068 2 \u91cd\u306b\u51fa\u529b\u3055\u308c\u3066\u3057\u307e\u3046\u306e\u3067 bag \u306b\u306f\u542b\u3081\u306a\u3044</p>"},{"location":"ja/use_case/yabloc/#evaluation","title":"evaluation","text":"<p>\u8a55\u4fa1\u306b\u5fc5\u8981\u306a\u60c5\u5831\u3092\u8ff0\u3079\u308b\u3002</p>"},{"location":"ja/use_case/yabloc/#_5","title":"\u30b7\u30ca\u30ea\u30aa\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p>"},{"location":"ja/use_case/yabloc/#_6","title":"\u8a55\u4fa1\u7d50\u679c\u30d5\u30a9\u30fc\u30de\u30c3\u30c8","text":"<p>\u30b5\u30f3\u30d7\u30eb\u53c2\u7167</p> <p>\u4ee5\u4e0b\u306b\u3001\u305d\u308c\u305e\u308c\u306e\u8a55\u4fa1\u306e\u4f8b\u3092\u8a18\u8ff0\u3059\u308b\u3002 \u6ce8:\u7d50\u679c\u30d5\u30a1\u30a4\u30eb\u30d5\u30a9\u30fc\u30de\u30c3\u30c8\u3067\u89e3\u8aac\u6e08\u307f\u306e\u5171\u901a\u90e8\u5206\u306b\u3064\u3044\u3066\u306f\u7701\u7565\u3059\u308b\u3002</p> <p>Availability\u306e\u7d50\u679c(Frame \u306e\u4e2d\u306b Availability \u9805\u76ee\u304c\u3042\u308b\u5834\u5408)</p> <pre><code>{\n  \"Availability\": {\n    \"Result\": { \"Total\": \"Success or Fail\", \"Frame\": \"Success, Fail, or Warn\" },\n    \"Info\": {}\n  }\n}\n</code></pre>"}]}