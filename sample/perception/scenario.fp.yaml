ScenarioFormatVersion: 3.0.0
ScenarioName: fp_sample
ScenarioDescription: fp_sample
SensorModel: sample_sensor_kit
VehicleModel: sample_vehicle
Evaluation:
  UseCaseName: perception
  UseCaseFormatVersion: 0.6.0
  Datasets:
    - sample_dataset:
        VehicleId: default # Specify VehicleId for each data set.
        LaunchSensing: false # Specifies whether the sensing module should be activated for each dataset. if false, use concatenated/pointcloud in bag
        LocalMapPath: $HOME/autoware_map/sample-map-planning # Specify LocalMapPath for each data set.
  Conditions:
    PassRate: 99.0 # How much (%) of the evaluation attempts are considered successful.
    CriteriaMethod: num_tp # Method name of criteria (num_tp/metrics_score)
    CriteriaLevel: easy # Level of criteria (perfect/hard/normal/easy, or custom value 0.0-100.0)
  PerceptionEvaluationConfig:
    evaluation_config_dict:
      evaluation_task: fp_validation # detection, tracking, or fp_validation. Evaluate the objects specified here
      target_labels: [car, bicycle, pedestrian, motorbike] # evaluation label
      max_x_position: 102.4 # Maximum x position of object to be evaluated
      max_y_position: 102.4 # Maximum y position of object to be evaluated
      max_matchable_radii: [5.0, 3.0, 3.0, 3.0]
      merge_similar_labels: false # Whether or not to merge similar labels https://github.com/tier4/autoware_perception_evaluation/blob/develop/docs/en/perception/label.md#merge-similar-labels-option
      allow_matching_unknown: true # Whether or not to match objects whose labels are unknown
  CriticalObjectFilterConfig:
    target_labels: [car, bicycle, pedestrian, motorbike]
    max_x_position_list: [100.0, 100.0, 100.0, 100.0]
    max_y_position_list: [100.0, 100.0, 100.0, 100.0]
  PerceptionPassFailConfig:
    target_labels: [car, bicycle, pedestrian, motorbike]
    matching_threshold_list: [2.0, 2.0, 2.0, 2.0] # Threshold for planar distance matching
